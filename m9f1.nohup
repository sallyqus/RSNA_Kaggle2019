+ model=model009
+ gpu=1
+ fold=1
+ conf=./conf/model009.py
+ python -m src.cnn.main train ./conf/model009.py --fold 1 --gpu 1

----- 2019-11-04 01:09:58 -----
/home/xum/kaggle/kaggle-rsna-intracranial-hemorrhage/src/cnn/main.py train ./conf/model009.py --fold 1 --gpu 1
logpath: ./model/model009/train_fold1.log
mode: train
workdir: ./model/model009
fold: 1
batch size: 16
acc: 1
model: efficientnet-b7
pretrained: none
input channel: 5
Loaded pretrained weights for efficientnet-b7
EfficientNet(
  (_conv_stem): Conv2dDynamicSamePadding(5, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)
  (_bn0): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
  (_blocks): ModuleList(
    (0): MBConvBlock(
      (_depthwise_conv): Conv2dStaticSamePadding(
        64, 64, kernel_size=(3, 3), stride=[1, 1], groups=64, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        64, 16, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        16, 64, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (1): MBConvBlock(
      (_depthwise_conv): Conv2dStaticSamePadding(
        32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        32, 8, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        8, 32, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (2): MBConvBlock(
      (_depthwise_conv): Conv2dStaticSamePadding(
        32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        32, 8, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        8, 32, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (3): MBConvBlock(
      (_depthwise_conv): Conv2dStaticSamePadding(
        32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        32, 8, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        8, 32, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (4): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        192, 192, kernel_size=(3, 3), stride=[2, 2], groups=192, bias=False
        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        192, 8, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        8, 192, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (5): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        288, 288, kernel_size=(3, 3), stride=(1, 1), groups=288, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        288, 12, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        12, 288, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (6): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        288, 288, kernel_size=(3, 3), stride=(1, 1), groups=288, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        288, 12, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        12, 288, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (7): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        288, 288, kernel_size=(3, 3), stride=(1, 1), groups=288, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        288, 12, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        12, 288, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (8): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        288, 288, kernel_size=(3, 3), stride=(1, 1), groups=288, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        288, 12, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        12, 288, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (9): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        288, 288, kernel_size=(3, 3), stride=(1, 1), groups=288, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        288, 12, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        12, 288, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (10): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        288, 288, kernel_size=(3, 3), stride=(1, 1), groups=288, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        288, 12, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        12, 288, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (11): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        288, 288, kernel_size=(5, 5), stride=[2, 2], groups=288, bias=False
        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        288, 12, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        12, 288, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        288, 80, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (12): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        480, 480, kernel_size=(5, 5), stride=(1, 1), groups=480, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        480, 20, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        20, 480, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (13): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        480, 480, kernel_size=(5, 5), stride=(1, 1), groups=480, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        480, 20, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        20, 480, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (14): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        480, 480, kernel_size=(5, 5), stride=(1, 1), groups=480, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        480, 20, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        20, 480, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (15): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        480, 480, kernel_size=(5, 5), stride=(1, 1), groups=480, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        480, 20, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        20, 480, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (16): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        480, 480, kernel_size=(5, 5), stride=(1, 1), groups=480, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        480, 20, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        20, 480, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (17): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        480, 480, kernel_size=(5, 5), stride=(1, 1), groups=480, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        480, 20, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        20, 480, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (18): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        480, 480, kernel_size=(3, 3), stride=[2, 2], groups=480, bias=False
        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        480, 20, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        20, 480, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        480, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (19): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        960, 40, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        40, 960, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (20): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        960, 40, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        40, 960, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (21): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        960, 40, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        40, 960, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (22): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        960, 40, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        40, 960, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (23): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        960, 40, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        40, 960, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (24): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        960, 40, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        40, 960, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (25): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        960, 40, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        40, 960, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (26): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        960, 40, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        40, 960, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (27): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        960, 40, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        40, 960, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (28): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        960, 960, kernel_size=(5, 5), stride=[1, 1], groups=960, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        960, 40, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        40, 960, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        960, 224, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (29): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        1344, 56, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        56, 1344, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (30): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        1344, 56, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        56, 1344, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (31): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        1344, 56, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        56, 1344, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (32): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        1344, 56, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        56, 1344, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (33): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        1344, 56, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        56, 1344, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (34): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        1344, 56, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        56, 1344, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (35): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        1344, 56, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        56, 1344, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (36): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        1344, 56, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        56, 1344, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (37): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        1344, 56, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        56, 1344, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (38): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        1344, 1344, kernel_size=(5, 5), stride=[2, 2], groups=1344, bias=False
        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        1344, 56, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        56, 1344, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (39): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (40): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (41): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (42): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (43): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (44): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (45): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (46): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (47): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (48): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (49): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (50): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (51): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        2304, 2304, kernel_size=(3, 3), stride=[1, 1], groups=2304, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        2304, 96, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        96, 2304, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(640, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (52): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(3840, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        3840, 3840, kernel_size=(3, 3), stride=(1, 1), groups=3840, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(3840, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        3840, 160, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        160, 3840, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(640, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (53): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(3840, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        3840, 3840, kernel_size=(3, 3), stride=(1, 1), groups=3840, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(3840, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        3840, 160, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        160, 3840, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(640, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
    (54): MBConvBlock(
      (_expand_conv): Conv2dStaticSamePadding(
        640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn0): BatchNorm2d(3840, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_depthwise_conv): Conv2dStaticSamePadding(
        3840, 3840, kernel_size=(3, 3), stride=(1, 1), groups=3840, bias=False
        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
      )
      (_bn1): BatchNorm2d(3840, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_se_reduce): Conv2dStaticSamePadding(
        3840, 160, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_se_expand): Conv2dStaticSamePadding(
        160, 3840, kernel_size=(1, 1), stride=(1, 1)
        (static_padding): Identity()
      )
      (_project_conv): Conv2dStaticSamePadding(
        3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False
        (static_padding): Identity()
      )
      (_bn2): BatchNorm2d(640, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
      (_swish): MemoryEfficientSwish()
    )
  )
  (_conv_head): Conv2dStaticSamePadding(
    640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False
    (static_padding): Identity()
  )
  (_bn1): BatchNorm2d(2560, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)
  (_dropout): Dropout(p=0.5, inplace=False)
  (_fc): Linear(in_features=2560, out_features=6, bias=True)
  (_swish): MemoryEfficientSwish()
)
Using loss weight: [2, 1, 1, 1, 1, 1]
loss: BCEWithLogitsLoss
optim: Adam
dataset_policy: all
window_policy: 3
read dataset (533384 records)
applied dataset_policy all (533384 records)
use default(random) sampler
dataset_policy: all
window_policy: 3
read dataset (132030 records)
applied dataset_policy all (132030 records)
use default(random) sampler
train data: loaded 533384 records
valid data: loaded 132030 records
last_epoch: -1
apex True
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError("No module named 'amp_C'")

----- epoch 0 -----
[train] 1/33336 12(s) eta:400020(s) loss:0.803369 loss200:0.803369 lr:6.00e-05[train] 2/33336 13(s) eta:216671(s) loss:0.804448 loss200:0.804448 lr:6.00e-05[train] 3/33336 14(s) eta:155554(s) loss:0.795809 loss200:0.795809 lr:6.00e-05[train] 4/33336 15(s) eta:124995(s) loss:0.793765 loss200:0.793765 lr:6.00e-05[train] 5/33336 16(s) eta:106659(s) loss:0.793837 loss200:0.793837 lr:6.00e-05[train] 6/33336 17(s) eta:94435(s) loss:0.791719 loss200:0.791719 lr:6.00e-05[train] 7/33336 18(s) eta:85703(s) loss:0.789042 loss200:0.789042 lr:6.00e-05[train] 8/33336 18(s) eta:74988(s) loss:0.785084 loss200:0.785084 lr:6.00e-05[train] 9/33336 19(s) eta:70357(s) loss:0.782066 loss200:0.782066 lr:6.00e-05[train] 10/33336 20(s) eta:66652(s) loss:0.778277 loss200:0.778277 lr:6.00e-05[train] 11/33336 21(s) eta:63620(s) loss:0.776819 loss200:0.776819 lr:6.00e-05[train] 12/33336 22(s) eta:61094(s) loss:0.773831 loss200:0.773831 lr:6.00e-05[train] 13/33336 23(s) eta:58956(s) loss:0.770041 loss200:0.770041 lr:6.00e-05[train] 14/33336 24(s) eta:57123(s) loss:0.768456 loss200:0.768456 lr:6.00e-05[train] 15/33336 25(s) eta:55535(s) loss:0.764715 loss200:0.764715 lr:6.00e-05[train] 16/33336 25(s) eta:52062(s) loss:0.762732 loss200:0.762732 lr:6.00e-05[train] 17/33336 26(s) eta:50958(s) loss:0.759618 loss200:0.759618 lr:6.00e-05[train] 18/33336 27(s) eta:49977(s) loss:0.756213 loss200:0.756213 lr:6.00e-05[train] 19/33336 28(s) eta:49098(s) loss:0.753001 loss200:0.753001 lr:6.00e-05[train] 20/33336 29(s) eta:48308(s) loss:0.749911 loss200:0.749911 lr:6.00e-05[train] 21/33336 30(s) eta:47592(s) loss:0.746530 loss200:0.746530 lr:6.00e-05[train] 22/33336 31(s) eta:46942(s) loss:0.743311 loss200:0.743311 lr:6.00e-05[train] 23/33336 32(s) eta:46348(s) loss:0.739077 loss200:0.739077 lr:6.00e-05[train] 24/33336 32(s) eta:44416(s) loss:0.736368 loss200:0.736368 lr:6.00e-05[train] 25/33336 33(s) eta:43970(s) loss:0.732769 loss200:0.732769 lr:6.00e-05[train] 26/33336 34(s) eta:43559(s) loss:0.729759 loss200:0.729759 lr:6.00e-05[train] 27/33336 35(s) eta:43178(s) loss:0.726128 loss200:0.726128 lr:6.00e-05[train] 28/33336 36(s) eta:42824(s) loss:0.723072 loss200:0.723072 lr:6.00e-05[train] 29/33336 37(s) eta:42495(s) loss:0.719638 loss200:0.719638 lr:6.00e-05[train] 30/33336 38(s) eta:42187(s) loss:0.716173 loss200:0.716173 lr:6.00e-05[train] 31/33336 39(s) eta:41899(s) loss:0.714398 loss200:0.714398 lr:6.00e-05[train] 32/33336 40(s) eta:41630(s) loss:0.710442 loss200:0.710442 lr:6.00e-05[train] 33/33336 40(s) eta:40367(s) loss:0.706774 loss200:0.706774 lr:6.00e-05[train] 34/33336 41(s) eta:40158(s) loss:0.703799 loss200:0.703799 lr:6.00e-05[train] 35/33336 42(s) eta:39961(s) loss:0.701023 loss200:0.701023 lr:6.00e-05[train] 36/33336 43(s) eta:39775(s) loss:0.697643 loss200:0.697643 lr:6.00e-05[train] 37/33336 44(s) eta:39598(s) loss:0.693463 loss200:0.693463 lr:6.00e-05[train] 38/33336 45(s) eta:39431(s) loss:0.690698 loss200:0.690698 lr:6.00e-05[train] 39/33336 46(s) eta:39273(s) loss:0.686375 loss200:0.686375 lr:6.00e-05[train] 40/33336 47(s) eta:39122(s) loss:0.683866 loss200:0.683866 lr:6.00e-05[train] 41/33336 48(s) eta:38979(s) loss:0.680529 loss200:0.680529 lr:6.00e-05[train] 42/33336 48(s) eta:38050(s) loss:0.676607 loss200:0.676607 lr:6.00e-05[train] 43/33336 49(s) eta:37938(s) loss:0.672949 loss200:0.672949 lr:6.00e-05[train] 44/33336 50(s) eta:37831(s) loss:0.670060 loss200:0.670060 lr:6.00e-05[train] 45/33336 51(s) eta:37729(s) loss:0.665505 loss200:0.665505 lr:6.00e-05[train] 46/33336 52(s) eta:37632(s) loss:0.661732 loss200:0.661732 lr:6.00e-05[train] 47/33336 53(s) eta:37538(s) loss:0.657837 loss200:0.657837 lr:6.00e-05[train] 48/33336 54(s) eta:37449(s) loss:0.655301 loss200:0.655301 lr:6.00e-05[train] 49/33336 55(s) eta:37362(s) loss:0.650893 loss200:0.650893 lr:6.00e-05[train] 50/33336 55(s) eta:36614(s) loss:0.646576 loss200:0.646576 lr:6.00e-05[train] 51/33336 56(s) eta:36548(s) loss:0.643250 loss200:0.643250 lr:6.00e-05[train] 52/33336 57(s) eta:36484(s) loss:0.639260 loss200:0.639260 lr:6.00e-05[train] 53/33336 58(s) eta:36422(s) loss:0.634733 loss200:0.634733 lr:6.00e-05[train] 54/33336 59(s) eta:36363(s) loss:0.630961 loss200:0.630961 lr:6.00e-05[train] 55/33336 60(s) eta:36306(s) loss:0.627572 loss200:0.627572 lr:6.00e-05[train] 56/33336 61(s) eta:36251(s) loss:0.623986 loss200:0.623986 lr:6.00e-05[train] 57/33336 62(s) eta:36198(s) loss:0.620594 loss200:0.620594 lr:6.00e-05[train] 58/33336 63(s) eta:36146(s) loss:0.615806 loss200:0.615806 lr:6.00e-05[train] 59/33336 64(s) eta:36097(s) loss:0.611320 loss200:0.611320 lr:6.00e-05[train] 60/33336 64(s) eta:35494(s) loss:0.606993 loss200:0.606993 lr:6.00e-05[train] 61/33336 65(s) eta:35456(s) loss:0.602641 loss200:0.602641 lr:6.00e-05[train] 62/33336 66(s) eta:35420(s) loss:0.599887 loss200:0.599887 lr:6.00e-05[train] 63/33336 67(s) eta:35385(s) loss:0.595193 loss200:0.595193 lr:6.00e-05[train] 64/33336 68(s) eta:35351(s) loss:0.593528 loss200:0.593528 lr:6.00e-05[train] 65/33336 69(s) eta:35318(s) loss:0.593523 loss200:0.593523 lr:6.00e-05[train] 66/33336 70(s) eta:35286(s) loss:0.590738 loss200:0.590738 lr:6.00e-05[train] 67/33336 70(s) eta:34758(s) loss:0.588414 loss200:0.588414 lr:6.00e-05[train] 68/33336 71(s) eta:34735(s) loss:0.587160 loss200:0.587160 lr:6.00e-05[train] 69/33336 72(s) eta:34713(s) loss:0.583396 loss200:0.583396 lr:6.00e-05[train] 70/33336 73(s) eta:34691(s) loss:0.579093 loss200:0.579093 lr:6.00e-05[train] 71/33336 74(s) eta:34670(s) loss:0.574724 loss200:0.574724 lr:6.00e-05[train] 72/33336 75(s) eta:34650(s) loss:0.571374 loss200:0.571374 lr:6.00e-05[train] 73/33336 76(s) eta:34629(s) loss:0.567870 loss200:0.567870 lr:6.00e-05[train] 74/33336 77(s) eta:34610(s) loss:0.565473 loss200:0.565473 lr:6.00e-05[train] 75/33336 77(s) eta:34147(s) loss:0.561979 loss200:0.561979 lr:6.00e-05[train] 76/33336 78(s) eta:34135(s) loss:0.558064 loss200:0.558064 lr:6.00e-05[train] 77/33336 79(s) eta:34122(s) loss:0.554585 loss200:0.554585 lr:6.00e-05[train] 78/33336 80(s) eta:34110(s) loss:0.550498 loss200:0.550498 lr:6.00e-05[train] 79/33336 81(s) eta:34098(s) loss:0.547150 loss200:0.547150 lr:6.00e-05[train] 80/33336 82(s) eta:34087(s) loss:0.544436 loss200:0.544436 lr:6.00e-05[train] 81/33336 83(s) eta:34076(s) loss:0.541229 loss200:0.541229 lr:6.00e-05[train] 82/33336 83(s) eta:33659(s) loss:0.538658 loss200:0.538658 lr:6.00e-05[train] 83/33336 84(s) eta:33653(s) loss:0.535894 loss200:0.535894 lr:6.00e-05[train] 84/33336 85(s) eta:33647(s) loss:0.534030 loss200:0.534030 lr:6.00e-05[train] 85/33336 86(s) eta:33642(s) loss:0.530944 loss200:0.530944 lr:6.00e-05[train] 86/33336 87(s) eta:33636(s) loss:0.529678 loss200:0.529678 lr:6.00e-05[train] 87/33336 88(s) eta:33631(s) loss:0.526569 loss200:0.526569 lr:6.00e-05[train] 88/33336 89(s) eta:33625(s) loss:0.522780 loss200:0.522780 lr:6.00e-05[train] 89/33336 89(s) eta:33247(s) loss:0.520021 loss200:0.520021 lr:6.00e-05[train] 90/33336 90(s) eta:33246(s) loss:0.518463 loss200:0.518463 lr:6.00e-05[train] 91/33336 91(s) eta:33245(s) loss:0.515450 loss200:0.515450 lr:6.00e-05[train] 92/33336 92(s) eta:33244(s) loss:0.514145 loss200:0.514145 lr:6.00e-05[train] 93/33336 93(s) eta:33243(s) loss:0.511009 loss200:0.511009 lr:6.00e-05[train] 94/33336 94(s) eta:33242(s) loss:0.509620 loss200:0.509620 lr:6.00e-05[train] 95/33336 95(s) eta:33241(s) loss:0.508470 loss200:0.508470 lr:6.00e-05[train] 96/33336 96(s) eta:33240(s) loss:0.506078 loss200:0.506078 lr:6.00e-05[train] 97/33336 96(s) eta:32896(s) loss:0.503551 loss200:0.503551 lr:6.00e-05[train] 98/33336 97(s) eta:32898(s) loss:0.502176 loss200:0.502176 lr:6.00e-05[train] 99/33336 98(s) eta:32901(s) loss:0.499813 loss200:0.499813 lr:6.00e-05[train] 100/33336 99(s) eta:32903(s) loss:0.497740 loss200:0.497740 lr:6.00e-05[train] 101/33336 100(s) eta:32905(s) loss:0.495182 loss200:0.495182 lr:6.00e-05[train] 102/33336 101(s) eta:32908(s) loss:0.493294 loss200:0.493294 lr:6.00e-05[train] 103/33336 102(s) eta:32910(s) loss:0.490792 loss200:0.490792 lr:6.00e-05[train] 104/33336 103(s) eta:32912(s) loss:0.488929 loss200:0.488929 lr:6.00e-05[train] 105/33336 103(s) eta:32598(s) loss:0.487071 loss200:0.487071 lr:6.00e-05[train] 106/33336 104(s) eta:32603(s) loss:0.485107 loss200:0.485107 lr:6.00e-05[train] 107/33336 105(s) eta:32607(s) loss:0.484490 loss200:0.484490 lr:6.00e-05[train] 108/33336 106(s) eta:32612(s) loss:0.482234 loss200:0.482234 lr:6.00e-05[train] 109/33336 107(s) eta:32617(s) loss:0.480456 loss200:0.480456 lr:6.00e-05[train] 110/33336 108(s) eta:32621(s) loss:0.477429 loss200:0.477429 lr:6.00e-05[train] 111/33336 109(s) eta:32626(s) loss:0.475537 loss200:0.475537 lr:6.00e-05[train] 112/33336 110(s) eta:32630(s) loss:0.472823 loss200:0.472823 lr:6.00e-05[train] 113/33336 110(s) eta:32340(s) loss:0.470854 loss200:0.470854 lr:6.00e-05[train] 114/33336 111(s) eta:32347(s) loss:0.469132 loss200:0.469132 lr:6.00e-05[train] 115/33336 112(s) eta:32354(s) loss:0.466997 loss200:0.466997 lr:6.00e-05[train] 116/33336 113(s) eta:32360(s) loss:0.464712 loss200:0.464712 lr:6.00e-05[train] 117/33336 114(s) eta:32367(s) loss:0.462642 loss200:0.462642 lr:6.00e-05[train] 118/33336 115(s) eta:32373(s) loss:0.461140 loss200:0.461140 lr:6.00e-05[train] 119/33336 116(s) eta:32379(s) loss:0.460719 loss200:0.460719 lr:6.00e-05[train] 120/33336 117(s) eta:32385(s) loss:0.458836 loss200:0.458836 lr:6.00e-05[train] 121/33336 117(s) eta:32116(s) loss:0.457471 loss200:0.457471 lr:6.00e-05[train] 122/33336 118(s) eta:32125(s) loss:0.455177 loss200:0.455177 lr:6.00e-05[train] 123/33336 119(s) eta:32132(s) loss:0.453737 loss200:0.453737 lr:6.00e-05[train] 124/33336 120(s) eta:32140(s) loss:0.451601 loss200:0.451601 lr:6.00e-05[train] 125/33336 121(s) eta:32148(s) loss:0.449530 loss200:0.449530 lr:6.00e-05[train] 126/33336 122(s) eta:32155(s) loss:0.447559 loss200:0.447559 lr:6.00e-05[train] 127/33336 123(s) eta:32163(s) loss:0.445985 loss200:0.445985 lr:6.00e-05[train] 128/33336 124(s) eta:32170(s) loss:0.444077 loss200:0.444077 lr:6.00e-05[train] 129/33336 124(s) eta:31919(s) loss:0.444406 loss200:0.444406 lr:6.00e-05[train] 130/33336 125(s) eta:31928(s) loss:0.443394 loss200:0.443394 lr:6.00e-05[train] 131/33336 126(s) eta:31937(s) loss:0.441220 loss200:0.441220 lr:6.00e-05[train] 132/33336 127(s) eta:31946(s) loss:0.439745 loss200:0.439745 lr:6.00e-05[train] 133/33336 128(s) eta:31954(s) loss:0.438100 loss200:0.438100 lr:6.00e-05[train] 134/33336 129(s) eta:31963(s) loss:0.436476 loss200:0.436476 lr:6.00e-05[train] 135/33336 130(s) eta:31971(s) loss:0.436183 loss200:0.436183 lr:6.00e-05[train] 136/33336 131(s) eta:31979(s) loss:0.436502 loss200:0.436502 lr:6.00e-05[train] 137/33336 132(s) eta:31987(s) loss:0.434687 loss200:0.434687 lr:6.00e-05[train] 138/33336 132(s) eta:31754(s) loss:0.432671 loss200:0.432671 lr:6.00e-05[train] 139/33336 133(s) eta:31764(s) loss:0.431132 loss200:0.431132 lr:6.00e-05[train] 140/33336 134(s) eta:31773(s) loss:0.429183 loss200:0.429183 lr:6.00e-05[train] 141/33336 135(s) eta:31782(s) loss:0.428536 loss200:0.428536 lr:6.00e-05[train] 142/33336 136(s) eta:31791(s) loss:0.426709 loss200:0.426709 lr:6.00e-05[train] 143/33336 137(s) eta:31800(s) loss:0.425119 loss200:0.425119 lr:6.00e-05[train] 144/33336 138(s) eta:31809(s) loss:0.424184 loss200:0.424184 lr:6.00e-05[train] 145/33336 139(s) eta:31817(s) loss:0.422610 loss200:0.422610 lr:6.00e-05[train] 146/33336 139(s) eta:31598(s) loss:0.422208 loss200:0.422208 lr:6.00e-05[train] 147/33336 140(s) eta:31608(s) loss:0.421726 loss200:0.421726 lr:6.00e-05[train] 148/33336 141(s) eta:31618(s) loss:0.420324 loss200:0.420324 lr:6.00e-05[train] 149/33336 142(s) eta:31627(s) loss:0.419317 loss200:0.419317 lr:6.00e-05[train] 150/33336 143(s) eta:31637(s) loss:0.417756 loss200:0.417756 lr:6.00e-05[train] 151/33336 144(s) eta:31646(s) loss:0.416332 loss200:0.416332 lr:6.00e-05[train] 152/33336 145(s) eta:31655(s) loss:0.415059 loss200:0.415059 lr:6.00e-05[train] 153/33336 146(s) eta:31664(s) loss:0.414640 loss200:0.414640 lr:6.00e-05[train] 154/33336 146(s) eta:31458(s) loss:0.413371 loss200:0.413371 lr:6.00e-05[train] 155/33336 147(s) eta:31468(s) loss:0.414051 loss200:0.414051 lr:6.00e-05[train] 156/33336 148(s) eta:31478(s) loss:0.412974 loss200:0.412974 lr:6.00e-05[train] 157/33336 149(s) eta:31488(s) loss:0.411403 loss200:0.411403 lr:6.00e-05[train] 158/33336 150(s) eta:31498(s) loss:0.410662 loss200:0.410662 lr:6.00e-05[train] 159/33336 151(s) eta:31507(s) loss:0.410002 loss200:0.410002 lr:6.00e-05[train] 160/33336 152(s) eta:31517(s) loss:0.408280 loss200:0.408280 lr:6.00e-05[train] 161/33336 152(s) eta:31320(s) loss:0.406872 loss200:0.406872 lr:6.00e-05[train] 162/33336 153(s) eta:31331(s) loss:0.405550 loss200:0.405550 lr:6.00e-05[train] 163/33336 154(s) eta:31341(s) loss:0.404338 loss200:0.404338 lr:6.00e-05[train] 164/33336 155(s) eta:31351(s) loss:0.403515 loss200:0.403515 lr:6.00e-05[train] 165/33336 156(s) eta:31361(s) loss:0.403564 loss200:0.403564 lr:6.00e-05[train] 166/33336 157(s) eta:31371(s) loss:0.401935 loss200:0.401935 lr:6.00e-05[train] 167/33336 158(s) eta:31381(s) loss:0.401344 loss200:0.401344 lr:6.00e-05[train] 168/33336 159(s) eta:31391(s) loss:0.400010 loss200:0.400010 lr:6.00e-05[train] 169/33336 159(s) eta:31204(s) loss:0.398583 loss200:0.398583 lr:6.00e-05[train] 170/33336 160(s) eta:31215(s) loss:0.397728 loss200:0.397728 lr:6.00e-05[train] 171/33336 161(s) eta:31225(s) loss:0.396658 loss200:0.396658 lr:6.00e-05[train] 172/33336 162(s) eta:31235(s) loss:0.395876 loss200:0.395876 lr:6.00e-05[train] 173/33336 163(s) eta:31246(s) loss:0.395783 loss200:0.395783 lr:6.00e-05[train] 174/33336 164(s) eta:31256(s) loss:0.394135 loss200:0.394135 lr:6.00e-05Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
[train] 175/33336 164(s) eta:31076(s) loss:0.394913 loss200:0.394913 lr:6.00e-05[train] 176/33336 165(s) eta:31087(s) loss:0.394109 loss200:0.394109 lr:6.00e-05[train] 177/33336 166(s) eta:31098(s) loss:0.392832 loss200:0.392832 lr:6.00e-05[train] 178/33336 167(s) eta:31108(s) loss:0.392170 loss200:0.392170 lr:6.00e-05[train] 179/33336 168(s) eta:31119(s) loss:0.391332 loss200:0.391332 lr:6.00e-05[train] 180/33336 169(s) eta:31129(s) loss:0.391327 loss200:0.391327 lr:6.00e-05[train] 181/33336 170(s) eta:31140(s) loss:0.389915 loss200:0.389915 lr:6.00e-05[train] 182/33336 171(s) eta:31150(s) loss:0.388647 loss200:0.388647 lr:6.00e-05[train] 183/33336 171(s) eta:30979(s) loss:0.387329 loss200:0.387329 lr:6.00e-05[train] 184/33336 172(s) eta:30989(s) loss:0.386477 loss200:0.386477 lr:6.00e-05[train] 185/33336 173(s) eta:31000(s) loss:0.385721 loss200:0.385721 lr:6.00e-05[train] 186/33336 174(s) eta:31011(s) loss:0.384401 loss200:0.384401 lr:6.00e-05[train] 187/33336 175(s) eta:31021(s) loss:0.383096 loss200:0.383096 lr:6.00e-05[train] 188/33336 176(s) eta:31032(s) loss:0.381580 loss200:0.381580 lr:6.00e-05[train] 189/33336 177(s) eta:31042(s) loss:0.380158 loss200:0.380158 lr:6.00e-05[train] 190/33336 178(s) eta:31052(s) loss:0.378944 loss200:0.378944 lr:6.00e-05[train] 191/33336 178(s) eta:30889(s) loss:0.377711 loss200:0.377711 lr:6.00e-05[train] 192/33336 179(s) eta:30899(s) loss:0.376451 loss200:0.376451 lr:6.00e-05[train] 193/33336 180(s) eta:30910(s) loss:0.376835 loss200:0.376835 lr:6.00e-05[train] 194/33336 181(s) eta:30921(s) loss:0.375654 loss200:0.375654 lr:6.00e-05[train] 195/33336 182(s) eta:30931(s) loss:0.374795 loss200:0.374795 lr:6.00e-05[train] 196/33336 183(s) eta:30941(s) loss:0.373894 loss200:0.373894 lr:6.00e-05[train] 197/33336 184(s) eta:30952(s) loss:0.372932 loss200:0.372932 lr:6.00e-05[train] 198/33336 185(s) eta:30962(s) loss:0.371974 loss200:0.371974 lr:6.00e-05[train] 199/33336 186(s) eta:30972(s) loss:0.371595 loss200:0.371595 lr:6.00e-05[train] 200/33336 186(s) eta:30816(s) loss:0.370256 loss200:0.370256 lr:6.00e-05[train] 201/33336 187(s) eta:30827(s) loss:0.369796 loss200:0.367629 lr:6.00e-05[train] 202/33336 188(s) eta:30837(s) loss:0.368997 loss200:0.364643 lr:6.00e-05[train] 203/33336 189(s) eta:30847(s) loss:0.367901 loss200:0.361482 lr:6.00e-05[train] 204/33336 190(s) eta:30858(s) loss:0.367470 loss200:0.358944 lr:6.00e-05[train] 205/33336 191(s) eta:30868(s) loss:0.366858 loss200:0.356183 lr:6.00e-05[train] 206/33336 192(s) eta:30878(s) loss:0.367505 loss200:0.354779 lr:6.00e-05[train] 207/33336 192(s) eta:30728(s) loss:0.366302 loss200:0.351506 lr:6.00e-05[train] 208/33336 193(s) eta:30738(s) loss:0.365818 loss200:0.349048 lr:6.00e-05[train] 209/33336 194(s) eta:30749(s) loss:0.365443 loss200:0.346695 lr:6.00e-05[train] 210/33336 195(s) eta:30759(s) loss:0.364247 loss200:0.343546 lr:6.00e-05[train] 211/33336 196(s) eta:30770(s) loss:0.363128 loss200:0.340375 lr:6.00e-05[train] 212/33336 197(s) eta:30780(s) loss:0.364060 loss200:0.339473 lr:6.00e-05[train] 213/33336 198(s) eta:30790(s) loss:0.363275 loss200:0.336835 lr:6.00e-05[train] 214/33336 199(s) eta:30800(s) loss:0.362471 loss200:0.334052 lr:6.00e-05[train] 215/33336 199(s) eta:30656(s) loss:0.362515 loss200:0.332350 lr:6.00e-05[train] 216/33336 200(s) eta:30666(s) loss:0.361539 loss200:0.329443 lr:6.00e-05[train] 217/33336 201(s) eta:30677(s) loss:0.360876 loss200:0.326983 lr:6.00e-05[train] 218/33336 202(s) eta:30687(s) loss:0.359831 loss200:0.324157 lr:6.00e-05[train] 219/33336 203(s) eta:30697(s) loss:0.359122 loss200:0.321704 lr:6.00e-05[train] 220/33336 204(s) eta:30707(s) loss:0.358480 loss200:0.319337 lr:6.00e-05[train] 221/33336 205(s) eta:30717(s) loss:0.357485 loss200:0.316635 lr:6.00e-05[train] 222/33336 206(s) eta:30727(s) loss:0.356873 loss200:0.314364 lr:6.00e-05[train] 223/33336 206(s) eta:30588(s) loss:0.355797 loss200:0.311720 lr:6.00e-05[train] 224/33336 207(s) eta:30599(s) loss:0.355631 loss200:0.309943 lr:6.00e-05[train] 225/33336 208(s) eta:30609(s) loss:0.354616 loss200:0.307347 lr:6.00e-05[train] 226/33336 209(s) eta:30619(s) loss:0.354170 loss200:0.305343 lr:6.00e-05[train] 227/33336 210(s) eta:30629(s) loss:0.353087 loss200:0.302727 lr:6.00e-05[train] 228/33336 211(s) eta:30639(s) loss:0.352278 loss200:0.300367 lr:6.00e-05[train] 229/33336 212(s) eta:30649(s) loss:0.351452 loss200:0.298065 lr:6.00e-05[train] 230/33336 213(s) eta:30659(s) loss:0.351066 loss200:0.296300 lr:6.00e-05[train] 231/33336 213(s) eta:30525(s) loss:0.350583 loss200:0.294192 lr:6.00e-05[train] 232/33336 214(s) eta:30535(s) loss:0.349989 loss200:0.292316 lr:6.00e-05[train] 233/33336 215(s) eta:30545(s) loss:0.349190 loss200:0.290189 lr:6.00e-05[train] 234/33336 216(s) eta:30555(s) loss:0.349124 loss200:0.288830 lr:6.00e-05[train] 235/33336 217(s) eta:30565(s) loss:0.348714 loss200:0.287060 lr:6.00e-05[train] 236/33336 218(s) eta:30575(s) loss:0.348590 loss200:0.285761 lr:6.00e-05[train] 237/33336 219(s) eta:30585(s) loss:0.347674 loss200:0.283703 lr:6.00e-05[train] 238/33336 220(s) eta:30594(s) loss:0.347188 loss200:0.281921 lr:6.00e-05[train] 239/33336 221(s) eta:30604(s) loss:0.346320 loss200:0.280009 lr:6.00e-05[train] 240/33336 221(s) eta:30475(s) loss:0.345955 loss200:0.278373 lr:6.00e-05[train] 241/33336 222(s) eta:30485(s) loss:0.345700 loss200:0.277060 lr:6.00e-05[train] 242/33336 223(s) eta:30495(s) loss:0.345411 loss200:0.275860 lr:6.00e-05[train] 243/33336 224(s) eta:30505(s) loss:0.344996 loss200:0.274486 lr:6.00e-05[train] 244/33336 225(s) eta:30515(s) loss:0.344142 loss200:0.272441 lr:6.00e-05[train] 245/33336 226(s) eta:30524(s) loss:0.343306 loss200:0.270811 lr:6.00e-05[train] 246/33336 227(s) eta:30534(s) loss:0.342402 loss200:0.268956 lr:6.00e-05[train] 247/33336 228(s) eta:30543(s) loss:0.341864 loss200:0.267610 lr:6.00e-05[train] 248/33336 228(s) eta:30419(s) loss:0.342000 loss200:0.266808 lr:6.00e-05[train] 249/33336 229(s) eta:30429(s) loss:0.341122 loss200:0.265229 lr:6.00e-05[train] 250/33336 230(s) eta:30439(s) loss:0.341202 loss200:0.264859 lr:6.00e-05[train] 251/33336 231(s) eta:30448(s) loss:0.340503 loss200:0.263302 lr:6.00e-05[train] 252/33336 232(s) eta:30458(s) loss:0.339696 loss200:0.261809 lr:6.00e-05[train] 253/33336 233(s) eta:30467(s) loss:0.339502 loss200:0.261265 lr:6.00e-05[train] 254/33336 234(s) eta:30477(s) loss:0.338917 loss200:0.260065 lr:6.00e-05[train] 255/33336 235(s) eta:30486(s) loss:0.338027 loss200:0.258402 lr:6.00e-05[train] 256/33336 236(s) eta:30495(s) loss:0.337415 loss200:0.257175 lr:6.00e-05[train] 257/33336 236(s) eta:30376(s) loss:0.336772 loss200:0.255883 lr:6.00e-05[train] 258/33336 237(s) eta:30385(s) loss:0.335836 loss200:0.254644 lr:6.00e-05[train] 259/33336 238(s) eta:30395(s) loss:0.334861 loss200:0.253305 lr:6.00e-05[train] 260/33336 239(s) eta:30404(s) loss:0.334651 loss200:0.252949 lr:6.00e-05[train] 261/33336 240(s) eta:30413(s) loss:0.334377 loss200:0.252556 lr:6.00e-05[train] 262/33336 241(s) eta:30423(s) loss:0.334346 loss200:0.252029 lr:6.00e-05[train] 263/33336 242(s) eta:30432(s) loss:0.333544 loss200:0.251125 lr:6.00e-05[train] 264/33336 243(s) eta:30441(s) loss:0.333092 loss200:0.249752 lr:6.00e-05[train] 265/33336 244(s) eta:30450(s) loss:0.332745 loss200:0.247993 lr:6.00e-05[train] 266/33336 245(s) eta:30459(s) loss:0.332146 loss200:0.246811 lr:6.00e-05[train] 267/33336 245(s) eta:30344(s) loss:0.331239 loss200:0.245086 lr:6.00e-05[train] 268/33336 246(s) eta:30353(s) loss:0.331127 loss200:0.244076 lr:6.00e-05[train] 269/33336 247(s) eta:30362(s) loss:0.330862 loss200:0.243738 lr:6.00e-05[train] 270/33336 248(s) eta:30371(s) loss:0.330036 loss200:0.242866 lr:6.00e-05[train] 271/33336 249(s) eta:30380(s) loss:0.329686 loss200:0.242697 lr:6.00e-05[train] 272/33336 250(s) eta:30389(s) loss:0.329341 loss200:0.242209 lr:6.00e-05[train] 273/33336 251(s) eta:30398(s) loss:0.328521 loss200:0.241159 lr:6.00e-05[train] 274/33336 252(s) eta:30407(s) loss:0.327685 loss200:0.239704 lr:6.00e-05[train] 275/33336 253(s) eta:30416(s) loss:0.326897 loss200:0.238741 lr:6.00e-05[train] 276/33336 253(s) eta:30305(s) loss:0.326041 loss200:0.237872 lr:6.00e-05[train] 277/33336 254(s) eta:30314(s) loss:0.325652 loss200:0.237513 lr:6.00e-05[train] 278/33336 255(s) eta:30322(s) loss:0.325061 loss200:0.237141 lr:6.00e-05[train] 279/33336 256(s) eta:30331(s) loss:0.324972 loss200:0.237211 lr:6.00e-05[train] 280/33336 257(s) eta:30340(s) loss:0.324304 loss200:0.236251 lr:6.00e-05[train] 281/33336 258(s) eta:30349(s) loss:0.323473 loss200:0.235281 lr:6.00e-05[train] 282/33336 259(s) eta:30358(s) loss:0.323325 loss200:0.235038 lr:6.00e-05[train] 283/33336 259(s) eta:30249(s) loss:0.322863 loss200:0.234455 lr:6.00e-05[train] 284/33336 260(s) eta:30258(s) loss:0.322163 loss200:0.233179 lr:6.00e-05[train] 285/33336 261(s) eta:30267(s) loss:0.321316 loss200:0.232224 lr:6.00e-05[train] 286/33336 262(s) eta:30276(s) loss:0.320614 loss200:0.230716 lr:6.00e-05[train] 287/33336 263(s) eta:30285(s) loss:0.319893 loss200:0.229989 lr:6.00e-05[train] 288/33336 264(s) eta:30294(s) loss:0.319380 loss200:0.229884 lr:6.00e-05[train] 289/33336 265(s) eta:30302(s) loss:0.318620 loss200:0.228997 lr:6.00e-05[train] 290/33336 266(s) eta:30311(s) loss:0.318204 loss200:0.228087 lr:6.00e-05[train] 291/33336 266(s) eta:30206(s) loss:0.318448 loss200:0.228812 lr:6.00e-05[train] 292/33336 267(s) eta:30214(s) loss:0.317709 loss200:0.227349 lr:6.00e-05[train] 293/33336 268(s) eta:30223(s) loss:0.317274 loss200:0.227186 lr:6.00e-05[train] 294/33336 269(s) eta:30232(s) loss:0.316872 loss200:0.226280 lr:6.00e-05[train] 295/33336 270(s) eta:30240(s) loss:0.316178 loss200:0.224840 lr:6.00e-05[train] 296/33336 271(s) eta:30249(s) loss:0.315961 loss200:0.224704 lr:6.00e-05[train] 297/33336 272(s) eta:30257(s) loss:0.315401 loss200:0.224148 lr:6.00e-05[train] 298/33336 273(s) eta:30266(s) loss:0.314686 loss200:0.222816 lr:6.00e-05[train] 299/33336 274(s) eta:30274(s) loss:0.314579 loss200:0.222889 lr:6.00e-05[train] 300/33336 274(s) eta:30172(s) loss:0.314169 loss200:0.222384 lr:6.00e-05[train] 301/33336 275(s) eta:30181(s) loss:0.313540 loss200:0.221811 lr:6.00e-05[train] 302/33336 276(s) eta:30190(s) loss:0.313027 loss200:0.221091 lr:6.00e-05[train] 303/33336 277(s) eta:30198(s) loss:0.312291 loss200:0.220364 lr:6.00e-05[train] 304/33336 278(s) eta:30206(s) loss:0.312316 loss200:0.220477 lr:6.00e-05[train] 305/33336 279(s) eta:30215(s) loss:0.311729 loss200:0.219674 lr:6.00e-05[train] 306/33336 280(s) eta:30223(s) loss:0.311531 loss200:0.219536 lr:6.00e-05[train] 307/33336 280(s) eta:30124(s) loss:0.310954 loss200:0.218113 lr:6.00e-05[train] 308/33336 281(s) eta:30132(s) loss:0.310710 loss200:0.218087 lr:6.00e-05[train] 309/33336 282(s) eta:30141(s) loss:0.310234 loss200:0.217463 lr:6.00e-05[train] 310/33336 283(s) eta:30149(s) loss:0.310267 loss200:0.218329 lr:6.00e-05[train] 311/33336 284(s) eta:30157(s) loss:0.309682 loss200:0.217632 lr:6.00e-05[train] 312/33336 285(s) eta:30166(s) loss:0.309215 loss200:0.217594 lr:6.00e-05[train] 313/33336 286(s) eta:30174(s) loss:0.308641 loss200:0.216991 lr:6.00e-05[train] 314/33336 287(s) eta:30182(s) loss:0.307978 loss200:0.216120 lr:6.00e-05[train] 315/33336 287(s) eta:30085(s) loss:0.307616 loss200:0.215972 lr:6.00e-05[train] 316/33336 288(s) eta:30094(s) loss:0.307385 loss200:0.216136 lr:6.00e-05[train] 317/33336 289(s) eta:30102(s) loss:0.306747 loss200:0.215549 lr:6.00e-05[train] 318/33336 290(s) eta:30110(s) loss:0.306147 loss200:0.214701 lr:6.00e-05[train] 319/33336 291(s) eta:30118(s) loss:0.305854 loss200:0.213709 lr:6.00e-05[train] 320/33336 292(s) eta:30127(s) loss:0.306260 loss200:0.214715 lr:6.00e-05[train] 321/33336 293(s) eta:30135(s) loss:0.305705 loss200:0.213887 lr:6.00e-05[train] 322/33336 294(s) eta:30143(s) loss:0.305510 loss200:0.214214 lr:6.00e-05[train] 323/33336 295(s) eta:30151(s) loss:0.305511 loss200:0.214353 lr:6.00e-05[train] 324/33336 295(s) eta:30057(s) loss:0.305053 loss200:0.214193 lr:6.00e-05[train] 325/33336 296(s) eta:30065(s) loss:0.304626 loss200:0.214061 lr:6.00e-05[train] 326/33336 297(s) eta:30073(s) loss:0.304192 loss200:0.213871 lr:6.00e-05[train] 327/33336 298(s) eta:30081(s) loss:0.303742 loss200:0.213418 lr:6.00e-05[train] 328/33336 299(s) eta:30089(s) loss:0.303016 loss200:0.212737 lr:6.00e-05[train] 329/33336 300(s) eta:30097(s) loss:0.303105 loss200:0.211966 lr:6.00e-05[train] 330/33336 301(s) eta:30105(s) loss:0.303545 loss200:0.212643 lr:6.00e-05[train] 331/33336 302(s) eta:30113(s) loss:0.303527 loss200:0.213338 lr:6.00e-05[train] 332/33336 303(s) eta:30121(s) loss:0.303248 loss200:0.213159 lr:6.00e-05[train] 333/33336 303(s) eta:30029(s) loss:0.303072 loss200:0.213279 lr:6.00e-05[train] 334/33336 304(s) eta:30037(s) loss:0.302478 loss200:0.212700 lr:6.00e-05[train] 335/33336 305(s) eta:30045(s) loss:0.301797 loss200:0.211086 lr:6.00e-05[train] 336/33336 306(s) eta:30053(s) loss:0.301721 loss200:0.210070 lr:6.00e-05[train] 337/33336 307(s) eta:30061(s) loss:0.301094 loss200:0.209583 lr:6.00e-05[train] 338/33336 308(s) eta:30069(s) loss:0.300585 loss200:0.209445 lr:6.00e-05[train] 339/33336 309(s) eta:30076(s) loss:0.300062 loss200:0.208969 lr:6.00e-05[train] 340/33336 309(s) eta:29987(s) loss:0.299975 loss200:0.209529 lr:6.00e-05[train] 341/33336 310(s) eta:29995(s) loss:0.299404 loss200:0.208366 lr:6.00e-05[train] 342/33336 311(s) eta:30003(s) loss:0.298836 loss200:0.208046 lr:6.00e-05[train] 343/33336 312(s) eta:30011(s) loss:0.298380 loss200:0.207762 lr:6.00e-05[train] 344/33336 313(s) eta:30018(s) loss:0.298031 loss200:0.207202 lr:6.00e-05[train] 345/33336 314(s) eta:30026(s) loss:0.297507 loss200:0.206807 lr:6.00e-05[train] 346/33336 315(s) eta:30034(s) loss:0.297153 loss200:0.205862 lr:6.00e-05[train] 347/33336 316(s) eta:30041(s) loss:0.296781 loss200:0.204946 lr:6.00e-05[train] 348/33336 316(s) eta:29954(s) loss:0.296413 loss200:0.204719 lr:6.00e-05[train] 349/33336 317(s) eta:29962(s) loss:0.295863 loss200:0.203890 lr:6.00e-05[train] 350/33336 318(s) eta:29970(s) loss:0.295440 loss200:0.203703 lr:6.00e-05[train] 351/33336 319(s) eta:29977(s) loss:0.295549 loss200:0.204358 lr:6.00e-05[train] 352/33336 320(s) eta:29985(s) loss:0.295095 loss200:0.203923 lr:6.00e-05[train] 353/33336 321(s) eta:29993(s) loss:0.295014 loss200:0.203499 lr:6.00e-05[train] 354/33336 322(s) eta:30000(s) loss:0.294753 loss200:0.203417 lr:6.00e-05[train] 355/33336 323(s) eta:30008(s) loss:0.294136 loss200:0.201201 lr:6.00e-05[train] 356/33336 324(s) eta:30015(s) loss:0.293802 loss200:0.200847 lr:6.00e-05[train] 357/33336 324(s) eta:29930(s) loss:0.293190 loss200:0.200392 lr:6.00e-05[train] 358/33336 325(s) eta:29938(s) loss:0.292671 loss200:0.199457 lr:6.00e-05[train] 359/33336 326(s) eta:29945(s) loss:0.292511 loss200:0.199106 lr:6.00e-05[train] 360/33336 327(s) eta:29953(s) loss:0.292488 loss200:0.199854 lr:6.00e-05[train] 361/33336 328(s) eta:29960(s) loss:0.292049 loss200:0.199617 lr:6.00e-05[train] 362/33336 329(s) eta:29968(s) loss:0.291671 loss200:0.199429 lr:6.00e-05[train] 363/33336 330(s) eta:29975(s) loss:0.291428 loss200:0.199406 lr:6.00e-05[train] 364/33336 330(s) eta:29892(s) loss:0.291298 loss200:0.199280 lr:6.00e-05[train] 365/33336 331(s) eta:29899(s) loss:0.290818 loss200:0.197802 lr:6.00e-05[train] 366/33336 332(s) eta:29907(s) loss:0.291231 loss200:0.199346 lr:6.00e-05[train] 367/33336 333(s) eta:29914(s) loss:0.290698 loss200:0.198309 lr:6.00e-05[train] 368/33336 334(s) eta:29922(s) loss:0.290519 loss200:0.198547 lr:6.00e-05[train] 369/33336 335(s) eta:29929(s) loss:0.290255 loss200:0.198717 lr:6.00e-05[train] 370/33336 336(s) eta:29936(s) loss:0.289834 loss200:0.198124 lr:6.00e-05[train] 371/33336 337(s) eta:29943(s) loss:0.289497 loss200:0.197875 lr:6.00e-05[train] 372/33336 338(s) eta:29951(s) loss:0.289178 loss200:0.197417 lr:6.00e-05[train] 373/33336 338(s) eta:29869(s) loss:0.288615 loss200:0.195914 lr:6.00e-05[train] 374/33336 339(s) eta:29877(s) loss:0.288315 loss200:0.196252 lr:6.00e-05[train] 375/33336 340(s) eta:29884(s) loss:0.287789 loss200:0.194056 lr:6.00e-05[train] 376/33336 341(s) eta:29891(s) loss:0.287912 loss200:0.194459 lr:6.00e-05[train] 377/33336 342(s) eta:29899(s) loss:0.287367 loss200:0.194031 lr:6.00e-05[train] 378/33336 343(s) eta:29906(s) loss:0.287169 loss200:0.193718 lr:6.00e-05[train] 379/33336 344(s) eta:29913(s) loss:0.286921 loss200:0.193474 lr:6.00e-05[train] 380/33336 345(s) eta:29920(s) loss:0.286447 loss200:0.192055 lr:6.00e-05[train] 381/33336 346(s) eta:29927(s) loss:0.285975 loss200:0.191910 lr:6.00e-05[train] 382/33336 346(s) eta:29848(s) loss:0.285693 loss200:0.192004 lr:6.00e-05[train] 383/33336 347(s) eta:29855(s) loss:0.285327 loss200:0.191996 lr:6.00e-05[train] 384/33336 348(s) eta:29862(s) loss:0.285127 loss200:0.191885 lr:6.00e-05[train] 385/33336 349(s) eta:29869(s) loss:0.284882 loss200:0.191607 lr:6.00e-05[train] 386/33336 350(s) eta:29876(s) loss:0.284929 loss200:0.192421 lr:6.00e-05[train] 387/33336 351(s) eta:29883(s) loss:0.284377 loss200:0.192074 lr:6.00e-05[train] 388/33336 352(s) eta:29890(s) loss:0.284197 loss200:0.192657 lr:6.00e-05[train] 389/33336 353(s) eta:29897(s) loss:0.283777 loss200:0.192697 lr:6.00e-05[train] 390/33336 354(s) eta:29904(s) loss:0.283487 loss200:0.192804 lr:6.00e-05[train] 391/33336 354(s) eta:29827(s) loss:0.283236 loss200:0.193011 lr:6.00e-05[train] 392/33336 355(s) eta:29834(s) loss:0.282780 loss200:0.192856 lr:6.00e-05[train] 393/33336 356(s) eta:29841(s) loss:0.282742 loss200:0.191942 lr:6.00e-05[train] 394/33336 357(s) eta:29848(s) loss:0.282591 loss200:0.192319 lr:6.00e-05[train] 395/33336 358(s) eta:29855(s) loss:0.283315 loss200:0.194122 lr:6.00e-05[train] 396/33336 359(s) eta:29862(s) loss:0.282935 loss200:0.193794 lr:6.00e-05[train] 397/33336 360(s) eta:29869(s) loss:0.282433 loss200:0.193291 lr:6.00e-05[train] 398/33336 361(s) eta:29875(s) loss:0.282247 loss200:0.193417 lr:6.00e-05[train] 399/33336 361(s) eta:29800(s) loss:0.281814 loss200:0.192482 lr:6.00e-05[train] 400/33336 362(s) eta:29807(s) loss:0.282177 loss200:0.194098 lr:6.00e-05[train] 401/33336 363(s) eta:29813(s) loss:0.281963 loss200:0.193690 lr:6.00e-05[train] 402/33336 364(s) eta:29820(s) loss:0.281512 loss200:0.193152 lr:6.00e-05[train] 403/33336 365(s) eta:29827(s) loss:0.281104 loss200:0.193004 lr:6.00e-05[train] 404/33336 366(s) eta:29834(s) loss:0.280600 loss200:0.191994 lr:6.00e-05[train] 405/33336 367(s) eta:29841(s) loss:0.280255 loss200:0.191487 lr:6.00e-05[train] 406/33336 368(s) eta:29847(s) loss:0.280361 loss200:0.190603 lr:6.00e-05[train] 407/33336 369(s) eta:29854(s) loss:0.280052 loss200:0.190782 lr:6.00e-05[train] 408/33336 369(s) eta:29780(s) loss:0.279530 loss200:0.189790 lr:6.00e-05[train] 409/33336 370(s) eta:29787(s) loss:0.278992 loss200:0.188651 lr:6.00e-05[train] 410/33336 371(s) eta:29794(s) loss:0.278460 loss200:0.188383 lr:6.00e-05[train] 411/33336 372(s) eta:29800(s) loss:0.278435 loss200:0.189083 lr:6.00e-05[train] 412/33336 373(s) eta:29807(s) loss:0.278421 loss200:0.187645 lr:6.00e-05[train] 413/33336 374(s) eta:29814(s) loss:0.278348 loss200:0.187901 lr:6.00e-05[train] 414/33336 375(s) eta:29820(s) loss:0.278304 loss200:0.188246 lr:6.00e-05[train] 415/33336 376(s) eta:29827(s) loss:0.278298 loss200:0.187764 lr:6.00e-05[train] 416/33336 376(s) eta:29754(s) loss:0.278218 loss200:0.188231 lr:6.00e-05[train] 417/33336 377(s) eta:29761(s) loss:0.278397 loss200:0.188907 lr:6.00e-05[train] 418/33336 378(s) eta:29767(s) loss:0.277869 loss200:0.188530 lr:6.00e-05[train] 419/33336 379(s) eta:29774(s) loss:0.277448 loss200:0.188015 lr:6.00e-05[train] 420/33336 380(s) eta:29781(s) loss:0.277103 loss200:0.187588 lr:6.00e-05[train] 421/33336 381(s) eta:29787(s) loss:0.276750 loss200:0.187538 lr:6.00e-05[train] 422/33336 382(s) eta:29794(s) loss:0.276521 loss200:0.187331 lr:6.00e-05[train] 423/33336 383(s) eta:29800(s) loss:0.276332 loss200:0.187729 lr:6.00e-05[train] 424/33336 384(s) eta:29807(s) loss:0.275975 loss200:0.186759 lr:6.00e-05[train] 425/33336 385(s) eta:29813(s) loss:0.276239 loss200:0.188066 lr:6.00e-05[train] 426/33336 385(s) eta:29742(s) loss:0.276004 loss200:0.187677 lr:6.00e-05[train] 427/33336 386(s) eta:29749(s) loss:0.275700 loss200:0.187864 lr:6.00e-05[train] 428/33336 387(s) eta:29755(s) loss:0.275277 loss200:0.187496 lr:6.00e-05[train] 429/33336 388(s) eta:29762(s) loss:0.275656 loss200:0.188869 lr:6.00e-05[train] 430/33336 389(s) eta:29768(s) loss:0.275298 loss200:0.188165 lr:6.00e-05[train] 431/33336 390(s) eta:29774(s) loss:0.275052 loss200:0.187815 lr:6.00e-05[train] 432/33336 391(s) eta:29781(s) loss:0.274547 loss200:0.187034 lr:6.00e-05[train] 433/33336 392(s) eta:29787(s) loss:0.274194 loss200:0.186823 lr:6.00e-05[train] 434/33336 392(s) eta:29717(s) loss:0.273833 loss200:0.185742 lr:6.00e-05[train] 435/33336 393(s) eta:29724(s) loss:0.273681 loss200:0.185517 lr:6.00e-05[train] 436/33336 394(s) eta:29730(s) loss:0.273354 loss200:0.184575 lr:6.00e-05[train] 437/33336 395(s) eta:29737(s) loss:0.273200 loss200:0.184947 lr:6.00e-05[train] 438/33336 396(s) eta:29743(s) loss:0.273074 loss200:0.184878 lr:6.00e-05[train] 439/33336 397(s) eta:29749(s) loss:0.272856 loss200:0.185067 lr:6.00e-05[train] 440/33336 398(s) eta:29755(s) loss:0.272498 loss200:0.184349 lr:6.00e-05[train] 441/33336 399(s) eta:29762(s) loss:0.272080 loss200:0.183368 lr:6.00e-05[train] 442/33336 399(s) eta:29693(s) loss:0.271806 loss200:0.182745 lr:6.00e-05[train] 443/33336 400(s) eta:29700(s) loss:0.271417 loss200:0.182019 lr:6.00e-05[train] 444/33336 401(s) eta:29706(s) loss:0.271496 loss200:0.182868 lr:6.00e-05[train] 445/33336 402(s) eta:29712(s) loss:0.271281 loss200:0.183051 lr:6.00e-05[train] 446/33336 403(s) eta:29718(s) loss:0.270978 loss200:0.183125 lr:6.00e-05[train] 447/33336 404(s) eta:29725(s) loss:0.270895 loss200:0.183248 lr:6.00e-05[train] 448/33336 405(s) eta:29731(s) loss:0.270895 loss200:0.182724 lr:6.00e-05[train] 449/33336 406(s) eta:29737(s) loss:0.271167 loss200:0.184073 lr:6.00e-05[train] 450/33336 407(s) eta:29743(s) loss:0.270721 loss200:0.182620 lr:6.00e-05[train] 451/33336 407(s) eta:29676(s) loss:0.270396 loss200:0.182412 lr:6.00e-05[train] 452/33336 408(s) eta:29682(s) loss:0.270236 loss200:0.182718 lr:6.00e-05[train] 453/33336 409(s) eta:29689(s) loss:0.270079 loss200:0.182260 lr:6.00e-05[train] 454/33336 410(s) eta:29695(s) loss:0.269772 loss200:0.181957 lr:6.00e-05[train] 455/33336 411(s) eta:29701(s) loss:0.269318 loss200:0.181714 lr:6.00e-05[train] 456/33336 412(s) eta:29707(s) loss:0.269035 loss200:0.181509 lr:6.00e-05[train] 457/33336 413(s) eta:29713(s) loss:0.268888 loss200:0.181658 lr:6.00e-05[train] 458/33336 414(s) eta:29719(s) loss:0.268845 loss200:0.182428 lr:6.00e-05[train] 459/33336 414(s) eta:29653(s) loss:0.268877 loss200:0.183429 lr:6.00e-05[train] 460/33336 415(s) eta:29659(s) loss:0.268475 loss200:0.182447 lr:6.00e-05[train] 461/33336 416(s) eta:29665(s) loss:0.268717 loss200:0.183030 lr:6.00e-05[train] 462/33336 417(s) eta:29671(s) loss:0.268745 loss200:0.182808 lr:6.00e-05[train] 463/33336 418(s) eta:29678(s) loss:0.268495 loss200:0.182956 lr:6.00e-05[train] 464/33336 419(s) eta:29683(s) loss:0.268234 loss200:0.182622 lr:6.00e-05[train] 465/33336 420(s) eta:29689(s) loss:0.268254 loss200:0.182803 lr:6.00e-05[train] 466/33336 421(s) eta:29695(s) loss:0.268100 loss200:0.182918 lr:6.00e-05[train] 467/33336 422(s) eta:29701(s) loss:0.267713 loss200:0.182906 lr:6.00e-05[train] 468/33336 423(s) eta:29707(s) loss:0.267435 loss200:0.182088 lr:6.00e-05[train] 469/33336 423(s) eta:29643(s) loss:0.267509 loss200:0.182300 lr:6.00e-05[train] 470/33336 424(s) eta:29649(s) loss:0.267381 loss200:0.182795 lr:6.00e-05[train] 471/33336 425(s) eta:29655(s) loss:0.267552 loss200:0.183361 lr:6.00e-05[train] 472/33336 426(s) eta:29661(s) loss:0.268043 loss200:0.184679 lr:6.00e-05[train] 473/33336 427(s) eta:29667(s) loss:0.268010 loss200:0.185411 lr:6.00e-05[train] 474/33336 428(s) eta:29672(s) loss:0.267786 loss200:0.185724 lr:6.00e-05[train] 475/33336 429(s) eta:29678(s) loss:0.267618 loss200:0.186109 lr:6.00e-05[train] 476/33336 430(s) eta:29684(s) loss:0.267655 loss200:0.187083 lr:6.00e-05[train] 477/33336 431(s) eta:29690(s) loss:0.267328 loss200:0.186549 lr:6.00e-05[train] 478/33336 431(s) eta:29627(s) loss:0.267130 loss200:0.186606 lr:6.00e-05[train] 479/33336 432(s) eta:29633(s) loss:0.266685 loss200:0.185375 lr:6.00e-05[train] 480/33336 433(s) eta:29638(s) loss:0.266513 loss200:0.185606 lr:6.00e-05[train] 481/33336 434(s) eta:29644(s) loss:0.266233 loss200:0.185812 lr:6.00e-05[train] 482/33336 435(s) eta:29650(s) loss:0.266056 loss200:0.185307 lr:6.00e-05[train] 483/33336 436(s) eta:29656(s) loss:0.265965 loss200:0.185453 lr:6.00e-05[train] 484/33336 437(s) eta:29661(s) loss:0.265607 loss200:0.185297 lr:6.00e-05[train] 485/33336 438(s) eta:29667(s) loss:0.265275 loss200:0.185416 lr:6.00e-05[train] 486/33336 439(s) eta:29673(s) loss:0.264941 loss200:0.185329 lr:6.00e-05[train] 487/33336 439(s) eta:29611(s) loss:0.264584 loss200:0.185214 lr:6.00e-05[train] 488/33336 440(s) eta:29617(s) loss:0.264442 loss200:0.185332 lr:6.00e-05[train] 489/33336 441(s) eta:29622(s) loss:0.264201 loss200:0.185565 lr:6.00e-05[train] 490/33336 442(s) eta:29628(s) loss:0.264083 loss200:0.185609 lr:6.00e-05[train] 491/33336 443(s) eta:29634(s) loss:0.263827 loss200:0.184353 lr:6.00e-05[train] 492/33336 444(s) eta:29639(s) loss:0.263676 loss200:0.184788 lr:6.00e-05[train] 493/33336 445(s) eta:29645(s) loss:0.263537 loss200:0.184814 lr:6.00e-05[train] 494/33336 445(s) eta:29584(s) loss:0.263202 loss200:0.184308 lr:6.00e-05[train] 495/33336 446(s) eta:29590(s) loss:0.263453 loss200:0.185684 lr:6.00e-05[train] 496/33336 447(s) eta:29595(s) loss:0.263161 loss200:0.185018 lr:6.00e-05[train] 497/33336 448(s) eta:29601(s) loss:0.262859 loss200:0.184835 lr:6.00e-05[train] 498/33336 449(s) eta:29606(s) loss:0.262500 loss200:0.184744 lr:6.00e-05[train] 499/33336 450(s) eta:29612(s) loss:0.262167 loss200:0.183811 lr:6.00e-05[train] 500/33336 451(s) eta:29618(s) loss:0.262052 loss200:0.183875 lr:6.00e-05[train] 501/33336 452(s) eta:29623(s) loss:0.261883 loss200:0.184140 lr:6.00e-05[train] 502/33336 452(s) eta:29563(s) loss:0.261690 loss200:0.184173 lr:6.00e-05[train] 503/33336 453(s) eta:29569(s) loss:0.261601 loss200:0.184806 lr:6.00e-05[train] 504/33336 454(s) eta:29574(s) loss:0.261404 loss200:0.184019 lr:6.00e-05[train] 505/33336 455(s) eta:29580(s) loss:0.261373 loss200:0.184580 lr:6.00e-05[train] 506/33336 456(s) eta:29585(s) loss:0.261059 loss200:0.183836 lr:6.00e-05[train] 507/33336 457(s) eta:29591(s) loss:0.261017 loss200:0.184363 lr:6.00e-05[train] 508/33336 458(s) eta:29596(s) loss:0.260765 loss200:0.183849 lr:6.00e-05[train] 509/33336 459(s) eta:29602(s) loss:0.260490 loss200:0.183637 lr:6.00e-05[train] 510/33336 459(s) eta:29543(s) loss:0.260249 loss200:0.182721 lr:6.00e-05[train] 511/33336 460(s) eta:29548(s) loss:0.259856 loss200:0.182376 lr:6.00e-05[train] 512/33336 461(s) eta:29554(s) loss:0.259471 loss200:0.181871 lr:6.00e-05[train] 513/33336 462(s) eta:29559(s) loss:0.259160 loss200:0.181722 lr:6.00e-05[train] 514/33336 463(s) eta:29565(s) loss:0.258782 loss200:0.181546 lr:6.00e-05[train] 515/33336 464(s) eta:29570(s) loss:0.258418 loss200:0.180932 lr:6.00e-05[train] 516/33336 465(s) eta:29576(s) loss:0.258015 loss200:0.180010 lr:6.00e-05[train] 517/33336 466(s) eta:29581(s) loss:0.257629 loss200:0.179777 lr:6.00e-05[train] 518/33336 467(s) eta:29586(s) loss:0.257373 loss200:0.179822 lr:6.00e-05[train] 519/33336 467(s) eta:29528(s) loss:0.256993 loss200:0.179059 lr:6.00e-05[train] 520/33336 468(s) eta:29534(s) loss:0.256746 loss200:0.177522 lr:6.00e-05[train] 521/33336 469(s) eta:29539(s) loss:0.256763 loss200:0.178211 lr:6.00e-05[train] 522/33336 470(s) eta:29545(s) loss:0.256954 loss200:0.178780 lr:6.00e-05[train] 523/33336 471(s) eta:29550(s) loss:0.256732 loss200:0.177953 lr:6.00e-05[train] 524/33336 472(s) eta:29555(s) loss:0.256529 loss200:0.177921 lr:6.00e-05[train] 525/33336 473(s) eta:29561(s) loss:0.256251 loss200:0.177643 lr:6.00e-05[train] 526/33336 474(s) eta:29566(s) loss:0.256390 loss200:0.178473 lr:6.00e-05[train] 527/33336 475(s) eta:29571(s) loss:0.256213 loss200:0.178502 lr:6.00e-05[train] 528/33336 476(s) eta:29576(s) loss:0.255944 loss200:0.178746 lr:6.00e-05[train] 529/33336 476(s) eta:29520(s) loss:0.255936 loss200:0.178343 lr:6.00e-05[train] 530/33336 477(s) eta:29525(s) loss:0.255591 loss200:0.176466 lr:6.00e-05[train] 531/33336 478(s) eta:29530(s) loss:0.255656 loss200:0.176431 lr:6.00e-05[train] 532/33336 479(s) eta:29535(s) loss:0.255612 loss200:0.176536 lr:6.00e-05[train] 533/33336 480(s) eta:29541(s) loss:0.255239 loss200:0.175595 lr:6.00e-05[train] 534/33336 481(s) eta:29546(s) loss:0.255177 loss200:0.176184 lr:6.00e-05[train] 535/33336 482(s) eta:29551(s) loss:0.254983 loss200:0.176569 lr:6.00e-05[train] 536/33336 483(s) eta:29556(s) loss:0.254697 loss200:0.175698 lr:6.00e-05[train] 537/33336 484(s) eta:29561(s) loss:0.254654 loss200:0.176403 lr:6.00e-05[train] 538/33336 484(s) eta:29506(s) loss:0.254569 loss200:0.176803 lr:6.00e-05[train] 539/33336 485(s) eta:29511(s) loss:0.254599 loss200:0.177538 lr:6.00e-05[train] 540/33336 486(s) eta:29516(s) loss:0.254270 loss200:0.176572 lr:6.00e-05[train] 541/33336 487(s) eta:29521(s) loss:0.254314 loss200:0.177436 lr:6.00e-05[train] 542/33336 488(s) eta:29526(s) loss:0.253994 loss200:0.177315 lr:6.00e-05[train] 543/33336 489(s) eta:29531(s) loss:0.253900 loss200:0.177616 lr:6.00e-05[train] 544/33336 490(s) eta:29536(s) loss:0.254213 loss200:0.178845 lr:6.00e-05[train] 545/33336 491(s) eta:29541(s) loss:0.253984 loss200:0.178907 lr:6.00e-05[train] 546/33336 491(s) eta:29486(s) loss:0.253748 loss200:0.178658 lr:6.00e-05[train] 547/33336 492(s) eta:29492(s) loss:0.253616 loss200:0.178725 lr:6.00e-05[train] 548/33336 493(s) eta:29497(s) loss:0.253438 loss200:0.178662 lr:6.00e-05[train] 549/33336 494(s) eta:29502(s) loss:0.253488 loss200:0.179544 lr:6.00e-05[train] 550/33336 495(s) eta:29507(s) loss:0.253571 loss200:0.180301 lr:6.00e-05[train] 551/33336 496(s) eta:29512(s) loss:0.253338 loss200:0.179257 lr:6.00e-05[train] 552/33336 497(s) eta:29517(s) loss:0.253340 loss200:0.179849 lr:6.00e-05[train] 553/33336 497(s) eta:29463(s) loss:0.253094 loss200:0.179106 lr:6.00e-05[train] 554/33336 498(s) eta:29468(s) loss:0.253053 loss200:0.179245 lr:6.00e-05[train] 555/33336 499(s) eta:29473(s) loss:0.252932 loss200:0.179795 lr:6.00e-05[train] 556/33336 500(s) eta:29478(s) loss:0.252726 loss200:0.179611 lr:6.00e-05[train] 557/33336 501(s) eta:29483(s) loss:0.252601 loss200:0.180150 lr:6.00e-05[train] 558/33336 502(s) eta:29488(s) loss:0.252493 loss200:0.180575 lr:6.00e-05[train] 559/33336 503(s) eta:29493(s) loss:0.252278 loss200:0.180060 lr:6.00e-05[train] 560/33336 504(s) eta:29498(s) loss:0.251955 loss200:0.178996 lr:6.00e-05[train] 561/33336 505(s) eta:29503(s) loss:0.251727 loss200:0.178946 lr:6.00e-05[train] 562/33336 505(s) eta:29449(s) loss:0.251560 loss200:0.178960 lr:6.00e-05[train] 563/33336 506(s) eta:29454(s) loss:0.251415 loss200:0.178791 lr:6.00e-05[train] 564/33336 507(s) eta:29459(s) loss:0.251164 loss200:0.178119 lr:6.00e-05[train] 565/33336 508(s) eta:29464(s) loss:0.251138 loss200:0.178722 lr:6.00e-05[train] 566/33336 509(s) eta:29469(s) loss:0.251090 loss200:0.177632 lr:6.00e-05[train] 567/33336 510(s) eta:29474(s) loss:0.251053 loss200:0.178303 lr:6.00e-05[train] 568/33336 511(s) eta:29479(s) loss:0.250808 loss200:0.177740 lr:6.00e-05[train] 569/33336 511(s) eta:29426(s) loss:0.250557 loss200:0.177314 lr:6.00e-05[train] 570/33336 512(s) eta:29431(s) loss:0.250501 loss200:0.177736 lr:6.00e-05[train] 571/33336 513(s) eta:29436(s) loss:0.250214 loss200:0.177344 lr:6.00e-05[train] 572/33336 514(s) eta:29441(s) loss:0.250083 loss200:0.177367 lr:6.00e-05[train] 573/33336 515(s) eta:29446(s) loss:0.249905 loss200:0.177712 lr:6.00e-05[train] 574/33336 516(s) eta:29451(s) loss:0.249809 loss200:0.177801 lr:6.00e-05[train] 575/33336 517(s) eta:29456(s) loss:0.249584 loss200:0.177949 lr:6.00e-05[train] 576/33336 517(s) eta:29404(s) loss:0.249294 loss200:0.176690 lr:6.00e-05[train] 577/33336 518(s) eta:29409(s) loss:0.249131 loss200:0.177055 lr:6.00e-05[train] 578/33336 519(s) eta:29414(s) loss:0.248853 loss200:0.176437 lr:6.00e-05[train] 579/33336 520(s) eta:29419(s) loss:0.248855 loss200:0.176718 lr:6.00e-05[train] 580/33336 521(s) eta:29423(s) loss:0.249125 loss200:0.178213 lr:6.00e-05[train] 581/33336 522(s) eta:29428(s) loss:0.249002 loss200:0.178568 lr:6.00e-05[train] 582/33336 523(s) eta:29433(s) loss:0.248837 loss200:0.178443 lr:6.00e-05[train] 583/33336 524(s) eta:29438(s) loss:0.248606 loss200:0.178286 lr:6.00e-05[train] 584/33336 524(s) eta:29387(s) loss:0.248595 loss200:0.178452 lr:6.00e-05[train] 585/33336 525(s) eta:29391(s) loss:0.248425 loss200:0.178244 lr:6.00e-05[train] 586/33336 526(s) eta:29396(s) loss:0.248310 loss200:0.177635 lr:6.00e-05[train] 587/33336 527(s) eta:29401(s) loss:0.248144 loss200:0.178033 lr:6.00e-05[train] 588/33336 528(s) eta:29406(s) loss:0.248059 loss200:0.177952 lr:6.00e-05[train] 589/33336 529(s) eta:29411(s) loss:0.248143 loss200:0.178834 lr:6.00e-05[train] 590/33336 530(s) eta:29415(s) loss:0.248179 loss200:0.179328 lr:6.00e-05[train] 591/33336 530(s) eta:29365(s) loss:0.248110 loss200:0.179438 lr:6.00e-05[train] 592/33336 531(s) eta:29370(s) loss:0.247863 loss200:0.179426 lr:6.00e-05[train] 593/33336 532(s) eta:29374(s) loss:0.247936 loss200:0.179541 lr:6.00e-05[train] 594/33336 533(s) eta:29379(s) loss:0.248018 loss200:0.179908 lr:6.00e-05[train] 595/33336 534(s) eta:29384(s) loss:0.247896 loss200:0.177945 lr:6.00e-05[train] 596/33336 535(s) eta:29389(s) loss:0.247754 loss200:0.178096 lr:6.00e-05[train] 597/33336 536(s) eta:29393(s) loss:0.247661 loss200:0.178637 lr:6.00e-05[train] 598/33336 537(s) eta:29398(s) loss:0.247537 loss200:0.178463 lr:6.00e-05[train] 599/33336 538(s) eta:29403(s) loss:0.247331 loss200:0.178538 lr:6.00e-05[train] 600/33336 539(s) eta:29407(s) loss:0.247238 loss200:0.177360 lr:6.00e-05[train] 601/33336 539(s) eta:29358(s) loss:0.247062 loss200:0.177087 lr:6.00e-05[train] 602/33336 540(s) eta:29362(s) loss:0.246855 loss200:0.177194 lr:6.00e-05[train] 603/33336 541(s) eta:29367(s) loss:0.246837 loss200:0.177791 lr:6.00e-05[train] 604/33336 542(s) eta:29372(s) loss:0.246620 loss200:0.177980 lr:6.00e-05[train] 605/33336 543(s) eta:29376(s) loss:0.246365 loss200:0.177739 lr:6.00e-05[train] 606/33336 544(s) eta:29381(s) loss:0.246376 loss200:0.177386 lr:6.00e-05[train] 607/33336 545(s) eta:29386(s) loss:0.246202 loss200:0.177317 lr:6.00e-05[train] 608/33336 545(s) eta:29336(s) loss:0.246225 loss200:0.178284 lr:6.00e-05[train] 609/33336 546(s) eta:29341(s) loss:0.246111 loss200:0.178869 lr:6.00e-05[train] 610/33336 547(s) eta:29346(s) loss:0.245960 loss200:0.179336 lr:6.00e-05[train] 611/33336 548(s) eta:29350(s) loss:0.245903 loss200:0.179049 lr:6.00e-05[train] 612/33336 549(s) eta:29355(s) loss:0.245754 loss200:0.178459 lr:6.00e-05[train] 613/33336 550(s) eta:29359(s) loss:0.245716 loss200:0.178331 lr:6.00e-05[train] 614/33336 551(s) eta:29364(s) loss:0.245536 loss200:0.177706 lr:6.00e-05[train] 615/33336 552(s) eta:29369(s) loss:0.245612 loss200:0.177789 lr:6.00e-05[train] 616/33336 553(s) eta:29373(s) loss:0.245676 loss200:0.177991 lr:6.00e-05[train] 617/33336 553(s) eta:29325(s) loss:0.245509 loss200:0.176939 lr:6.00e-05[train] 618/33336 554(s) eta:29329(s) loss:0.245505 loss200:0.177864 lr:6.00e-05[train] 619/33336 555(s) eta:29334(s) loss:0.245276 loss200:0.177875 lr:6.00e-05[train] 620/33336 556(s) eta:29338(s) loss:0.245038 loss200:0.177701 lr:6.00e-05[train] 621/33336 557(s) eta:29343(s) loss:0.244979 loss200:0.178102 lr:6.00e-05[train] 622/33336 558(s) eta:29347(s) loss:0.245054 loss200:0.178659 lr:6.00e-05[train] 623/33336 559(s) eta:29352(s) loss:0.244942 loss200:0.178553 lr:6.00e-05[train] 624/33336 560(s) eta:29356(s) loss:0.244730 loss200:0.178491 lr:6.00e-05[train] 625/33336 561(s) eta:29361(s) loss:0.244560 loss200:0.177243 lr:6.00e-05[train] 626/33336 561(s) eta:29313(s) loss:0.244586 loss200:0.177664 lr:6.00e-05[train] 627/33336 562(s) eta:29318(s) loss:0.244514 loss200:0.177934 lr:6.00e-05[train] 628/33336 563(s) eta:29322(s) loss:0.244320 loss200:0.178071 lr:6.00e-05[train] 629/33336 564(s) eta:29327(s) loss:0.244086 loss200:0.176370 lr:6.00e-05[train] 630/33336 565(s) eta:29331(s) loss:0.244007 loss200:0.176732 lr:6.00e-05[train] 631/33336 566(s) eta:29336(s) loss:0.243931 loss200:0.176865 lr:6.00e-05[train] 632/33336 567(s) eta:29340(s) loss:0.243793 loss200:0.177365 lr:6.00e-05[train] 633/33336 568(s) eta:29344(s) loss:0.243596 loss200:0.177352 lr:6.00e-05[train] 634/33336 568(s) eta:29297(s) loss:0.243496 loss200:0.177664 lr:6.00e-05[train] 635/33336 569(s) eta:29302(s) loss:0.243223 loss200:0.176976 lr:6.00e-05[train] 636/33336 570(s) eta:29306(s) loss:0.243018 loss200:0.176887 lr:6.00e-05[train] 637/33336 571(s) eta:29311(s) loss:0.243012 loss200:0.177051 lr:6.00e-05[train] 638/33336 572(s) eta:29315(s) loss:0.242771 loss200:0.176409 lr:6.00e-05[train] 639/33336 573(s) eta:29319(s) loss:0.242742 loss200:0.176642 lr:6.00e-05[train] 640/33336 574(s) eta:29324(s) loss:0.242698 loss200:0.177139 lr:6.00e-05[train] 641/33336 575(s) eta:29328(s) loss:0.242479 loss200:0.177208 lr:6.00e-05[train] 642/33336 576(s) eta:29332(s) loss:0.242198 loss200:0.176762 lr:6.00e-05[train] 643/33336 577(s) eta:29337(s) loss:0.241942 loss200:0.176653 lr:6.00e-05[train] 644/33336 577(s) eta:29290(s) loss:0.241994 loss200:0.176499 lr:6.00e-05[train] 645/33336 578(s) eta:29295(s) loss:0.241789 loss200:0.176169 lr:6.00e-05[train] 646/33336 579(s) eta:29299(s) loss:0.241566 loss200:0.175979 lr:6.00e-05[train] 647/33336 580(s) eta:29303(s) loss:0.241398 loss200:0.175473 lr:6.00e-05[train] 648/33336 581(s) eta:29308(s) loss:0.241177 loss200:0.174608 lr:6.00e-05[train] 649/33336 582(s) eta:29312(s) loss:0.240888 loss200:0.172911 lr:6.00e-05[train] 650/33336 583(s) eta:29316(s) loss:0.240770 loss200:0.173378 lr:6.00e-05[train] 651/33336 584(s) eta:29321(s) loss:0.240815 loss200:0.174109 lr:6.00e-05[train] 652/33336 584(s) eta:29275(s) loss:0.240604 loss200:0.173634 lr:6.00e-05[train] 653/33336 585(s) eta:29279(s) loss:0.240340 loss200:0.172980 lr:6.00e-05[train] 654/33336 586(s) eta:29283(s) loss:0.240093 loss200:0.172721 lr:6.00e-05[train] 655/33336 587(s) eta:29288(s) loss:0.239913 loss200:0.173016 lr:6.00e-05[train] 656/33336 588(s) eta:29292(s) loss:0.239673 loss200:0.172729 lr:6.00e-05[train] 657/33336 589(s) eta:29296(s) loss:0.239787 loss200:0.173292 lr:6.00e-05[train] 658/33336 590(s) eta:29300(s) loss:0.239714 loss200:0.173003 lr:6.00e-05[train] 659/33336 591(s) eta:29305(s) loss:0.239513 loss200:0.172123 lr:6.00e-05[train] 660/33336 592(s) eta:29309(s) loss:0.239381 loss200:0.172463 lr:6.00e-05[train] 661/33336 592(s) eta:29264(s) loss:0.239094 loss200:0.170812 lr:6.00e-05[train] 662/33336 593(s) eta:29268(s) loss:0.239107 loss200:0.170641 lr:6.00e-05[train] 663/33336 594(s) eta:29272(s) loss:0.238843 loss200:0.170198 lr:6.00e-05[train] 664/33336 595(s) eta:29276(s) loss:0.238906 loss200:0.170864 lr:6.00e-05[train] 665/33336 596(s) eta:29281(s) loss:0.238796 loss200:0.170308 lr:6.00e-05[train] 666/33336 597(s) eta:29285(s) loss:0.238812 loss200:0.170570 lr:6.00e-05[train] 667/33336 598(s) eta:29289(s) loss:0.238918 loss200:0.171683 lr:6.00e-05[train] 668/33336 598(s) eta:29244(s) loss:0.238851 loss200:0.171962 lr:6.00e-05[train] 669/33336 599(s) eta:29248(s) loss:0.238623 loss200:0.170886 lr:6.00e-05[train] 670/33336 600(s) eta:29253(s) loss:0.238450 loss200:0.170464 lr:6.00e-05[train] 671/33336 601(s) eta:29257(s) loss:0.238397 loss200:0.169737 lr:6.00e-05[train] 672/33336 602(s) eta:29261(s) loss:0.238208 loss200:0.167797 lr:6.00e-05[train] 673/33336 603(s) eta:29265(s) loss:0.238097 loss200:0.167354 lr:6.00e-05[train] 674/33336 604(s) eta:29269(s) loss:0.237865 loss200:0.166951 lr:6.00e-05[train] 675/33336 605(s) eta:29273(s) loss:0.237642 loss200:0.166448 lr:6.00e-05[train] 676/33336 605(s) eta:29229(s) loss:0.237571 loss200:0.165973 lr:6.00e-05[train] 677/33336 606(s) eta:29233(s) loss:0.237659 loss200:0.166897 lr:6.00e-05[train] 678/33336 607(s) eta:29238(s) loss:0.237639 loss200:0.167157 lr:6.00e-05[train] 679/33336 608(s) eta:29242(s) loss:0.237401 loss200:0.167266 lr:6.00e-05[train] 680/33336 609(s) eta:29246(s) loss:0.237223 loss200:0.166926 lr:6.00e-05[train] 681/33336 610(s) eta:29250(s) loss:0.237551 loss200:0.168570 lr:6.00e-05[train] 682/33336 611(s) eta:29254(s) loss:0.237343 loss200:0.168145 lr:6.00e-05[train] 683/33336 612(s) eta:29258(s) loss:0.237281 loss200:0.168012 lr:6.00e-05[train] 684/33336 612(s) eta:29214(s) loss:0.237209 loss200:0.168486 lr:6.00e-05[train] 685/33336 613(s) eta:29219(s) loss:0.237001 loss200:0.168437 lr:6.00e-05[train] 686/33336 614(s) eta:29223(s) loss:0.236783 loss200:0.168361 lr:6.00e-05[train] 687/33336 615(s) eta:29227(s) loss:0.236562 loss200:0.168330 lr:6.00e-05[train] 688/33336 616(s) eta:29231(s) loss:0.236663 loss200:0.168884 lr:6.00e-05[train] 689/33336 617(s) eta:29235(s) loss:0.236436 loss200:0.168551 lr:6.00e-05[train] 690/33336 618(s) eta:29239(s) loss:0.236241 loss200:0.168029 lr:6.00e-05[train] 691/33336 619(s) eta:29243(s) loss:0.235998 loss200:0.167679 lr:6.00e-05[train] 692/33336 619(s) eta:29200(s) loss:0.235799 loss200:0.167221 lr:6.00e-05[train] 693/33336 620(s) eta:29204(s) loss:0.235808 loss200:0.167456 lr:6.00e-05[train] 694/33336 621(s) eta:29208(s) loss:0.235553 loss200:0.167261 lr:6.00e-05[train] 695/33336 622(s) eta:29212(s) loss:0.235287 loss200:0.165577 lr:6.00e-05[train] 696/33336 623(s) eta:29216(s) loss:0.235306 loss200:0.166226 lr:6.00e-05[train] 697/33336 624(s) eta:29220(s) loss:0.235211 loss200:0.166506 lr:6.00e-05[train] 698/33336 625(s) eta:29224(s) loss:0.235064 loss200:0.166747 lr:6.00e-05[train] 699/33336 626(s) eta:29228(s) loss:0.234919 loss200:0.166934 lr:6.00e-05[train] 700/33336 626(s) eta:29185(s) loss:0.234748 loss200:0.166491 lr:6.00e-05[train] 701/33336 627(s) eta:29189(s) loss:0.234501 loss200:0.165909 lr:6.00e-05[train] 702/33336 628(s) eta:29193(s) loss:0.234376 loss200:0.165815 lr:6.00e-05[train] 703/33336 629(s) eta:29197(s) loss:0.234247 loss200:0.165452 lr:6.00e-05[train] 704/33336 630(s) eta:29201(s) loss:0.234023 loss200:0.165023 lr:6.00e-05[train] 705/33336 631(s) eta:29205(s) loss:0.233940 loss200:0.164670 lr:6.00e-05[train] 706/33336 632(s) eta:29209(s) loss:0.233712 loss200:0.164525 lr:6.00e-05[train] 707/33336 632(s) eta:29167(s) loss:0.233640 loss200:0.164238 lr:6.00e-05[train] 708/33336 633(s) eta:29171(s) loss:0.233464 loss200:0.164119 lr:6.00e-05[train] 709/33336 634(s) eta:29175(s) loss:0.233435 loss200:0.164579 lr:6.00e-05[train] 710/33336 635(s) eta:29179(s) loss:0.233301 loss200:0.164585 lr:6.00e-05[train] 711/33336 636(s) eta:29183(s) loss:0.233313 loss200:0.165497 lr:6.00e-05[train] 712/33336 637(s) eta:29187(s) loss:0.233199 loss200:0.165943 lr:6.00e-05[train] 713/33336 638(s) eta:29191(s) loss:0.233036 loss200:0.166026 lr:6.00e-05[train] 714/33336 639(s) eta:29195(s) loss:0.233011 loss200:0.166779 lr:6.00e-05[train] 715/33336 640(s) eta:29199(s) loss:0.232887 loss200:0.167145 lr:6.00e-05[train] 716/33336 640(s) eta:29157(s) loss:0.233016 loss200:0.168519 lr:6.00e-05[train] 717/33336 641(s) eta:29161(s) loss:0.233079 loss200:0.169615 lr:6.00e-05[train] 718/33336 642(s) eta:29165(s) loss:0.233095 loss200:0.170215 lr:6.00e-05[train] 719/33336 643(s) eta:29169(s) loss:0.232896 loss200:0.170364 lr:6.00e-05[train] 720/33336 644(s) eta:29173(s) loss:0.232983 loss200:0.171201 lr:6.00e-05[train] 721/33336 645(s) eta:29177(s) loss:0.232732 loss200:0.170129 lr:6.00e-05[train] 722/33336 646(s) eta:29180(s) loss:0.232685 loss200:0.169340 lr:6.00e-05[train] 723/33336 647(s) eta:29184(s) loss:0.233103 loss200:0.171313 lr:6.00e-05[train] 724/33336 647(s) eta:29143(s) loss:0.233007 loss200:0.171380 lr:6.00e-05[train] 725/33336 648(s) eta:29147(s) loss:0.232778 loss200:0.171162 lr:6.00e-05[train] 726/33336 649(s) eta:29151(s) loss:0.232700 loss200:0.170395 lr:6.00e-05[train] 727/33336 650(s) eta:29155(s) loss:0.232767 loss200:0.170990 lr:6.00e-05[train] 728/33336 651(s) eta:29159(s) loss:0.232737 loss200:0.171471 lr:6.00e-05[train] 729/33336 652(s) eta:29162(s) loss:0.232633 loss200:0.170996 lr:6.00e-05[train] 730/33336 653(s) eta:29166(s) loss:0.232453 loss200:0.171139 lr:6.00e-05[train] 731/33336 654(s) eta:29170(s) loss:0.232352 loss200:0.170478 lr:6.00e-05[train] 732/33336 654(s) eta:29129(s) loss:0.232312 loss200:0.170336 lr:6.00e-05[train] 733/33336 655(s) eta:29133(s) loss:0.232187 loss200:0.170755 lr:6.00e-05[train] 734/33336 656(s) eta:29137(s) loss:0.232035 loss200:0.170244 lr:6.00e-05[train] 735/33336 657(s) eta:29141(s) loss:0.231920 loss200:0.170228 lr:6.00e-05[train] 736/33336 658(s) eta:29145(s) loss:0.231800 loss200:0.170434 lr:6.00e-05[train] 737/33336 659(s) eta:29148(s) loss:0.231746 loss200:0.170236 lr:6.00e-05[train] 738/33336 660(s) eta:29152(s) loss:0.231592 loss200:0.169784 lr:6.00e-05[train] 739/33336 660(s) eta:29112(s) loss:0.231623 loss200:0.169702 lr:6.00e-05[train] 740/33336 661(s) eta:29116(s) loss:0.231640 loss200:0.170539 lr:6.00e-05[train] 741/33336 662(s) eta:29119(s) loss:0.231558 loss200:0.170002 lr:6.00e-05[train] 742/33336 663(s) eta:29123(s) loss:0.231360 loss200:0.170020 lr:6.00e-05[train] 743/33336 664(s) eta:29127(s) loss:0.231134 loss200:0.169326 lr:6.00e-05[train] 744/33336 665(s) eta:29131(s) loss:0.231037 loss200:0.167998 lr:6.00e-05[train] 745/33336 666(s) eta:29135(s) loss:0.230779 loss200:0.167545 lr:6.00e-05[train] 746/33336 666(s) eta:29095(s) loss:0.230728 loss200:0.167883 lr:6.00e-05[train] 747/33336 667(s) eta:29098(s) loss:0.230651 loss200:0.167841 lr:6.00e-05[train] 748/33336 668(s) eta:29102(s) loss:0.230814 loss200:0.168825 lr:6.00e-05[train] 749/33336 669(s) eta:29106(s) loss:0.230754 loss200:0.168348 lr:6.00e-05[train] 750/33336 670(s) eta:29110(s) loss:0.230526 loss200:0.167150 lr:6.00e-05[train] 751/33336 671(s) eta:29113(s) loss:0.230478 loss200:0.167500 lr:6.00e-05[train] 752/33336 672(s) eta:29117(s) loss:0.230396 loss200:0.167073 lr:6.00e-05[train] 753/33336 673(s) eta:29121(s) loss:0.230267 loss200:0.167151 lr:6.00e-05[train] 754/33336 673(s) eta:29081(s) loss:0.230098 loss200:0.166512 lr:6.00e-05[train] 755/33336 674(s) eta:29085(s) loss:0.229975 loss200:0.166271 lr:6.00e-05[train] 756/33336 675(s) eta:29089(s) loss:0.229717 loss200:0.165753 lr:6.00e-05[train] 757/33336 676(s) eta:29093(s) loss:0.229545 loss200:0.165334 lr:6.00e-05[train] 758/33336 677(s) eta:29096(s) loss:0.229460 loss200:0.165196 lr:6.00e-05[train] 759/33336 678(s) eta:29100(s) loss:0.229399 loss200:0.165452 lr:6.00e-05[train] 760/33336 679(s) eta:29104(s) loss:0.229250 loss200:0.165676 lr:6.00e-05[train] 761/33336 680(s) eta:29107(s) loss:0.229400 loss200:0.166770 lr:6.00e-05[train] 762/33336 680(s) eta:29068(s) loss:0.229247 loss200:0.166548 lr:6.00e-05[train] 763/33336 681(s) eta:29072(s) loss:0.229121 loss200:0.166366 lr:6.00e-05[train] 764/33336 682(s) eta:29076(s) loss:0.229041 loss200:0.166655 lr:6.00e-05[train] 765/33336 683(s) eta:29079(s) loss:0.229050 loss200:0.166651 lr:6.00e-05[train] 766/33336 684(s) eta:29083(s) loss:0.228943 loss200:0.166266 lr:6.00e-05[train] 767/33336 685(s) eta:29087(s) loss:0.228899 loss200:0.166092 lr:6.00e-05[train] 768/33336 686(s) eta:29090(s) loss:0.228819 loss200:0.166368 lr:6.00e-05[train] 769/33336 687(s) eta:29094(s) loss:0.228647 loss200:0.166314 lr:6.00e-05[train] 770/33336 687(s) eta:29055(s) loss:0.228480 loss200:0.165719 lr:6.00e-05[train] 771/33336 688(s) eta:29059(s) loss:0.228445 loss200:0.166294 lr:6.00e-05[train] 772/33336 689(s) eta:29062(s) loss:0.228373 loss200:0.166281 lr:6.00e-05[train] 773/33336 690(s) eta:29066(s) loss:0.228181 loss200:0.165942 lr:6.00e-05[train] 774/33336 691(s) eta:29070(s) loss:0.228110 loss200:0.165835 lr:6.00e-05[train] 775/33336 692(s) eta:29073(s) loss:0.227996 loss200:0.165932 lr:6.00e-05[train] 776/33336 693(s) eta:29077(s) loss:0.228001 loss200:0.166677 lr:6.00e-05[train] 777/33336 694(s) eta:29081(s) loss:0.227874 loss200:0.166549 lr:6.00e-05[train] 778/33336 695(s) eta:29084(s) loss:0.227698 loss200:0.166558 lr:6.00e-05[train] 779/33336 695(s) eta:29046(s) loss:0.227540 loss200:0.165835 lr:6.00e-05[train] 780/33336 696(s) eta:29049(s) loss:0.227696 loss200:0.165551 lr:6.00e-05[train] 781/33336 697(s) eta:29053(s) loss:0.227599 loss200:0.165421 lr:6.00e-05[train] 782/33336 698(s) eta:29057(s) loss:0.227689 loss200:0.166146 lr:6.00e-05[train] 783/33336 699(s) eta:29060(s) loss:0.227532 loss200:0.166101 lr:6.00e-05[train] 784/33336 700(s) eta:29064(s) loss:0.227419 loss200:0.165588 lr:6.00e-05[train] 785/33336 701(s) eta:29067(s) loss:0.227312 loss200:0.165556 lr:6.00e-05[train] 786/33336 702(s) eta:29071(s) loss:0.227193 loss200:0.165320 lr:6.00e-05[train] 787/33336 703(s) eta:29074(s) loss:0.227144 loss200:0.165508 lr:6.00e-05[train] 788/33336 704(s) eta:29078(s) loss:0.227045 loss200:0.165264 lr:6.00e-05[train] 789/33336 704(s) eta:29040(s) loss:0.227067 loss200:0.165000 lr:6.00e-05[train] 790/33336 705(s) eta:29044(s) loss:0.226949 loss200:0.164321 lr:6.00e-05[train] 791/33336 706(s) eta:29047(s) loss:0.226848 loss200:0.164018 lr:6.00e-05[train] 792/33336 707(s) eta:29051(s) loss:0.226865 loss200:0.164710 lr:6.00e-05[train] 793/33336 708(s) eta:29054(s) loss:0.226913 loss200:0.164580 lr:6.00e-05[train] 794/33336 709(s) eta:29058(s) loss:0.227029 loss200:0.164692 lr:6.00e-05[train] 795/33336 710(s) eta:29061(s) loss:0.227032 loss200:0.164963 lr:6.00e-05[train] 796/33336 710(s) eta:29024(s) loss:0.226813 loss200:0.164408 lr:6.00e-05[train] 797/33336 711(s) eta:29027(s) loss:0.226734 loss200:0.164267 lr:6.00e-05[train] 798/33336 712(s) eta:29031(s) loss:0.226618 loss200:0.164072 lr:6.00e-05[train] 799/33336 713(s) eta:29034(s) loss:0.226645 loss200:0.164688 lr:6.00e-05[train] 800/33336 714(s) eta:29038(s) loss:0.226698 loss200:0.165079 lr:6.00e-05[train] 801/33336 715(s) eta:29041(s) loss:0.226775 loss200:0.165811 lr:6.00e-05[train] 802/33336 716(s) eta:29045(s) loss:0.226589 loss200:0.165589 lr:6.00e-05[train] 803/33336 717(s) eta:29048(s) loss:0.226490 loss200:0.165144 lr:6.00e-05[train] 804/33336 718(s) eta:29052(s) loss:0.226436 loss200:0.165480 lr:6.00e-05[train] 805/33336 718(s) eta:29015(s) loss:0.226494 loss200:0.166383 lr:6.00e-05[train] 806/33336 719(s) eta:29018(s) loss:0.226420 loss200:0.165953 lr:6.00e-05[train] 807/33336 720(s) eta:29022(s) loss:0.226427 loss200:0.166410 lr:6.00e-05[train] 808/33336 721(s) eta:29025(s) loss:0.226326 loss200:0.165830 lr:6.00e-05[train] 809/33336 722(s) eta:29029(s) loss:0.226142 loss200:0.165336 lr:6.00e-05[train] 810/33336 723(s) eta:29032(s) loss:0.225984 loss200:0.165055 lr:6.00e-05[train] 811/33336 724(s) eta:29035(s) loss:0.225866 loss200:0.164654 lr:6.00e-05[train] 812/33336 725(s) eta:29039(s) loss:0.225681 loss200:0.164257 lr:6.00e-05[train] 813/33336 725(s) eta:29002(s) loss:0.225482 loss200:0.163463 lr:6.00e-05[train] 814/33336 726(s) eta:29006(s) loss:0.225299 loss200:0.163170 lr:6.00e-05[train] 815/33336 727(s) eta:29009(s) loss:0.225116 loss200:0.162092 lr:6.00e-05[train] 816/33336 728(s) eta:29012(s) loss:0.224943 loss200:0.161084 lr:6.00e-05[train] 817/33336 729(s) eta:29016(s) loss:0.224765 loss200:0.160768 lr:6.00e-05[train] 818/33336 730(s) eta:29019(s) loss:0.224596 loss200:0.159986 lr:6.00e-05[train] 819/33336 731(s) eta:29023(s) loss:0.224502 loss200:0.160205 lr:6.00e-05[train] 820/33336 732(s) eta:29026(s) loss:0.224549 loss200:0.161035 lr:6.00e-05[train] 821/33336 733(s) eta:29029(s) loss:0.224572 loss200:0.161209 lr:6.00e-05[train] 822/33336 733(s) eta:28993(s) loss:0.224417 loss200:0.160233 lr:6.00e-05[train] 823/33336 734(s) eta:28997(s) loss:0.224314 loss200:0.160056 lr:6.00e-05[train] 824/33336 735(s) eta:29000(s) loss:0.224333 loss200:0.160694 lr:6.00e-05[train] 825/33336 736(s) eta:29003(s) loss:0.224272 loss200:0.160871 lr:6.00e-05[train] 826/33336 737(s) eta:29007(s) loss:0.224124 loss200:0.160080 lr:6.00e-05[train] 827/33336 738(s) eta:29010(s) loss:0.224019 loss200:0.159767 lr:6.00e-05[train] 828/33336 739(s) eta:29013(s) loss:0.224065 loss200:0.160465 lr:6.00e-05[train] 829/33336 740(s) eta:29017(s) loss:0.223909 loss200:0.160453 lr:6.00e-05[train] 830/33336 741(s) eta:29020(s) loss:0.223872 loss200:0.160446 lr:6.00e-05[train] 831/33336 741(s) eta:28984(s) loss:0.223801 loss200:0.160289 lr:6.00e-05[train] 832/33336 742(s) eta:28987(s) loss:0.223778 loss200:0.160529 lr:6.00e-05[train] 833/33336 743(s) eta:28991(s) loss:0.223686 loss200:0.160673 lr:6.00e-05[train] 834/33336 744(s) eta:28994(s) loss:0.223583 loss200:0.160462 lr:6.00e-05[train] 835/33336 745(s) eta:28997(s) loss:0.223451 loss200:0.160677 lr:6.00e-05[train] 836/33336 746(s) eta:29001(s) loss:0.223263 loss200:0.160441 lr:6.00e-05[train] 837/33336 747(s) eta:29004(s) loss:0.223292 loss200:0.160485 lr:6.00e-05[train] 838/33336 748(s) eta:29007(s) loss:0.223131 loss200:0.160480 lr:6.00e-05[train] 839/33336 748(s) eta:28972(s) loss:0.223149 loss200:0.160551 lr:6.00e-05[train] 840/33336 749(s) eta:28975(s) loss:0.222996 loss200:0.159950 lr:6.00e-05[train] 841/33336 750(s) eta:28978(s) loss:0.222794 loss200:0.159705 lr:6.00e-05[train] 842/33336 751(s) eta:28982(s) loss:0.222764 loss200:0.160381 lr:6.00e-05[train] 843/33336 752(s) eta:28985(s) loss:0.222630 loss200:0.160541 lr:6.00e-05[train] 844/33336 753(s) eta:28988(s) loss:0.222419 loss200:0.159389 lr:6.00e-05[train] 845/33336 754(s) eta:28991(s) loss:0.222353 loss200:0.159670 lr:6.00e-05[train] 846/33336 755(s) eta:28995(s) loss:0.222243 loss200:0.159828 lr:6.00e-05[train] 847/33336 755(s) eta:28960(s) loss:0.222031 loss200:0.159378 lr:6.00e-05[train] 848/33336 756(s) eta:28963(s) loss:0.221923 loss200:0.159543 lr:6.00e-05[train] 849/33336 757(s) eta:28966(s) loss:0.221917 loss200:0.160357 lr:6.00e-05[train] 850/33336 758(s) eta:28969(s) loss:0.221916 loss200:0.160642 lr:6.00e-05[train] 851/33336 759(s) eta:28973(s) loss:0.221975 loss200:0.160650 lr:6.00e-05[train] 852/33336 760(s) eta:28976(s) loss:0.221806 loss200:0.160527 lr:6.00e-05[train] 853/33336 761(s) eta:28979(s) loss:0.221853 loss200:0.161491 lr:6.00e-05[train] 854/33336 762(s) eta:28982(s) loss:0.221677 loss200:0.161458 lr:6.00e-05[train] 855/33336 763(s) eta:28985(s) loss:0.221513 loss200:0.161253 lr:6.00e-05[train] 856/33336 763(s) eta:28951(s) loss:0.221357 loss200:0.161278 lr:6.00e-05[train] 857/33336 764(s) eta:28954(s) loss:0.221183 loss200:0.160067 lr:6.00e-05[train] 858/33336 765(s) eta:28957(s) loss:0.221011 loss200:0.159479 lr:6.00e-05[train] 859/33336 766(s) eta:28960(s) loss:0.221014 loss200:0.160058 lr:6.00e-05[train] 860/33336 767(s) eta:28964(s) loss:0.220811 loss200:0.159531 lr:6.00e-05[train] 861/33336 768(s) eta:28967(s) loss:0.220780 loss200:0.160253 lr:6.00e-05[train] 862/33336 769(s) eta:28970(s) loss:0.220656 loss200:0.159585 lr:6.00e-05[train] 863/33336 770(s) eta:28973(s) loss:0.220530 loss200:0.159824 lr:6.00e-05[train] 864/33336 770(s) eta:28939(s) loss:0.220444 loss200:0.159152 lr:6.00e-05[train] 865/33336 771(s) eta:28942(s) loss:0.220281 loss200:0.158719 lr:6.00e-05[train] 866/33336 772(s) eta:28945(s) loss:0.220126 loss200:0.157905 lr:6.00e-05[train] 867/33336 773(s) eta:28948(s) loss:0.220064 loss200:0.157185 lr:6.00e-05[train] 868/33336 774(s) eta:28951(s) loss:0.220051 loss200:0.157261 lr:6.00e-05[train] 869/33336 775(s) eta:28955(s) loss:0.220054 loss200:0.157938 lr:6.00e-05[train] 870/33336 776(s) eta:28958(s) loss:0.220193 loss200:0.159030 lr:6.00e-05[train] 871/33336 777(s) eta:28961(s) loss:0.220070 loss200:0.158583 lr:6.00e-05[train] 872/33336 777(s) eta:28927(s) loss:0.219899 loss200:0.158382 lr:6.00e-05[train] 873/33336 778(s) eta:28930(s) loss:0.219830 loss200:0.158359 lr:6.00e-05[train] 874/33336 779(s) eta:28933(s) loss:0.219653 loss200:0.158278 lr:6.00e-05[train] 875/33336 780(s) eta:28936(s) loss:0.220153 loss200:0.161127 lr:6.00e-05[train] 876/33336 781(s) eta:28939(s) loss:0.219982 loss200:0.160527 lr:6.00e-05[train] 877/33336 782(s) eta:28942(s) loss:0.219812 loss200:0.159403 lr:6.00e-05[train] 878/33336 783(s) eta:28946(s) loss:0.219713 loss200:0.158945 lr:6.00e-05[train] 879/33336 784(s) eta:28949(s) loss:0.219768 loss200:0.159904 lr:6.00e-05[train] 880/33336 784(s) eta:28915(s) loss:0.219859 loss200:0.160821 lr:6.00e-05[train] 881/33336 785(s) eta:28918(s) loss:0.219775 loss200:0.159249 lr:6.00e-05[train] 882/33336 786(s) eta:28921(s) loss:0.219985 loss200:0.160793 lr:6.00e-05[train] 883/33336 787(s) eta:28924(s) loss:0.219920 loss200:0.160629 lr:6.00e-05[train] 884/33336 788(s) eta:28927(s) loss:0.220010 loss200:0.161189 lr:6.00e-05[train] 885/33336 789(s) eta:28930(s) loss:0.219899 loss200:0.161326 lr:6.00e-05[train] 886/33336 790(s) eta:28933(s) loss:0.219773 loss200:0.161428 lr:6.00e-05[train] 887/33336 791(s) eta:28937(s) loss:0.219773 loss200:0.162100 lr:6.00e-05[train] 888/33336 792(s) eta:28940(s) loss:0.219667 loss200:0.161198 lr:6.00e-05[train] 889/33336 792(s) eta:28906(s) loss:0.219493 loss200:0.161125 lr:6.00e-05[train] 890/33336 793(s) eta:28909(s) loss:0.219370 loss200:0.161163 lr:6.00e-05[train] 891/33336 794(s) eta:28912(s) loss:0.219212 loss200:0.161214 lr:6.00e-05[train] 892/33336 795(s) eta:28915(s) loss:0.219217 loss200:0.161841 lr:6.00e-05[train] 893/33336 796(s) eta:28918(s) loss:0.219354 loss200:0.162340 lr:6.00e-05[train] 894/33336 797(s) eta:28922(s) loss:0.219448 loss200:0.163564 lr:6.00e-05[train] 895/33336 798(s) eta:28925(s) loss:0.219356 loss200:0.163996 lr:6.00e-05[train] 896/33336 799(s) eta:28928(s) loss:0.219265 loss200:0.163443 lr:6.00e-05[train] 897/33336 799(s) eta:28894(s) loss:0.219395 loss200:0.164273 lr:6.00e-05[train] 898/33336 800(s) eta:28897(s) loss:0.219260 loss200:0.164105 lr:6.00e-05[train] 899/33336 801(s) eta:28901(s) loss:0.219277 loss200:0.164608 lr:6.00e-05[train] 900/33336 802(s) eta:28904(s) loss:0.219123 loss200:0.164434 lr:6.00e-05[train] 901/33336 803(s) eta:28907(s) loss:0.219301 loss200:0.166025 lr:6.00e-05[train] 902/33336 804(s) eta:28910(s) loss:0.219111 loss200:0.165534 lr:6.00e-05[train] 903/33336 805(s) eta:28913(s) loss:0.219131 loss200:0.165995 lr:6.00e-05[train] 904/33336 806(s) eta:28916(s) loss:0.219028 loss200:0.166243 lr:6.00e-05[train] 905/33336 807(s) eta:28919(s) loss:0.219044 loss200:0.166537 lr:6.00e-05[train] 906/33336 807(s) eta:28886(s) loss:0.219024 loss200:0.167173 lr:6.00e-05[train] 907/33336 808(s) eta:28889(s) loss:0.218881 loss200:0.166710 lr:6.00e-05[train] 908/33336 809(s) eta:28892(s) loss:0.218790 loss200:0.166846 lr:6.00e-05[train] 909/33336 810(s) eta:28895(s) loss:0.218982 loss200:0.167745 lr:6.00e-05[train] 910/33336 811(s) eta:28898(s) loss:0.218853 loss200:0.167560 lr:6.00e-05[train] 911/33336 812(s) eta:28901(s) loss:0.218709 loss200:0.166793 lr:6.00e-05[train] 912/33336 813(s) eta:28904(s) loss:0.218636 loss200:0.166791 lr:6.00e-05[train] 913/33336 813(s) eta:28871(s) loss:0.218461 loss200:0.166503 lr:6.00e-05[train] 914/33336 814(s) eta:28874(s) loss:0.218506 loss200:0.166724 lr:6.00e-05[train] 915/33336 815(s) eta:28877(s) loss:0.218719 loss200:0.168067 lr:6.00e-05[train] 916/33336 816(s) eta:28880(s) loss:0.218708 loss200:0.167482 lr:6.00e-05[train] 917/33336 817(s) eta:28883(s) loss:0.218754 loss200:0.167398 lr:6.00e-05[train] 918/33336 818(s) eta:28886(s) loss:0.218720 loss200:0.167115 lr:6.00e-05[train] 919/33336 819(s) eta:28889(s) loss:0.218677 loss200:0.167563 lr:6.00e-05[train] 920/33336 820(s) eta:28892(s) loss:0.218662 loss200:0.167103 lr:6.00e-05[train] 921/33336 820(s) eta:28860(s) loss:0.218619 loss200:0.167742 lr:6.00e-05[train] 922/33336 821(s) eta:28863(s) loss:0.218651 loss200:0.167988 lr:6.00e-05[train] 923/33336 822(s) eta:28866(s) loss:0.218565 loss200:0.166010 lr:6.00e-05[train] 924/33336 823(s) eta:28869(s) loss:0.218503 loss200:0.165997 lr:6.00e-05[train] 925/33336 824(s) eta:28872(s) loss:0.218428 loss200:0.166409 lr:6.00e-05[train] 926/33336 825(s) eta:28875(s) loss:0.218332 loss200:0.166175 lr:6.00e-05[train] 927/33336 826(s) eta:28877(s) loss:0.218229 loss200:0.165383 lr:6.00e-05[train] 928/33336 827(s) eta:28880(s) loss:0.218201 loss200:0.165288 lr:6.00e-05[train] 929/33336 827(s) eta:28848(s) loss:0.218156 loss200:0.165386 lr:6.00e-05[train] 930/33336 828(s) eta:28851(s) loss:0.218091 loss200:0.165668 lr:6.00e-05[train] 931/33336 829(s) eta:28854(s) loss:0.218181 loss200:0.166388 lr:6.00e-05[train] 932/33336 830(s) eta:28857(s) loss:0.218140 loss200:0.166267 lr:6.00e-05[train] 933/33336 831(s) eta:28860(s) loss:0.217984 loss200:0.165928 lr:6.00e-05[train] 934/33336 832(s) eta:28863(s) loss:0.217992 loss200:0.166453 lr:6.00e-05[train] 935/33336 833(s) eta:28866(s) loss:0.217985 loss200:0.166774 lr:6.00e-05[train] 936/33336 834(s) eta:28869(s) loss:0.217819 loss200:0.166369 lr:6.00e-05[train] 937/33336 835(s) eta:28872(s) loss:0.217712 loss200:0.166000 lr:6.00e-05[train] 938/33336 836(s) eta:28874(s) loss:0.217716 loss200:0.166513 lr:6.00e-05[train] 939/33336 836(s) eta:28843(s) loss:0.217555 loss200:0.165576 lr:6.00e-05[train] 940/33336 837(s) eta:28846(s) loss:0.217488 loss200:0.165126 lr:6.00e-05[train] 941/33336 838(s) eta:28849(s) loss:0.217385 loss200:0.164877 lr:6.00e-05[train] 942/33336 839(s) eta:28851(s) loss:0.217245 loss200:0.164879 lr:6.00e-05[train] 943/33336 840(s) eta:28854(s) loss:0.217143 loss200:0.165166 lr:6.00e-05[train] 944/33336 841(s) eta:28857(s) loss:0.217049 loss200:0.165016 lr:6.00e-05[train] 945/33336 842(s) eta:28860(s) loss:0.216952 loss200:0.165449 lr:6.00e-05[train] 946/33336 843(s) eta:28863(s) loss:0.216828 loss200:0.164981 lr:6.00e-05[train] 947/33336 844(s) eta:28866(s) loss:0.216898 loss200:0.165534 lr:6.00e-05[train] 948/33336 844(s) eta:28834(s) loss:0.216910 loss200:0.164908 lr:6.00e-05[train] 949/33336 845(s) eta:28837(s) loss:0.216754 loss200:0.164323 lr:6.00e-05[train] 950/33336 846(s) eta:28840(s) loss:0.216723 loss200:0.164963 lr:6.00e-05[train] 951/33336 847(s) eta:28843(s) loss:0.216675 loss200:0.164844 lr:6.00e-05[train] 952/33336 848(s) eta:28846(s) loss:0.216723 loss200:0.165311 lr:6.00e-05[train] 953/33336 849(s) eta:28849(s) loss:0.216684 loss200:0.165543 lr:6.00e-05[train] 954/33336 850(s) eta:28851(s) loss:0.216526 loss200:0.165359 lr:6.00e-05[train] 955/33336 850(s) eta:28820(s) loss:0.216409 loss200:0.165197 lr:6.00e-05[train] 956/33336 851(s) eta:28823(s) loss:0.216339 loss200:0.165772 lr:6.00e-05[train] 957/33336 852(s) eta:28826(s) loss:0.216392 loss200:0.166609 lr:6.00e-05[train] 958/33336 853(s) eta:28829(s) loss:0.216530 loss200:0.167529 lr:6.00e-05[train] 959/33336 854(s) eta:28832(s) loss:0.216583 loss200:0.167944 lr:6.00e-05[train] 960/33336 855(s) eta:28834(s) loss:0.216531 loss200:0.168198 lr:6.00e-05[train] 961/33336 856(s) eta:28837(s) loss:0.216418 loss200:0.167025 lr:6.00e-05[train] 962/33336 857(s) eta:28840(s) loss:0.216247 loss200:0.166716 lr:6.00e-05[train] 963/33336 857(s) eta:28809(s) loss:0.216084 loss200:0.166348 lr:6.00e-05[train] 964/33336 858(s) eta:28812(s) loss:0.215959 loss200:0.165984 lr:6.00e-05[train] 965/33336 859(s) eta:28815(s) loss:0.215911 loss200:0.165656 lr:6.00e-05[train] 966/33336 860(s) eta:28818(s) loss:0.216076 loss200:0.166798 lr:6.00e-05[train] 967/33336 861(s) eta:28820(s) loss:0.215904 loss200:0.166071 lr:6.00e-05[train] 968/33336 862(s) eta:28823(s) loss:0.215846 loss200:0.166031 lr:6.00e-05[train] 969/33336 863(s) eta:28826(s) loss:0.215712 loss200:0.165977 lr:6.00e-05[train] 970/33336 864(s) eta:28829(s) loss:0.215549 loss200:0.165768 lr:6.00e-05[train] 971/33336 865(s) eta:28831(s) loss:0.215419 loss200:0.165205 lr:6.00e-05[train] 972/33336 866(s) eta:28834(s) loss:0.215335 loss200:0.165007 lr:6.00e-05[train] 973/33336 866(s) eta:28804(s) loss:0.215197 loss200:0.165010 lr:6.00e-05[train] 974/33336 867(s) eta:28806(s) loss:0.215113 loss200:0.164814 lr:6.00e-05[train] 975/33336 868(s) eta:28809(s) loss:0.215063 loss200:0.164946 lr:6.00e-05[train] 976/33336 869(s) eta:28812(s) loss:0.214930 loss200:0.164214 lr:6.00e-05[train] 977/33336 870(s) eta:28815(s) loss:0.214802 loss200:0.164017 lr:6.00e-05[train] 978/33336 871(s) eta:28817(s) loss:0.214640 loss200:0.163847 lr:6.00e-05[train] 979/33336 872(s) eta:28820(s) loss:0.214578 loss200:0.164093 lr:6.00e-05[train] 980/33336 872(s) eta:28790(s) loss:0.214550 loss200:0.163283 lr:6.00e-05[train] 981/33336 873(s) eta:28792(s) loss:0.214401 loss200:0.162865 lr:6.00e-05[train] 982/33336 874(s) eta:28795(s) loss:0.214337 loss200:0.162134 lr:6.00e-05[train] 983/33336 875(s) eta:28798(s) loss:0.214343 loss200:0.162707 lr:6.00e-05[train] 984/33336 876(s) eta:28801(s) loss:0.214257 loss200:0.162663 lr:6.00e-05[train] 985/33336 877(s) eta:28803(s) loss:0.214224 loss200:0.162855 lr:6.00e-05[train] 986/33336 878(s) eta:28806(s) loss:0.214048 loss200:0.162390 lr:6.00e-05[train] 987/33336 879(s) eta:28809(s) loss:0.213914 loss200:0.161857 lr:6.00e-05[train] 988/33336 879(s) eta:28779(s) loss:0.213858 loss200:0.161900 lr:6.00e-05[train] 989/33336 880(s) eta:28781(s) loss:0.213773 loss200:0.161324 lr:6.00e-05[train] 990/33336 881(s) eta:28784(s) loss:0.213620 loss200:0.160970 lr:6.00e-05[train] 991/33336 882(s) eta:28787(s) loss:0.213529 loss200:0.160857 lr:6.00e-05[train] 992/33336 883(s) eta:28790(s) loss:0.213362 loss200:0.159892 lr:6.00e-05[train] 993/33336 884(s) eta:28792(s) loss:0.213343 loss200:0.159540 lr:6.00e-05[train] 994/33336 885(s) eta:28795(s) loss:0.213287 loss200:0.158733 lr:6.00e-05[train] 995/33336 886(s) eta:28798(s) loss:0.213197 loss200:0.158202 lr:6.00e-05[train] 996/33336 886(s) eta:28768(s) loss:0.213080 loss200:0.158424 lr:6.00e-05[train] 997/33336 887(s) eta:28771(s) loss:0.212945 loss200:0.157995 lr:6.00e-05[train] 998/33336 888(s) eta:28773(s) loss:0.212815 loss200:0.157742 lr:6.00e-05[train] 999/33336 889(s) eta:28776(s) loss:0.212686 loss200:0.156921 lr:6.00e-05[train] 1000/33336 890(s) eta:28779(s) loss:0.212528 loss200:0.155845 lr:6.00e-05[train] 1001/33336 891(s) eta:28781(s) loss:0.212617 loss200:0.155915 lr:6.00e-05[train] 1002/33336 892(s) eta:28784(s) loss:0.212687 loss200:0.156938 lr:6.00e-05[train] 1003/33336 893(s) eta:28787(s) loss:0.212552 loss200:0.156588 lr:6.00e-05[train] 1004/33336 894(s) eta:28789(s) loss:0.212463 loss200:0.156292 lr:6.00e-05[train] 1005/33336 894(s) eta:28760(s) loss:0.212345 loss200:0.155398 lr:6.00e-05[train] 1006/33336 895(s) eta:28762(s) loss:0.212213 loss200:0.154958 lr:6.00e-05[train] 1007/33336 896(s) eta:28765(s) loss:0.212054 loss200:0.154062 lr:6.00e-05[train] 1008/33336 897(s) eta:28768(s) loss:0.211933 loss200:0.153788 lr:6.00e-05[train] 1009/33336 898(s) eta:28770(s) loss:0.211830 loss200:0.153937 lr:6.00e-05[train] 1010/33336 899(s) eta:28773(s) loss:0.211691 loss200:0.153806 lr:6.00e-05[train] 1011/33336 900(s) eta:28775(s) loss:0.211575 loss200:0.153626 lr:6.00e-05[train] 1012/33336 901(s) eta:28778(s) loss:0.211536 loss200:0.154107 lr:6.00e-05[train] 1013/33336 901(s) eta:28749(s) loss:0.211398 loss200:0.154149 lr:6.00e-05[train] 1014/33336 902(s) eta:28751(s) loss:0.211383 loss200:0.154745 lr:6.00e-05[train] 1015/33336 903(s) eta:28754(s) loss:0.211277 loss200:0.154882 lr:6.00e-05[train] 1016/33336 904(s) eta:28757(s) loss:0.211186 loss200:0.155058 lr:6.00e-05[train] 1017/33336 905(s) eta:28759(s) loss:0.211179 loss200:0.155679 lr:6.00e-05[train] 1018/33336 906(s) eta:28762(s) loss:0.211072 loss200:0.155759 lr:6.00e-05[train] 1019/33336 907(s) eta:28764(s) loss:0.211333 loss200:0.157406 lr:6.00e-05[train] 1020/33336 908(s) eta:28767(s) loss:0.211310 loss200:0.157029 lr:6.00e-05[train] 1021/33336 908(s) eta:28738(s) loss:0.211272 loss200:0.156676 lr:6.00e-05[train] 1022/33336 909(s) eta:28741(s) loss:0.211177 loss200:0.156764 lr:6.00e-05[train] 1023/33336 910(s) eta:28743(s) loss:0.211111 loss200:0.156780 lr:6.00e-05[train] 1024/33336 911(s) eta:28746(s) loss:0.210985 loss200:0.155994 lr:6.00e-05[train] 1025/33336 912(s) eta:28748(s) loss:0.210852 loss200:0.155496 lr:6.00e-05[train] 1026/33336 913(s) eta:28751(s) loss:0.210768 loss200:0.155609 lr:6.00e-05[train] 1027/33336 914(s) eta:28754(s) loss:0.210728 loss200:0.155769 lr:6.00e-05[train] 1028/33336 915(s) eta:28756(s) loss:0.210742 loss200:0.155586 lr:6.00e-05[train] 1029/33336 915(s) eta:28727(s) loss:0.210675 loss200:0.155816 lr:6.00e-05[train] 1030/33336 916(s) eta:28730(s) loss:0.210681 loss200:0.155939 lr:6.00e-05[train] 1031/33336 917(s) eta:28732(s) loss:0.210593 loss200:0.155715 lr:6.00e-05[train] 1032/33336 918(s) eta:28735(s) loss:0.210466 loss200:0.155090 lr:6.00e-05[train] 1033/33336 919(s) eta:28738(s) loss:0.210347 loss200:0.154786 lr:6.00e-05[train] 1034/33336 920(s) eta:28740(s) loss:0.210228 loss200:0.154536 lr:6.00e-05[train] 1035/33336 921(s) eta:28743(s) loss:0.210121 loss200:0.154470 lr:6.00e-05[train] 1036/33336 922(s) eta:28745(s) loss:0.210003 loss200:0.154574 lr:6.00e-05[train] 1037/33336 922(s) eta:28717(s) loss:0.209866 loss200:0.153677 lr:6.00e-05[train] 1038/33336 923(s) eta:28719(s) loss:0.209922 loss200:0.154575 lr:6.00e-05[train] 1039/33336 924(s) eta:28722(s) loss:0.209978 loss200:0.154722 lr:6.00e-05[train] 1040/33336 925(s) eta:28724(s) loss:0.209874 loss200:0.154760 lr:6.00e-05[train] 1041/33336 926(s) eta:28727(s) loss:0.209852 loss200:0.155432 lr:6.00e-05[train] 1042/33336 927(s) eta:28729(s) loss:0.209713 loss200:0.154768 lr:6.00e-05[train] 1043/33336 928(s) eta:28732(s) loss:0.209703 loss200:0.155216 lr:6.00e-05[train] 1044/33336 928(s) eta:28704(s) loss:0.209646 loss200:0.155740 lr:6.00e-05[train] 1045/33336 929(s) eta:28706(s) loss:0.209533 loss200:0.155371 lr:6.00e-05[train] 1046/33336 930(s) eta:28709(s) loss:0.209376 loss200:0.154948 lr:6.00e-05[train] 1047/33336 931(s) eta:28711(s) loss:0.209282 loss200:0.155290 lr:6.00e-05[train] 1048/33336 932(s) eta:28714(s) loss:0.209179 loss200:0.155142 lr:6.00e-05[train] 1049/33336 933(s) eta:28716(s) loss:0.209389 loss200:0.156206 lr:6.00e-05[train] 1050/33336 934(s) eta:28719(s) loss:0.209432 loss200:0.156374 lr:6.00e-05[train] 1051/33336 934(s) eta:28690(s) loss:0.209289 loss200:0.155312 lr:6.00e-05[train] 1052/33336 935(s) eta:28693(s) loss:0.209220 loss200:0.155599 lr:6.00e-05[train] 1053/33336 936(s) eta:28696(s) loss:0.209466 loss200:0.156638 lr:6.00e-05[train] 1054/33336 937(s) eta:28698(s) loss:0.209428 loss200:0.157125 lr:6.00e-05[train] 1055/33336 938(s) eta:28701(s) loss:0.209291 loss200:0.157044 lr:6.00e-05[train] 1056/33336 939(s) eta:28703(s) loss:0.209212 loss200:0.157233 lr:6.00e-05[train] 1057/33336 940(s) eta:28706(s) loss:0.209174 loss200:0.157716 lr:6.00e-05[train] 1058/33336 941(s) eta:28708(s) loss:0.209082 loss200:0.157906 lr:6.00e-05[train] 1059/33336 941(s) eta:28680(s) loss:0.209114 loss200:0.158002 lr:6.00e-05[train] 1060/33336 942(s) eta:28683(s) loss:0.209004 loss200:0.158232 lr:6.00e-05[train] 1061/33336 943(s) eta:28685(s) loss:0.209150 loss200:0.159083 lr:6.00e-05[train] 1062/33336 944(s) eta:28688(s) loss:0.209223 loss200:0.159944 lr:6.00e-05[train] 1063/33336 945(s) eta:28690(s) loss:0.209162 loss200:0.160107 lr:6.00e-05[train] 1064/33336 946(s) eta:28692(s) loss:0.209045 loss200:0.159802 lr:6.00e-05[train] 1065/33336 947(s) eta:28695(s) loss:0.208936 loss200:0.159865 lr:6.00e-05[train] 1066/33336 948(s) eta:28697(s) loss:0.208870 loss200:0.160128 lr:6.00e-05[train] 1067/33336 949(s) eta:28700(s) loss:0.208787 loss200:0.159902 lr:6.00e-05[train] 1068/33336 949(s) eta:28672(s) loss:0.208760 loss200:0.159756 lr:6.00e-05[train] 1069/33336 950(s) eta:28675(s) loss:0.208692 loss200:0.159324 lr:6.00e-05[train] 1070/33336 951(s) eta:28677(s) loss:0.208598 loss200:0.158162 lr:6.00e-05[train] 1071/33336 952(s) eta:28680(s) loss:0.208705 loss200:0.159213 lr:6.00e-05[train] 1072/33336 953(s) eta:28682(s) loss:0.208582 loss200:0.159238 lr:6.00e-05[train] 1073/33336 954(s) eta:28684(s) loss:0.208562 loss200:0.159377 lr:6.00e-05[train] 1074/33336 955(s) eta:28687(s) loss:0.208426 loss200:0.159366 lr:6.00e-05[train] 1075/33336 955(s) eta:28659(s) loss:0.208315 loss200:0.156528 lr:6.00e-05[train] 1076/33336 956(s) eta:28662(s) loss:0.208192 loss200:0.156556 lr:6.00e-05[train] 1077/33336 957(s) eta:28664(s) loss:0.208112 loss200:0.156804 lr:6.00e-05[train] 1078/33336 958(s) eta:28667(s) loss:0.207979 loss200:0.156467 lr:6.00e-05[train] 1079/33336 959(s) eta:28669(s) loss:0.207888 loss200:0.155676 lr:6.00e-05[train] 1080/33336 960(s) eta:28672(s) loss:0.207805 loss200:0.154769 lr:6.00e-05[train] 1081/33336 961(s) eta:28674(s) loss:0.207759 loss200:0.154827 lr:6.00e-05[train] 1082/33336 962(s) eta:28676(s) loss:0.207623 loss200:0.153109 lr:6.00e-05[train] 1083/33336 962(s) eta:28649(s) loss:0.207503 loss200:0.152683 lr:6.00e-05[train] 1084/33336 963(s) eta:28651(s) loss:0.207449 loss200:0.151930 lr:6.00e-05[train] 1085/33336 964(s) eta:28654(s) loss:0.207494 loss200:0.152601 lr:6.00e-05[train] 1086/33336 965(s) eta:28656(s) loss:0.207555 loss200:0.153430 lr:6.00e-05[train] 1087/33336 966(s) eta:28659(s) loss:0.207491 loss200:0.153023 lr:6.00e-05[train] 1088/33336 967(s) eta:28661(s) loss:0.207336 loss200:0.152587 lr:6.00e-05[train] 1089/33336 968(s) eta:28664(s) loss:0.207255 loss200:0.152856 lr:6.00e-05[train] 1090/33336 969(s) eta:28666(s) loss:0.207137 loss200:0.152699 lr:6.00e-05[train] 1091/33336 970(s) eta:28668(s) loss:0.207244 loss200:0.153931 lr:6.00e-05[train] 1092/33336 970(s) eta:28641(s) loss:0.207098 loss200:0.153049 lr:6.00e-05[train] 1093/33336 971(s) eta:28644(s) loss:0.207259 loss200:0.153254 lr:6.00e-05[train] 1094/33336 972(s) eta:28646(s) loss:0.207276 loss200:0.152864 lr:6.00e-05[train] 1095/33336 973(s) eta:28648(s) loss:0.207303 loss200:0.153365 lr:6.00e-05[train] 1096/33336 974(s) eta:28651(s) loss:0.207156 loss200:0.152906 lr:6.00e-05[train] 1097/33336 975(s) eta:28653(s) loss:0.207270 loss200:0.152893 lr:6.00e-05[train] 1098/33336 976(s) eta:28656(s) loss:0.207262 loss200:0.153389 lr:6.00e-05[train] 1099/33336 976(s) eta:28629(s) loss:0.207192 loss200:0.152873 lr:6.00e-05[train] 1100/33336 977(s) eta:28631(s) loss:0.207093 loss200:0.152956 lr:6.00e-05[train] 1101/33336 978(s) eta:28633(s) loss:0.206999 loss200:0.151577 lr:6.00e-05[train] 1102/33336 979(s) eta:28636(s) loss:0.206961 loss200:0.152161 lr:6.00e-05[train] 1103/33336 980(s) eta:28638(s) loss:0.206892 loss200:0.151637 lr:6.00e-05[train] 1104/33336 981(s) eta:28640(s) loss:0.206796 loss200:0.151508 lr:6.00e-05[train] 1105/33336 982(s) eta:28643(s) loss:0.206654 loss200:0.150592 lr:6.00e-05[train] 1106/33336 983(s) eta:28645(s) loss:0.206575 loss200:0.150186 lr:6.00e-05[train] 1107/33336 984(s) eta:28648(s) loss:0.206476 loss200:0.150220 lr:6.00e-05[train] 1108/33336 984(s) eta:28621(s) loss:0.206381 loss200:0.150042 lr:6.00e-05[train] 1109/33336 985(s) eta:28623(s) loss:0.206307 loss200:0.148702 lr:6.00e-05[train] 1110/33336 986(s) eta:28625(s) loss:0.206182 loss200:0.148532 lr:6.00e-05[train] 1111/33336 987(s) eta:28628(s) loss:0.206063 loss200:0.148459 lr:6.00e-05[train] 1112/33336 988(s) eta:28630(s) loss:0.205928 loss200:0.147978 lr:6.00e-05[train] 1113/33336 989(s) eta:28633(s) loss:0.205836 loss200:0.148202 lr:6.00e-05[train] 1114/33336 990(s) eta:28635(s) loss:0.205855 loss200:0.148037 lr:6.00e-05[train] 1115/33336 991(s) eta:28637(s) loss:0.205728 loss200:0.146297 lr:6.00e-05[train] 1116/33336 991(s) eta:28611(s) loss:0.205625 loss200:0.145709 lr:6.00e-05[train] 1117/33336 992(s) eta:28613(s) loss:0.205479 loss200:0.144615 lr:6.00e-05[train] 1118/33336 993(s) eta:28615(s) loss:0.205409 loss200:0.144310 lr:6.00e-05[train] 1119/33336 994(s) eta:28618(s) loss:0.205269 loss200:0.143655 lr:6.00e-05[train] 1120/33336 995(s) eta:28620(s) loss:0.205214 loss200:0.143357 lr:6.00e-05[train] 1121/33336 996(s) eta:28622(s) loss:0.205216 loss200:0.143494 lr:6.00e-05[train] 1122/33336 997(s) eta:28625(s) loss:0.205267 loss200:0.143569 lr:6.00e-05[train] 1123/33336 998(s) eta:28627(s) loss:0.205167 loss200:0.143339 lr:6.00e-05[train] 1124/33336 999(s) eta:28629(s) loss:0.205218 loss200:0.143840 lr:6.00e-05[train] 1125/33336 999(s) eta:28603(s) loss:0.205191 loss200:0.143969 lr:6.00e-05[train] 1126/33336 1000(s) eta:28605(s) loss:0.205046 loss200:0.143529 lr:6.00e-05[train] 1127/33336 1001(s) eta:28607(s) loss:0.204908 loss200:0.143164 lr:6.00e-05[train] 1128/33336 1002(s) eta:28610(s) loss:0.205006 loss200:0.143780 lr:6.00e-05[train] 1129/33336 1003(s) eta:28612(s) loss:0.204966 loss200:0.143703 lr:6.00e-05[train] 1130/33336 1004(s) eta:28614(s) loss:0.205009 loss200:0.144180 lr:6.00e-05[train] 1131/33336 1005(s) eta:28617(s) loss:0.205025 loss200:0.143782 lr:6.00e-05[train] 1132/33336 1005(s) eta:28591(s) loss:0.204914 loss200:0.143282 lr:6.00e-05[train] 1133/33336 1006(s) eta:28593(s) loss:0.204788 loss200:0.143228 lr:6.00e-05[train] 1134/33336 1007(s) eta:28595(s) loss:0.204689 loss200:0.142568 lr:6.00e-05[train] 1135/33336 1008(s) eta:28597(s) loss:0.204694 loss200:0.142556 lr:6.00e-05[train] 1136/33336 1009(s) eta:28600(s) loss:0.204620 loss200:0.142849 lr:6.00e-05[train] 1137/33336 1010(s) eta:28602(s) loss:0.204796 loss200:0.144282 lr:6.00e-05[train] 1138/33336 1011(s) eta:28604(s) loss:0.204665 loss200:0.143457 lr:6.00e-05[train] 1139/33336 1012(s) eta:28606(s) loss:0.204734 loss200:0.144538 lr:6.00e-05[train] 1140/33336 1013(s) eta:28609(s) loss:0.204699 loss200:0.144592 lr:6.00e-05[train] 1141/33336 1013(s) eta:28583(s) loss:0.204675 loss200:0.144870 lr:6.00e-05[train] 1142/33336 1014(s) eta:28585(s) loss:0.204622 loss200:0.145166 lr:6.00e-05[train] 1143/33336 1015(s) eta:28587(s) loss:0.204492 loss200:0.144843 lr:6.00e-05[train] 1144/33336 1016(s) eta:28590(s) loss:0.204404 loss200:0.144720 lr:6.00e-05[train] 1145/33336 1017(s) eta:28592(s) loss:0.204304 loss200:0.144540 lr:6.00e-05[train] 1146/33336 1018(s) eta:28594(s) loss:0.204202 loss200:0.144480 lr:6.00e-05[train] 1147/33336 1019(s) eta:28596(s) loss:0.204135 loss200:0.143700 lr:6.00e-05[train] 1148/33336 1020(s) eta:28599(s) loss:0.204035 loss200:0.143007 lr:6.00e-05[train] 1149/33336 1020(s) eta:28573(s) loss:0.203950 loss200:0.143196 lr:6.00e-05[train] 1150/33336 1021(s) eta:28575(s) loss:0.203864 loss200:0.142786 lr:6.00e-05[train] 1151/33336 1022(s) eta:28577(s) loss:0.203761 loss200:0.142352 lr:6.00e-05[train] 1152/33336 1023(s) eta:28580(s) loss:0.203754 loss200:0.142025 lr:6.00e-05[train] 1153/33336 1024(s) eta:28582(s) loss:0.203721 loss200:0.141952 lr:6.00e-05[train] 1154/33336 1025(s) eta:28584(s) loss:0.203585 loss200:0.141856 lr:6.00e-05[train] 1155/33336 1026(s) eta:28586(s) loss:0.203493 loss200:0.141817 lr:6.00e-05[train] 1156/33336 1027(s) eta:28588(s) loss:0.203476 loss200:0.141990 lr:6.00e-05[train] 1157/33336 1027(s) eta:28563(s) loss:0.203544 loss200:0.142063 lr:6.00e-05[train] 1158/33336 1028(s) eta:28565(s) loss:0.203517 loss200:0.141182 lr:6.00e-05[train] 1159/33336 1029(s) eta:28567(s) loss:0.203720 loss200:0.142045 lr:6.00e-05[train] 1160/33336 1030(s) eta:28570(s) loss:0.203667 loss200:0.141919 lr:6.00e-05[train] 1161/33336 1031(s) eta:28572(s) loss:0.203662 loss200:0.142369 lr:6.00e-05[train] 1162/33336 1032(s) eta:28574(s) loss:0.203548 loss200:0.142467 lr:6.00e-05[train] 1163/33336 1033(s) eta:28576(s) loss:0.203877 loss200:0.145098 lr:6.00e-05[train] 1164/33336 1034(s) eta:28578(s) loss:0.204250 loss200:0.147813 lr:6.00e-05[train] 1165/33336 1035(s) eta:28581(s) loss:0.204205 loss200:0.147721 lr:6.00e-05[train] 1166/33336 1035(s) eta:28555(s) loss:0.204089 loss200:0.146192 lr:6.00e-05[train] 1167/33336 1036(s) eta:28557(s) loss:0.204024 loss200:0.146581 lr:6.00e-05[train] 1168/33336 1037(s) eta:28560(s) loss:0.203928 loss200:0.146243 lr:6.00e-05[train] 1169/33336 1038(s) eta:28562(s) loss:0.203933 loss200:0.146864 lr:6.00e-05[train] 1170/33336 1039(s) eta:28564(s) loss:0.203898 loss200:0.147387 lr:6.00e-05[train] 1171/33336 1040(s) eta:28566(s) loss:0.203853 loss200:0.147698 lr:6.00e-05[train] 1172/33336 1041(s) eta:28568(s) loss:0.203818 loss200:0.147847 lr:6.00e-05[train] 1173/33336 1042(s) eta:28571(s) loss:0.203740 loss200:0.148005 lr:6.00e-05[train] 1174/33336 1043(s) eta:28573(s) loss:0.203654 loss200:0.147849 lr:6.00e-05[train] 1175/33336 1043(s) eta:28548(s) loss:0.203605 loss200:0.147747 lr:6.00e-05[train] 1176/33336 1044(s) eta:28550(s) loss:0.203563 loss200:0.148096 lr:6.00e-05[train] 1177/33336 1045(s) eta:28552(s) loss:0.203472 loss200:0.148121 lr:6.00e-05[train] 1178/33336 1046(s) eta:28554(s) loss:0.203430 loss200:0.148612 lr:6.00e-05[train] 1179/33336 1047(s) eta:28556(s) loss:0.203385 loss200:0.148595 lr:6.00e-05[train] 1180/33336 1048(s) eta:28558(s) loss:0.203406 loss200:0.148801 lr:6.00e-05[train] 1181/33336 1049(s) eta:28561(s) loss:0.203366 loss200:0.149239 lr:6.00e-05[train] 1182/33336 1049(s) eta:28535(s) loss:0.203350 loss200:0.149400 lr:6.00e-05[train] 1183/33336 1050(s) eta:28538(s) loss:0.203297 loss200:0.149006 lr:6.00e-05[train] 1184/33336 1051(s) eta:28540(s) loss:0.203253 loss200:0.149112 lr:6.00e-05[train] 1185/33336 1052(s) eta:28542(s) loss:0.203284 loss200:0.149404 lr:6.00e-05[train] 1186/33336 1053(s) eta:28544(s) loss:0.203194 loss200:0.149682 lr:6.00e-05[train] 1187/33336 1054(s) eta:28546(s) loss:0.203098 loss200:0.149719 lr:6.00e-05[train] 1188/33336 1055(s) eta:28548(s) loss:0.203059 loss200:0.149714 lr:6.00e-05[train] 1189/33336 1056(s) eta:28551(s) loss:0.203031 loss200:0.149911 lr:6.00e-05[train] 1190/33336 1057(s) eta:28553(s) loss:0.203061 loss200:0.150794 lr:6.00e-05[train] 1191/33336 1057(s) eta:28528(s) loss:0.203028 loss200:0.150991 lr:6.00e-05[train] 1192/33336 1058(s) eta:28530(s) loss:0.202950 loss200:0.151303 lr:6.00e-05[train] 1193/33336 1059(s) eta:28532(s) loss:0.202840 loss200:0.150694 lr:6.00e-05[train] 1194/33336 1060(s) eta:28534(s) loss:0.202792 loss200:0.150632 lr:6.00e-05[train] 1195/33336 1061(s) eta:28536(s) loss:0.202700 loss200:0.150475 lr:6.00e-05[train] 1196/33336 1062(s) eta:28539(s) loss:0.202646 loss200:0.150686 lr:6.00e-05[train] 1197/33336 1063(s) eta:28541(s) loss:0.202596 loss200:0.151008 lr:6.00e-05[train] 1198/33336 1064(s) eta:28543(s) loss:0.202718 loss200:0.152334 lr:6.00e-05[train] 1199/33336 1064(s) eta:28518(s) loss:0.202695 loss200:0.152793 lr:6.00e-05[train] 1200/33336 1065(s) eta:28520(s) loss:0.202576 loss200:0.152819 lr:6.00e-05[train] 1201/33336 1066(s) eta:28522(s) loss:0.202450 loss200:0.151563 lr:6.00e-05[train] 1202/33336 1067(s) eta:28524(s) loss:0.202529 loss200:0.151640 lr:6.00e-05[train] 1203/33336 1068(s) eta:28527(s) loss:0.202461 loss200:0.151857 lr:6.00e-05[train] 1204/33336 1069(s) eta:28529(s) loss:0.202375 loss200:0.151735 lr:6.00e-05[train] 1205/33336 1070(s) eta:28531(s) loss:0.202306 loss200:0.151861 lr:6.00e-05[train] 1206/33336 1071(s) eta:28533(s) loss:0.202200 loss200:0.151833 lr:6.00e-05[train] 1207/33336 1071(s) eta:28508(s) loss:0.202204 loss200:0.152609 lr:6.00e-05[train] 1208/33336 1072(s) eta:28510(s) loss:0.202324 loss200:0.153894 lr:6.00e-05[train] 1209/33336 1073(s) eta:28513(s) loss:0.202331 loss200:0.154411 lr:6.00e-05[train] 1210/33336 1074(s) eta:28515(s) loss:0.202272 loss200:0.154707 lr:6.00e-05[train] 1211/33336 1075(s) eta:28517(s) loss:0.202177 loss200:0.154667 lr:6.00e-05[train] 1212/33336 1076(s) eta:28519(s) loss:0.202076 loss200:0.154209 lr:6.00e-05[train] 1213/33336 1077(s) eta:28521(s) loss:0.202028 loss200:0.154571 lr:6.00e-05[train] 1214/33336 1078(s) eta:28523(s) loss:0.201964 loss200:0.154212 lr:6.00e-05[train] 1215/33336 1078(s) eta:28499(s) loss:0.201890 loss200:0.154252 lr:6.00e-05[train] 1216/33336 1079(s) eta:28501(s) loss:0.201780 loss200:0.153996 lr:6.00e-05[train] 1217/33336 1080(s) eta:28503(s) loss:0.201709 loss200:0.153554 lr:6.00e-05[train] 1218/33336 1081(s) eta:28505(s) loss:0.201708 loss200:0.154046 lr:6.00e-05[train] 1219/33336 1082(s) eta:28507(s) loss:0.201709 loss200:0.152676 lr:6.00e-05[train] 1220/33336 1083(s) eta:28509(s) loss:0.201644 loss200:0.152344 lr:6.00e-05[train] 1221/33336 1084(s) eta:28511(s) loss:0.201726 loss200:0.152992 lr:6.00e-05[train] 1222/33336 1085(s) eta:28513(s) loss:0.201589 loss200:0.152595 lr:6.00e-05[train] 1223/33336 1086(s) eta:28515(s) loss:0.201488 loss200:0.152270 lr:6.00e-05[train] 1224/33336 1086(s) eta:28491(s) loss:0.201387 loss200:0.152242 lr:6.00e-05[train] 1225/33336 1087(s) eta:28493(s) loss:0.201359 loss200:0.152706 lr:6.00e-05[train] 1226/33336 1088(s) eta:28495(s) loss:0.201366 loss200:0.153132 lr:6.00e-05[train] 1227/33336 1089(s) eta:28497(s) loss:0.201443 loss200:0.153762 lr:6.00e-05[train] 1228/33336 1090(s) eta:28499(s) loss:0.201333 loss200:0.152971 lr:6.00e-05[train] 1229/33336 1091(s) eta:28501(s) loss:0.201224 loss200:0.152603 lr:6.00e-05[train] 1230/33336 1092(s) eta:28503(s) loss:0.201104 loss200:0.151784 lr:6.00e-05[train] 1231/33336 1093(s) eta:28505(s) loss:0.201072 loss200:0.151994 lr:6.00e-05[train] 1232/33336 1093(s) eta:28481(s) loss:0.201094 loss200:0.152730 lr:6.00e-05[train] 1233/33336 1094(s) eta:28483(s) loss:0.200991 loss200:0.152668 lr:6.00e-05[train] 1234/33336 1095(s) eta:28485(s) loss:0.201000 loss200:0.153293 lr:6.00e-05[train] 1235/33336 1096(s) eta:28488(s) loss:0.200900 loss200:0.153178 lr:6.00e-05[train] 1236/33336 1097(s) eta:28490(s) loss:0.200829 loss200:0.153313 lr:6.00e-05[train] 1237/33336 1098(s) eta:28492(s) loss:0.200882 loss200:0.154299 lr:6.00e-05[train] 1238/33336 1099(s) eta:28494(s) loss:0.200792 loss200:0.153408 lr:6.00e-05[train] 1239/33336 1099(s) eta:28470(s) loss:0.200688 loss200:0.152428 lr:6.00e-05[train] 1240/33336 1100(s) eta:28472(s) loss:0.200715 loss200:0.153091 lr:6.00e-05[train] 1241/33336 1101(s) eta:28474(s) loss:0.200612 loss200:0.152514 lr:6.00e-05[train] 1242/33336 1102(s) eta:28476(s) loss:0.200559 loss200:0.152867 lr:6.00e-05[train] 1243/33336 1103(s) eta:28478(s) loss:0.200478 loss200:0.152370 lr:6.00e-05[train] 1244/33336 1104(s) eta:28480(s) loss:0.200399 loss200:0.152133 lr:6.00e-05[train] 1245/33336 1105(s) eta:28482(s) loss:0.200308 loss200:0.152108 lr:6.00e-05[train] 1246/33336 1106(s) eta:28484(s) loss:0.200409 loss200:0.153510 lr:6.00e-05[train] 1247/33336 1107(s) eta:28486(s) loss:0.200295 loss200:0.153248 lr:6.00e-05[train] 1248/33336 1108(s) eta:28488(s) loss:0.200424 loss200:0.154549 lr:6.00e-05[train] 1249/33336 1108(s) eta:28464(s) loss:0.200401 loss200:0.153262 lr:6.00e-05[train] 1250/33336 1109(s) eta:28466(s) loss:0.200622 loss200:0.154371 lr:6.00e-05[train] 1251/33336 1110(s) eta:28468(s) loss:0.200553 loss200:0.154645 lr:6.00e-05[train] 1252/33336 1111(s) eta:28470(s) loss:0.200454 loss200:0.154345 lr:6.00e-05[train] 1253/33336 1112(s) eta:28472(s) loss:0.200461 loss200:0.153052 lr:6.00e-05[train] 1254/33336 1113(s) eta:28474(s) loss:0.200456 loss200:0.153174 lr:6.00e-05[train] 1255/33336 1114(s) eta:28476(s) loss:0.200457 loss200:0.153856 lr:6.00e-05[train] 1256/33336 1114(s) eta:28453(s) loss:0.200348 loss200:0.153543 lr:6.00e-05[train] 1257/33336 1115(s) eta:28455(s) loss:0.200247 loss200:0.153070 lr:6.00e-05[train] 1258/33336 1116(s) eta:28457(s) loss:0.200300 loss200:0.153842 lr:6.00e-05[train] 1259/33336 1117(s) eta:28459(s) loss:0.200309 loss200:0.153691 lr:6.00e-05[train] 1260/33336 1118(s) eta:28461(s) loss:0.200389 loss200:0.154728 lr:6.00e-05[train] 1261/33336 1119(s) eta:28463(s) loss:0.200351 loss200:0.153671 lr:6.00e-05[train] 1262/33336 1120(s) eta:28465(s) loss:0.200507 loss200:0.154225 lr:6.00e-05[train] 1263/33336 1121(s) eta:28467(s) loss:0.200422 loss200:0.153971 lr:6.00e-05[train] 1264/33336 1121(s) eta:28443(s) loss:0.200389 loss200:0.154340 lr:6.00e-05[train] 1265/33336 1122(s) eta:28445(s) loss:0.200386 loss200:0.154857 lr:6.00e-05[train] 1266/33336 1123(s) eta:28447(s) loss:0.200332 loss200:0.154825 lr:6.00e-05[train] 1267/33336 1124(s) eta:28449(s) loss:0.200261 loss200:0.154773 lr:6.00e-05[train] 1268/33336 1125(s) eta:28451(s) loss:0.200654 loss200:0.157368 lr:6.00e-05[train] 1269/33336 1126(s) eta:28453(s) loss:0.200564 loss200:0.157124 lr:6.00e-05[train] 1270/33336 1127(s) eta:28455(s) loss:0.200556 loss200:0.157530 lr:6.00e-05[train] 1271/33336 1127(s) eta:28432(s) loss:0.200514 loss200:0.156647 lr:6.00e-05[train] 1272/33336 1128(s) eta:28434(s) loss:0.200473 loss200:0.157009 lr:6.00e-05[train] 1273/33336 1129(s) eta:28436(s) loss:0.200386 loss200:0.156521 lr:6.00e-05[train] 1274/33336 1130(s) eta:28438(s) loss:0.200468 loss200:0.157731 lr:6.00e-05[train] 1275/33336 1131(s) eta:28439(s) loss:0.200382 loss200:0.157742 lr:6.00e-05[train] 1276/33336 1132(s) eta:28441(s) loss:0.200292 loss200:0.157788 lr:6.00e-05[train] 1277/33336 1133(s) eta:28443(s) loss:0.200461 loss200:0.159265 lr:6.00e-05[train] 1278/33336 1133(s) eta:28420(s) loss:0.200386 loss200:0.159460 lr:6.00e-05[train] 1279/33336 1134(s) eta:28422(s) loss:0.200310 loss200:0.159429 lr:6.00e-05[train] 1280/33336 1135(s) eta:28424(s) loss:0.200301 loss200:0.159777 lr:6.00e-05[train] 1281/33336 1136(s) eta:28426(s) loss:0.200230 loss200:0.159536 lr:6.00e-05[train] 1282/33336 1137(s) eta:28428(s) loss:0.200187 loss200:0.159957 lr:6.00e-05[train] 1283/33336 1138(s) eta:28430(s) loss:0.200141 loss200:0.160279 lr:6.00e-05[train] 1284/33336 1139(s) eta:28432(s) loss:0.200196 loss200:0.160884 lr:6.00e-05[train] 1285/33336 1140(s) eta:28434(s) loss:0.200140 loss200:0.160245 lr:6.00e-05[train] 1286/33336 1141(s) eta:28436(s) loss:0.200034 loss200:0.159191 lr:6.00e-05[train] 1287/33336 1141(s) eta:28413(s) loss:0.200003 loss200:0.159306 lr:6.00e-05[train] 1288/33336 1142(s) eta:28415(s) loss:0.199915 loss200:0.159547 lr:6.00e-05[train] 1289/33336 1143(s) eta:28417(s) loss:0.200013 loss200:0.160584 lr:6.00e-05[train] 1290/33336 1144(s) eta:28419(s) loss:0.199927 loss200:0.160633 lr:6.00e-05[train] 1291/33336 1145(s) eta:28421(s) loss:0.199895 loss200:0.159804 lr:6.00e-05[train] 1292/33336 1146(s) eta:28422(s) loss:0.199792 loss200:0.159901 lr:6.00e-05[train] 1293/33336 1147(s) eta:28424(s) loss:0.199803 loss200:0.159056 lr:6.00e-05[train] 1294/33336 1148(s) eta:28426(s) loss:0.199779 loss200:0.158775 lr:6.00e-05[train] 1295/33336 1149(s) eta:28428(s) loss:0.199676 loss200:0.157920 lr:6.00e-05[train] 1296/33336 1149(s) eta:28405(s) loss:0.199598 loss200:0.158177 lr:6.00e-05[train] 1297/33336 1150(s) eta:28407(s) loss:0.199588 loss200:0.157449 lr:6.00e-05[train] 1298/33336 1151(s) eta:28409(s) loss:0.199505 loss200:0.156923 lr:6.00e-05[train] 1299/33336 1152(s) eta:28411(s) loss:0.199578 loss200:0.157735 lr:6.00e-05[train] 1300/33336 1153(s) eta:28413(s) loss:0.199627 loss200:0.158565 lr:6.00e-05[train] 1301/33336 1154(s) eta:28415(s) loss:0.199810 loss200:0.160233 lr:6.00e-05[train] 1302/33336 1155(s) eta:28417(s) loss:0.199851 loss200:0.160680 lr:6.00e-05[train] 1303/33336 1156(s) eta:28419(s) loss:0.199773 loss200:0.160511 lr:6.00e-05[train] 1304/33336 1156(s) eta:28396(s) loss:0.199693 loss200:0.160483 lr:6.00e-05[train] 1305/33336 1157(s) eta:28398(s) loss:0.199606 loss200:0.160666 lr:6.00e-05[train] 1306/33336 1158(s) eta:28400(s) loss:0.199522 loss200:0.160517 lr:6.00e-05[train] 1307/33336 1159(s) eta:28402(s) loss:0.199429 loss200:0.160423 lr:6.00e-05[train] 1308/33336 1160(s) eta:28404(s) loss:0.199315 loss200:0.160170 lr:6.00e-05[train] 1309/33336 1161(s) eta:28405(s) loss:0.199248 loss200:0.160106 lr:6.00e-05[train] 1310/33336 1161(s) eta:28383(s) loss:0.199214 loss200:0.160541 lr:6.00e-05[train] 1311/33336 1162(s) eta:28385(s) loss:0.199114 loss200:0.160512 lr:6.00e-05[train] 1312/33336 1163(s) eta:28387(s) loss:0.199032 loss200:0.160691 lr:6.00e-05[train] 1313/33336 1164(s) eta:28389(s) loss:0.198981 loss200:0.160832 lr:6.00e-05[train] 1314/33336 1165(s) eta:28390(s) loss:0.198897 loss200:0.160142 lr:6.00e-05[train] 1315/33336 1166(s) eta:28392(s) loss:0.198810 loss200:0.160239 lr:6.00e-05[train] 1316/33336 1167(s) eta:28394(s) loss:0.198727 loss200:0.160233 lr:6.00e-05[train] 1317/33336 1168(s) eta:28396(s) loss:0.198690 loss200:0.160777 lr:6.00e-05[train] 1318/33336 1169(s) eta:28398(s) loss:0.198585 loss200:0.160442 lr:6.00e-05[train] 1319/33336 1169(s) eta:28375(s) loss:0.198524 loss200:0.160789 lr:6.00e-05[train] 1320/33336 1170(s) eta:28377(s) loss:0.198423 loss200:0.160392 lr:6.00e-05[train] 1321/33336 1171(s) eta:28379(s) loss:0.198337 loss200:0.159783 lr:6.00e-05[train] 1322/33336 1172(s) eta:28381(s) loss:0.198289 loss200:0.159140 lr:6.00e-05[train] 1323/33336 1173(s) eta:28383(s) loss:0.198184 loss200:0.158971 lr:6.00e-05[train] 1324/33336 1174(s) eta:28385(s) loss:0.198170 loss200:0.158562 lr:6.00e-05[train] 1325/33336 1175(s) eta:28387(s) loss:0.198131 loss200:0.158418 lr:6.00e-05[train] 1326/33336 1176(s) eta:28388(s) loss:0.198121 loss200:0.159136 lr:6.00e-05[train] 1327/33336 1177(s) eta:28390(s) loss:0.198077 loss200:0.159583 lr:6.00e-05[train] 1328/33336 1177(s) eta:28368(s) loss:0.198009 loss200:0.158547 lr:6.00e-05[train] 1329/33336 1178(s) eta:28370(s) loss:0.197907 loss200:0.158054 lr:6.00e-05[train] 1330/33336 1179(s) eta:28372(s) loss:0.197819 loss200:0.157193 lr:6.00e-05[train] 1331/33336 1180(s) eta:28374(s) loss:0.197827 loss200:0.157124 lr:6.00e-05[train] 1332/33336 1181(s) eta:28375(s) loss:0.197710 loss200:0.156933 lr:6.00e-05[train] 1333/33336 1182(s) eta:28377(s) loss:0.197692 loss200:0.157493 lr:6.00e-05[train] 1334/33336 1183(s) eta:28379(s) loss:0.197656 loss200:0.157777 lr:6.00e-05[train] 1335/33336 1184(s) eta:28381(s) loss:0.197597 loss200:0.157321 lr:6.00e-05[train] 1336/33336 1184(s) eta:28359(s) loss:0.197520 loss200:0.157191 lr:6.00e-05[train] 1337/33336 1185(s) eta:28361(s) loss:0.197406 loss200:0.155396 lr:6.00e-05[train] 1338/33336 1186(s) eta:28362(s) loss:0.197584 loss200:0.157290 lr:6.00e-05[train] 1339/33336 1187(s) eta:28364(s) loss:0.197483 loss200:0.156191 lr:6.00e-05[train] 1340/33336 1188(s) eta:28366(s) loss:0.197483 loss200:0.156350 lr:6.00e-05[train] 1341/33336 1189(s) eta:28368(s) loss:0.197579 loss200:0.157097 lr:6.00e-05[train] 1342/33336 1190(s) eta:28370(s) loss:0.197537 loss200:0.157084 lr:6.00e-05[train] 1343/33336 1191(s) eta:28372(s) loss:0.197448 loss200:0.157191 lr:6.00e-05[train] 1344/33336 1191(s) eta:28350(s) loss:0.197423 loss200:0.157488 lr:6.00e-05[train] 1345/33336 1192(s) eta:28351(s) loss:0.197394 loss200:0.157836 lr:6.00e-05[train] 1346/33336 1193(s) eta:28353(s) loss:0.197411 loss200:0.158501 lr:6.00e-05[train] 1347/33336 1194(s) eta:28355(s) loss:0.197384 loss200:0.158669 lr:6.00e-05[train] 1348/33336 1195(s) eta:28357(s) loss:0.197296 loss200:0.158615 lr:6.00e-05[train] 1349/33336 1196(s) eta:28359(s) loss:0.197178 loss200:0.158272 lr:6.00e-05[train] 1350/33336 1197(s) eta:28360(s) loss:0.197100 loss200:0.158207 lr:6.00e-05[train] 1351/33336 1197(s) eta:28339(s) loss:0.196989 loss200:0.158017 lr:6.00e-05[train] 1352/33336 1198(s) eta:28340(s) loss:0.196946 loss200:0.157726 lr:6.00e-05[train] 1353/33336 1199(s) eta:28342(s) loss:0.196950 loss200:0.157916 lr:6.00e-05[train] 1354/33336 1200(s) eta:28344(s) loss:0.196834 loss200:0.157879 lr:6.00e-05[train] 1355/33336 1201(s) eta:28346(s) loss:0.196798 loss200:0.158136 lr:6.00e-05[train] 1356/33336 1202(s) eta:28348(s) loss:0.196708 loss200:0.157586 lr:6.00e-05[train] 1357/33336 1203(s) eta:28349(s) loss:0.196612 loss200:0.156512 lr:6.00e-05[train] 1358/33336 1204(s) eta:28351(s) loss:0.196530 loss200:0.156074 lr:6.00e-05[train] 1359/33336 1205(s) eta:28353(s) loss:0.196514 loss200:0.154755 lr:6.00e-05[train] 1360/33336 1206(s) eta:28355(s) loss:0.196431 loss200:0.154462 lr:6.00e-05[train] 1361/33336 1206(s) eta:28333(s) loss:0.196363 loss200:0.153989 lr:6.00e-05[train] 1362/33336 1207(s) eta:28335(s) loss:0.196299 loss200:0.154178 lr:6.00e-05[train] 1363/33336 1208(s) eta:28337(s) loss:0.196230 loss200:0.151764 lr:6.00e-05[train] 1364/33336 1209(s) eta:28338(s) loss:0.196168 loss200:0.149132 lr:6.00e-05[train] 1365/33336 1210(s) eta:28340(s) loss:0.196067 loss200:0.148664 lr:6.00e-05[train] 1366/33336 1211(s) eta:28342(s) loss:0.195991 loss200:0.148778 lr:6.00e-05[train] 1367/33336 1212(s) eta:28344(s) loss:0.195891 loss200:0.148439 lr:6.00e-05[train] 1368/33336 1213(s) eta:28345(s) loss:0.195789 loss200:0.148256 lr:6.00e-05[train] 1369/33336 1214(s) eta:28347(s) loss:0.195814 loss200:0.148355 lr:6.00e-05[train] 1370/33336 1214(s) eta:28326(s) loss:0.195722 loss200:0.147894 lr:6.00e-05[train] 1371/33336 1215(s) eta:28327(s) loss:0.195640 loss200:0.147552 lr:6.00e-05[train] 1372/33336 1216(s) eta:28329(s) loss:0.195607 loss200:0.147494 lr:6.00e-05[train] 1373/33336 1217(s) eta:28331(s) loss:0.195670 loss200:0.148338 lr:6.00e-05[train] 1374/33336 1218(s) eta:28333(s) loss:0.195617 loss200:0.148442 lr:6.00e-05[train] 1375/33336 1219(s) eta:28334(s) loss:0.195501 loss200:0.147889 lr:6.00e-05[train] 1376/33336 1220(s) eta:28336(s) loss:0.195408 loss200:0.147453 lr:6.00e-05[train] 1377/33336 1221(s) eta:28338(s) loss:0.195343 loss200:0.147504 lr:6.00e-05[train] 1378/33336 1221(s) eta:28316(s) loss:0.195363 loss200:0.147846 lr:6.00e-05[train] 1379/33336 1222(s) eta:28318(s) loss:0.195342 loss200:0.147929 lr:6.00e-05[train] 1380/33336 1223(s) eta:28320(s) loss:0.195407 loss200:0.148214 lr:6.00e-05[train] 1381/33336 1224(s) eta:28322(s) loss:0.195363 loss200:0.148102 lr:6.00e-05[train] 1382/33336 1225(s) eta:28323(s) loss:0.195394 loss200:0.148379 lr:6.00e-05[train] 1383/33336 1226(s) eta:28325(s) loss:0.195357 loss200:0.148393 lr:6.00e-05[train] 1384/33336 1227(s) eta:28327(s) loss:0.195365 loss200:0.148664 lr:6.00e-05[train] 1385/33336 1228(s) eta:28329(s) loss:0.195300 loss200:0.147998 lr:6.00e-05[train] 1386/33336 1228(s) eta:28307(s) loss:0.195258 loss200:0.148200 lr:6.00e-05[train] 1387/33336 1229(s) eta:28309(s) loss:0.195363 loss200:0.149458 lr:6.00e-05[train] 1388/33336 1230(s) eta:28311(s) loss:0.195363 loss200:0.149649 lr:6.00e-05[train] 1389/33336 1231(s) eta:28313(s) loss:0.195363 loss200:0.149782 lr:6.00e-05[train] 1390/33336 1232(s) eta:28314(s) loss:0.195270 loss200:0.148915 lr:6.00e-05[train] 1391/33336 1233(s) eta:28316(s) loss:0.195303 loss200:0.149302 lr:6.00e-05[train] 1392/33336 1234(s) eta:28318(s) loss:0.195278 loss200:0.149558 lr:6.00e-05[train] 1393/33336 1235(s) eta:28319(s) loss:0.195250 loss200:0.149971 lr:6.00e-05[train] 1394/33336 1235(s) eta:28298(s) loss:0.195272 loss200:0.150376 lr:6.00e-05[train] 1395/33336 1236(s) eta:28300(s) loss:0.195210 loss200:0.150459 lr:6.00e-05[train] 1396/33336 1237(s) eta:28302(s) loss:0.195244 loss200:0.150976 lr:6.00e-05[train] 1397/33336 1238(s) eta:28303(s) loss:0.195198 loss200:0.150925 lr:6.00e-05[train] 1398/33336 1239(s) eta:28305(s) loss:0.195116 loss200:0.149581 lr:6.00e-05[train] 1399/33336 1240(s) eta:28307(s) loss:0.195155 loss200:0.149953 lr:6.00e-05[train] 1400/33336 1241(s) eta:28308(s) loss:0.195076 loss200:0.150072 lr:6.00e-05[train] 1401/33336 1241(s) eta:28287(s) loss:0.195039 loss200:0.150534 lr:6.00e-05[train] 1402/33336 1242(s) eta:28289(s) loss:0.194990 loss200:0.149677 lr:6.00e-05[train] 1403/33336 1243(s) eta:28291(s) loss:0.195081 loss200:0.150690 lr:6.00e-05[train] 1404/33336 1244(s) eta:28293(s) loss:0.195041 loss200:0.150886 lr:6.00e-05[train] 1405/33336 1245(s) eta:28294(s) loss:0.194975 loss200:0.150800 lr:6.00e-05[train] 1406/33336 1246(s) eta:28296(s) loss:0.194913 loss200:0.150973 lr:6.00e-05[train] 1407/33336 1247(s) eta:28298(s) loss:0.194860 loss200:0.150535 lr:6.00e-05[train] 1408/33336 1248(s) eta:28299(s) loss:0.194805 loss200:0.149386 lr:6.00e-05[train] 1409/33336 1249(s) eta:28301(s) loss:0.194867 loss200:0.149743 lr:6.00e-05[train] 1410/33336 1249(s) eta:28280(s) loss:0.194814 loss200:0.149694 lr:6.00e-05[train] 1411/33336 1250(s) eta:28282(s) loss:0.194768 loss200:0.149909 lr:6.00e-05[train] 1412/33336 1251(s) eta:28283(s) loss:0.194834 loss200:0.150948 lr:6.00e-05[train] 1413/33336 1252(s) eta:28285(s) loss:0.194884 loss200:0.151550 lr:6.00e-05[train] 1414/33336 1253(s) eta:28287(s) loss:0.194954 loss200:0.152399 lr:6.00e-05[train] 1415/33336 1254(s) eta:28288(s) loss:0.194864 loss200:0.152178 lr:6.00e-05[train] 1416/33336 1255(s) eta:28290(s) loss:0.194792 loss200:0.152307 lr:6.00e-05[train] 1417/33336 1255(s) eta:28269(s) loss:0.194747 loss200:0.152385 lr:6.00e-05[train] 1418/33336 1256(s) eta:28271(s) loss:0.194675 loss200:0.151846 lr:6.00e-05[train] 1419/33336 1257(s) eta:28273(s) loss:0.194629 loss200:0.151478 lr:6.00e-05[train] 1420/33336 1258(s) eta:28274(s) loss:0.194630 loss200:0.151845 lr:6.00e-05[train] 1421/33336 1259(s) eta:28276(s) loss:0.194583 loss200:0.150976 lr:6.00e-05[train] 1422/33336 1260(s) eta:28278(s) loss:0.194522 loss200:0.151344 lr:6.00e-05[train] 1423/33336 1261(s) eta:28279(s) loss:0.194477 loss200:0.151602 lr:6.00e-05[train] 1424/33336 1262(s) eta:28281(s) loss:0.194434 loss200:0.151881 lr:6.00e-05[train] 1425/33336 1263(s) eta:28283(s) loss:0.194399 loss200:0.151768 lr:6.00e-05[train] 1426/33336 1264(s) eta:28284(s) loss:0.194444 loss200:0.152010 lr:6.00e-05[train] 1427/33336 1264(s) eta:28264(s) loss:0.194407 loss200:0.151242 lr:6.00e-05[train] 1428/33336 1265(s) eta:28265(s) loss:0.194416 loss200:0.151946 lr:6.00e-05[train] 1429/33336 1266(s) eta:28267(s) loss:0.194449 loss200:0.152816 lr:6.00e-05[train] 1430/33336 1267(s) eta:28269(s) loss:0.194398 loss200:0.153155 lr:6.00e-05[train] 1431/33336 1268(s) eta:28270(s) loss:0.194327 loss200:0.152807 lr:6.00e-05[train] 1432/33336 1269(s) eta:28272(s) loss:0.194323 loss200:0.152613 lr:6.00e-05[train] 1433/33336 1270(s) eta:28274(s) loss:0.194309 loss200:0.153116 lr:6.00e-05[train] 1434/33336 1271(s) eta:28275(s) loss:0.194298 loss200:0.152941 lr:6.00e-05[train] 1435/33336 1271(s) eta:28255(s) loss:0.194215 loss200:0.152937 lr:6.00e-05[train] 1436/33336 1272(s) eta:28256(s) loss:0.194245 loss200:0.153554 lr:6.00e-05[train] 1437/33336 1273(s) eta:28258(s) loss:0.194155 loss200:0.152547 lr:6.00e-05[train] 1438/33336 1274(s) eta:28260(s) loss:0.194123 loss200:0.152840 lr:6.00e-05[train] 1439/33336 1275(s) eta:28261(s) loss:0.194119 loss200:0.153425 lr:6.00e-05[train] 1440/33336 1276(s) eta:28263(s) loss:0.194173 loss200:0.153613 lr:6.00e-05[train] 1441/33336 1277(s) eta:28265(s) loss:0.194081 loss200:0.153558 lr:6.00e-05[train] 1442/33336 1278(s) eta:28266(s) loss:0.194053 loss200:0.153652 lr:6.00e-05[train] 1443/33336 1279(s) eta:28268(s) loss:0.193988 loss200:0.153654 lr:6.00e-05[train] 1444/33336 1279(s) eta:28247(s) loss:0.193895 loss200:0.153435 lr:6.00e-05[train] 1445/33336 1280(s) eta:28249(s) loss:0.193799 loss200:0.153278 lr:6.00e-05[train] 1446/33336 1281(s) eta:28251(s) loss:0.193743 loss200:0.152217 lr:6.00e-05[train] 1447/33336 1282(s) eta:28252(s) loss:0.193734 loss200:0.152828 lr:6.00e-05[train] 1448/33336 1283(s) eta:28254(s) loss:0.193694 loss200:0.151702 lr:6.00e-05[train] 1449/33336 1284(s) eta:28255(s) loss:0.193616 loss200:0.151242 lr:6.00e-05[train] 1450/33336 1285(s) eta:28257(s) loss:0.193727 loss200:0.150635 lr:6.00e-05[train] 1451/33336 1286(s) eta:28259(s) loss:0.193918 loss200:0.152414 lr:6.00e-05[train] 1452/33336 1286(s) eta:28238(s) loss:0.193915 loss200:0.152986 lr:6.00e-05[train] 1453/33336 1287(s) eta:28240(s) loss:0.193898 loss200:0.152778 lr:6.00e-05[train] 1454/33336 1288(s) eta:28242(s) loss:0.193798 loss200:0.152050 lr:6.00e-05[train] 1455/33336 1289(s) eta:28243(s) loss:0.193722 loss200:0.151459 lr:6.00e-05[train] 1456/33336 1290(s) eta:28245(s) loss:0.193760 loss200:0.152391 lr:6.00e-05[train] 1457/33336 1291(s) eta:28246(s) loss:0.193654 loss200:0.152216 lr:6.00e-05[train] 1458/33336 1292(s) eta:28248(s) loss:0.193564 loss200:0.151198 lr:6.00e-05[train] 1459/33336 1292(s) eta:28228(s) loss:0.193518 loss200:0.150767 lr:6.00e-05[train] 1460/33336 1293(s) eta:28229(s) loss:0.193518 loss200:0.150235 lr:6.00e-05[train] 1461/33336 1294(s) eta:28231(s) loss:0.193517 loss200:0.150429 lr:6.00e-05[train] 1462/33336 1295(s) eta:28233(s) loss:0.193486 loss200:0.149188 lr:6.00e-05[train] 1463/33336 1296(s) eta:28234(s) loss:0.193517 loss200:0.149914 lr:6.00e-05[train] 1464/33336 1297(s) eta:28236(s) loss:0.193499 loss200:0.149948 lr:6.00e-05[train] 1465/33336 1298(s) eta:28237(s) loss:0.193397 loss200:0.149196 lr:6.00e-05[train] 1466/33336 1299(s) eta:28239(s) loss:0.193346 loss200:0.149126 lr:6.00e-05[train] 1467/33336 1300(s) eta:28241(s) loss:0.193297 loss200:0.149179 lr:6.00e-05[train] 1468/33336 1301(s) eta:28242(s) loss:0.193213 loss200:0.146040 lr:6.00e-05[train] 1469/33336 1301(s) eta:28222(s) loss:0.193131 loss200:0.145962 lr:6.00e-05[train] 1470/33336 1302(s) eta:28224(s) loss:0.193174 loss200:0.146300 lr:6.00e-05[train] 1471/33336 1303(s) eta:28225(s) loss:0.193107 loss200:0.146035 lr:6.00e-05[train] 1472/33336 1304(s) eta:28227(s) loss:0.193018 loss200:0.145606 lr:6.00e-05[train] 1473/33336 1305(s) eta:28228(s) loss:0.192944 loss200:0.145581 lr:6.00e-05[train] 1474/33336 1306(s) eta:28230(s) loss:0.192879 loss200:0.144539 lr:6.00e-05[train] 1475/33336 1307(s) eta:28232(s) loss:0.192792 loss200:0.144403 lr:6.00e-05[train] 1476/33336 1307(s) eta:28212(s) loss:0.192760 loss200:0.144707 lr:6.00e-05[train] 1477/33336 1308(s) eta:28213(s) loss:0.192758 loss200:0.143572 lr:6.00e-05[train] 1478/33336 1309(s) eta:28215(s) loss:0.192669 loss200:0.143357 lr:6.00e-05[train] 1479/33336 1310(s) eta:28216(s) loss:0.192595 loss200:0.143251 lr:6.00e-05[train] 1480/33336 1311(s) eta:28218(s) loss:0.192578 loss200:0.143156 lr:6.00e-05[train] 1481/33336 1312(s) eta:28219(s) loss:0.192663 loss200:0.144193 lr:6.00e-05[train] 1482/33336 1313(s) eta:28221(s) loss:0.192567 loss200:0.143722 lr:6.00e-05[train] 1483/33336 1314(s) eta:28223(s) loss:0.192628 loss200:0.144429 lr:6.00e-05[train] 1484/33336 1315(s) eta:28224(s) loss:0.192631 loss200:0.144061 lr:6.00e-05[train] 1485/33336 1315(s) eta:28204(s) loss:0.192546 loss200:0.143753 lr:6.00e-05[train] 1486/33336 1316(s) eta:28206(s) loss:0.192527 loss200:0.144258 lr:6.00e-05[train] 1487/33336 1317(s) eta:28207(s) loss:0.192544 loss200:0.144542 lr:6.00e-05[train] 1488/33336 1318(s) eta:28209(s) loss:0.192499 loss200:0.144736 lr:6.00e-05[train] 1489/33336 1319(s) eta:28211(s) loss:0.192506 loss200:0.144123 lr:6.00e-05[train] 1490/33336 1320(s) eta:28212(s) loss:0.192498 loss200:0.144582 lr:6.00e-05[train] 1491/33336 1321(s) eta:28214(s) loss:0.192434 loss200:0.144270 lr:6.00e-05[train] 1492/33336 1322(s) eta:28215(s) loss:0.192342 loss200:0.144218 lr:6.00e-05[train] 1493/33336 1322(s) eta:28195(s) loss:0.192296 loss200:0.143765 lr:6.00e-05[train] 1494/33336 1323(s) eta:28197(s) loss:0.192234 loss200:0.143415 lr:6.00e-05[train] 1495/33336 1324(s) eta:28198(s) loss:0.192178 loss200:0.143625 lr:6.00e-05[train] 1496/33336 1325(s) eta:28200(s) loss:0.192214 loss200:0.144371 lr:6.00e-05[train] 1497/33336 1326(s) eta:28202(s) loss:0.192264 loss200:0.144767 lr:6.00e-05[train] 1498/33336 1327(s) eta:28203(s) loss:0.192298 loss200:0.145520 lr:6.00e-05[train] 1499/33336 1328(s) eta:28205(s) loss:0.192200 loss200:0.144285 lr:6.00e-05[train] 1500/33336 1328(s) eta:28185(s) loss:0.192179 loss200:0.143769 lr:6.00e-05[train] 1501/33336 1329(s) eta:28187(s) loss:0.192104 loss200:0.141982 lr:6.00e-05[train] 1502/33336 1330(s) eta:28188(s) loss:0.192140 loss200:0.141941 lr:6.00e-05[train] 1503/33336 1331(s) eta:28190(s) loss:0.192196 loss200:0.142830 lr:6.00e-05[train] 1504/33336 1332(s) eta:28191(s) loss:0.192116 loss200:0.142716 lr:6.00e-05[train] 1505/33336 1333(s) eta:28193(s) loss:0.192118 loss200:0.143260 lr:6.00e-05[train] 1506/33336 1334(s) eta:28194(s) loss:0.192172 loss200:0.144179 lr:6.00e-05[train] 1507/33336 1334(s) eta:28175(s) loss:0.192079 loss200:0.144048 lr:6.00e-05[train] 1508/33336 1335(s) eta:28176(s) loss:0.192016 loss200:0.144284 lr:6.00e-05[train] 1509/33336 1336(s) eta:28178(s) loss:0.191972 loss200:0.144348 lr:6.00e-05[train] 1510/33336 1337(s) eta:28179(s) loss:0.191892 loss200:0.143928 lr:6.00e-05[train] 1511/33336 1338(s) eta:28181(s) loss:0.191840 loss200:0.144156 lr:6.00e-05[train] 1512/33336 1339(s) eta:28182(s) loss:0.191840 loss200:0.144659 lr:6.00e-05[train] 1513/33336 1340(s) eta:28184(s) loss:0.191810 loss200:0.144733 lr:6.00e-05[train] 1514/33336 1341(s) eta:28185(s) loss:0.191729 loss200:0.144631 lr:6.00e-05[train] 1515/33336 1342(s) eta:28187(s) loss:0.191748 loss200:0.145317 lr:6.00e-05[train] 1516/33336 1343(s) eta:28188(s) loss:0.191744 loss200:0.145794 lr:6.00e-05[train] 1517/33336 1343(s) eta:28169(s) loss:0.191653 loss200:0.145313 lr:6.00e-05[train] 1518/33336 1344(s) eta:28170(s) loss:0.191656 loss200:0.145990 lr:6.00e-05[train] 1519/33336 1345(s) eta:28172(s) loss:0.191645 loss200:0.146274 lr:6.00e-05[train] 1520/33336 1346(s) eta:28173(s) loss:0.191569 loss200:0.146330 lr:6.00e-05[train] 1521/33336 1347(s) eta:28175(s) loss:0.191502 loss200:0.146360 lr:6.00e-05[train] 1522/33336 1348(s) eta:28176(s) loss:0.191448 loss200:0.146232 lr:6.00e-05[train] 1523/33336 1349(s) eta:28178(s) loss:0.191372 loss200:0.146310 lr:6.00e-05[train] 1524/33336 1349(s) eta:28159(s) loss:0.191461 loss200:0.147045 lr:6.00e-05[train] 1525/33336 1350(s) eta:28160(s) loss:0.191468 loss200:0.147324 lr:6.00e-05[train] 1526/33336 1351(s) eta:28162(s) loss:0.191514 loss200:0.147711 lr:6.00e-05[train] 1527/33336 1352(s) eta:28163(s) loss:0.191454 loss200:0.147509 lr:6.00e-05[train] 1528/33336 1353(s) eta:28165(s) loss:0.191457 loss200:0.147953 lr:6.00e-05[train] 1529/33336 1354(s) eta:28166(s) loss:0.191418 loss200:0.148299 lr:6.00e-05[train] 1530/33336 1355(s) eta:28168(s) loss:0.191410 loss200:0.148793 lr:6.00e-05[train] 1531/33336 1356(s) eta:28169(s) loss:0.191348 loss200:0.148227 lr:6.00e-05[train] 1532/33336 1357(s) eta:28171(s) loss:0.191290 loss200:0.148533 lr:6.00e-05[train] 1533/33336 1357(s) eta:28151(s) loss:0.191315 loss200:0.148817 lr:6.00e-05[train] 1534/33336 1358(s) eta:28153(s) loss:0.191292 loss200:0.148844 lr:6.00e-05[train] 1535/33336 1359(s) eta:28154(s) loss:0.191214 loss200:0.148607 lr:6.00e-05[train] 1536/33336 1360(s) eta:28156(s) loss:0.191297 loss200:0.149726 lr:6.00e-05[train] 1537/33336 1361(s) eta:28157(s) loss:0.191339 loss200:0.150783 lr:6.00e-05[train] 1538/33336 1362(s) eta:28159(s) loss:0.191284 loss200:0.149137 lr:6.00e-05[train] 1539/33336 1363(s) eta:28160(s) loss:0.191237 loss200:0.149418 lr:6.00e-05[train] 1540/33336 1363(s) eta:28141(s) loss:0.191164 loss200:0.148827 lr:6.00e-05[train] 1541/33336 1364(s) eta:28143(s) loss:0.191107 loss200:0.147712 lr:6.00e-05[train] 1542/33336 1365(s) eta:28144(s) loss:0.191061 loss200:0.147608 lr:6.00e-05[train] 1543/33336 1366(s) eta:28145(s) loss:0.191024 loss200:0.147887 lr:6.00e-05[train] 1544/33336 1367(s) eta:28147(s) loss:0.191119 loss200:0.148758 lr:6.00e-05[train] 1545/33336 1368(s) eta:28148(s) loss:0.191126 loss200:0.148969 lr:6.00e-05[train] 1546/33336 1369(s) eta:28150(s) loss:0.191042 loss200:0.148173 lr:6.00e-05[train] 1547/33336 1370(s) eta:28151(s) loss:0.191019 loss200:0.148146 lr:6.00e-05[train] 1548/33336 1371(s) eta:28153(s) loss:0.190928 loss200:0.148010 lr:6.00e-05[train] 1549/33336 1371(s) eta:28134(s) loss:0.190902 loss200:0.148570 lr:6.00e-05[train] 1550/33336 1372(s) eta:28135(s) loss:0.190831 loss200:0.148512 lr:6.00e-05[train] 1551/33336 1373(s) eta:28137(s) loss:0.190800 loss200:0.148992 lr:6.00e-05[train] 1552/33336 1374(s) eta:28138(s) loss:0.190749 loss200:0.148860 lr:6.00e-05[train] 1553/33336 1375(s) eta:28140(s) loss:0.190734 loss200:0.148682 lr:6.00e-05[train] 1554/33336 1376(s) eta:28141(s) loss:0.190662 loss200:0.148883 lr:6.00e-05[train] 1555/33336 1377(s) eta:28143(s) loss:0.190588 loss200:0.148517 lr:6.00e-05[train] 1556/33336 1377(s) eta:28124(s) loss:0.190497 loss200:0.148390 lr:6.00e-05[train] 1557/33336 1378(s) eta:28125(s) loss:0.190497 loss200:0.149005 lr:6.00e-05[train] 1558/33336 1379(s) eta:28126(s) loss:0.190522 loss200:0.149728 lr:6.00e-05[train] 1559/33336 1380(s) eta:28128(s) loss:0.190484 loss200:0.149506 lr:6.00e-05[train] 1560/33336 1381(s) eta:28129(s) loss:0.190511 loss200:0.150256 lr:6.00e-05[train] 1561/33336 1382(s) eta:28131(s) loss:0.190504 loss200:0.150636 lr:6.00e-05[train] 1562/33336 1383(s) eta:28132(s) loss:0.190512 loss200:0.151106 lr:6.00e-05[train] 1563/33336 1384(s) eta:28134(s) loss:0.190520 loss200:0.151602 lr:6.00e-05[train] 1564/33336 1385(s) eta:28135(s) loss:0.190496 loss200:0.151812 lr:6.00e-05[train] 1565/33336 1386(s) eta:28137(s) loss:0.190431 loss200:0.151965 lr:6.00e-05[train] 1566/33336 1386(s) eta:28118(s) loss:0.190520 loss200:0.153157 lr:6.00e-05[train] 1567/33336 1387(s) eta:28119(s) loss:0.190451 loss200:0.153263 lr:6.00e-05[train] 1568/33336 1388(s) eta:28121(s) loss:0.190398 loss200:0.153524 lr:6.00e-05[train] 1569/33336 1389(s) eta:28122(s) loss:0.190349 loss200:0.152943 lr:6.00e-05[train] 1570/33336 1390(s) eta:28124(s) loss:0.190298 loss200:0.153140 lr:6.00e-05[train] 1571/33336 1391(s) eta:28125(s) loss:0.190236 loss200:0.153190 lr:6.00e-05[train] 1572/33336 1392(s) eta:28126(s) loss:0.190191 loss200:0.153033 lr:6.00e-05[train] 1573/33336 1392(s) eta:28108(s) loss:0.190111 loss200:0.151952 lr:6.00e-05[train] 1574/33336 1393(s) eta:28109(s) loss:0.190077 loss200:0.152013 lr:6.00e-05[train] 1575/33336 1394(s) eta:28111(s) loss:0.189998 loss200:0.152168 lr:6.00e-05[train] 1576/33336 1395(s) eta:28112(s) loss:0.189941 loss200:0.152331 lr:6.00e-05[train] 1577/33336 1396(s) eta:28113(s) loss:0.189890 loss200:0.152348 lr:6.00e-05[train] 1578/33336 1397(s) eta:28115(s) loss:0.189853 loss200:0.151892 lr:6.00e-05[train] 1579/33336 1398(s) eta:28116(s) loss:0.189789 loss200:0.151502 lr:6.00e-05[train] 1580/33336 1399(s) eta:28118(s) loss:0.189792 loss200:0.151049 lr:6.00e-05[train] 1581/33336 1400(s) eta:28119(s) loss:0.189764 loss200:0.151108 lr:6.00e-05[train] 1582/33336 1400(s) eta:28100(s) loss:0.189731 loss200:0.150595 lr:6.00e-05[train] 1583/33336 1401(s) eta:28102(s) loss:0.189752 loss200:0.150995 lr:6.00e-05[train] 1584/33336 1402(s) eta:28103(s) loss:0.189709 loss200:0.150575 lr:6.00e-05[train] 1585/33336 1403(s) eta:28105(s) loss:0.189672 loss200:0.150699 lr:6.00e-05[train] 1586/33336 1404(s) eta:28106(s) loss:0.189719 loss200:0.151333 lr:6.00e-05[train] 1587/33336 1405(s) eta:28107(s) loss:0.189664 loss200:0.150140 lr:6.00e-05[train] 1588/33336 1406(s) eta:28109(s) loss:0.189594 loss200:0.149555 lr:6.00e-05[train] 1589/33336 1407(s) eta:28110(s) loss:0.189523 loss200:0.148962 lr:6.00e-05[train] 1590/33336 1407(s) eta:28092(s) loss:0.189429 loss200:0.148833 lr:6.00e-05[train] 1591/33336 1408(s) eta:28093(s) loss:0.189352 loss200:0.147964 lr:6.00e-05[train] 1592/33336 1409(s) eta:28095(s) loss:0.189290 loss200:0.147609 lr:6.00e-05[train] 1593/33336 1410(s) eta:28096(s) loss:0.189212 loss200:0.147157 lr:6.00e-05[train] 1594/33336 1411(s) eta:28097(s) loss:0.189248 loss200:0.147261 lr:6.00e-05[train] 1595/33336 1412(s) eta:28099(s) loss:0.189161 loss200:0.146971 lr:6.00e-05[train] 1596/33336 1413(s) eta:28100(s) loss:0.189087 loss200:0.146109 lr:6.00e-05[train] 1597/33336 1414(s) eta:28102(s) loss:0.188994 loss200:0.145654 lr:6.00e-05[train] 1598/33336 1414(s) eta:28083(s) loss:0.188950 loss200:0.145850 lr:6.00e-05[train] 1599/33336 1415(s) eta:28084(s) loss:0.188994 loss200:0.145896 lr:6.00e-05[train] 1600/33336 1416(s) eta:28086(s) loss:0.189079 loss200:0.147099 lr:6.00e-05[train] 1601/33336 1417(s) eta:28087(s) loss:0.189021 loss200:0.146866 lr:6.00e-05[train] 1602/33336 1418(s) eta:28089(s) loss:0.188987 loss200:0.146905 lr:6.00e-05[train] 1603/33336 1419(s) eta:28090(s) loss:0.188948 loss200:0.145924 lr:6.00e-05[train] 1604/33336 1420(s) eta:28091(s) loss:0.189044 loss200:0.146948 lr:6.00e-05[train] 1605/33336 1421(s) eta:28093(s) loss:0.188996 loss200:0.147000 lr:6.00e-05[train] 1606/33336 1421(s) eta:28074(s) loss:0.189078 loss200:0.148059 lr:6.00e-05[train] 1607/33336 1422(s) eta:28076(s) loss:0.189069 loss200:0.148332 lr:6.00e-05[train] 1608/33336 1423(s) eta:28077(s) loss:0.188989 loss200:0.148047 lr:6.00e-05[train] 1609/33336 1424(s) eta:28079(s) loss:0.188990 loss200:0.147593 lr:6.00e-05[train] 1610/33336 1425(s) eta:28080(s) loss:0.188953 loss200:0.147628 lr:6.00e-05[train] 1611/33336 1426(s) eta:28081(s) loss:0.188868 loss200:0.147243 lr:6.00e-05[train] 1612/33336 1427(s) eta:28083(s) loss:0.188788 loss200:0.146104 lr:6.00e-05[train] 1613/33336 1428(s) eta:28084(s) loss:0.188815 loss200:0.145942 lr:6.00e-05[train] 1614/33336 1428(s) eta:28066(s) loss:0.188785 loss200:0.145170 lr:6.00e-05[train] 1615/33336 1429(s) eta:28067(s) loss:0.188721 loss200:0.145262 lr:6.00e-05[train] 1616/33336 1430(s) eta:28069(s) loss:0.188638 loss200:0.145069 lr:6.00e-05[train] 1617/33336 1431(s) eta:28070(s) loss:0.188628 loss200:0.145279 lr:6.00e-05[train] 1618/33336 1432(s) eta:28071(s) loss:0.188653 loss200:0.145959 lr:6.00e-05[train] 1619/33336 1433(s) eta:28073(s) loss:0.188657 loss200:0.146283 lr:6.00e-05[train] 1620/33336 1434(s) eta:28074(s) loss:0.188626 loss200:0.146001 lr:6.00e-05[train] 1621/33336 1435(s) eta:28075(s) loss:0.188561 loss200:0.145774 lr:6.00e-05[train] 1622/33336 1435(s) eta:28057(s) loss:0.188501 loss200:0.145690 lr:6.00e-05[train] 1623/33336 1436(s) eta:28059(s) loss:0.188565 loss200:0.146502 lr:6.00e-05[train] 1624/33336 1437(s) eta:28060(s) loss:0.188516 loss200:0.146384 lr:6.00e-05[train] 1625/33336 1438(s) eta:28061(s) loss:0.188448 loss200:0.146048 lr:6.00e-05[train] 1626/33336 1439(s) eta:28063(s) loss:0.188452 loss200:0.145730 lr:6.00e-05[train] 1627/33336 1440(s) eta:28064(s) loss:0.188379 loss200:0.145370 lr:6.00e-05[train] 1628/33336 1441(s) eta:28065(s) loss:0.188324 loss200:0.144822 lr:6.00e-05[train] 1629/33336 1442(s) eta:28067(s) loss:0.188319 loss200:0.144521 lr:6.00e-05[train] 1630/33336 1442(s) eta:28049(s) loss:0.188262 loss200:0.144389 lr:6.00e-05[train] 1631/33336 1443(s) eta:28050(s) loss:0.188201 loss200:0.144372 lr:6.00e-05[train] 1632/33336 1444(s) eta:28051(s) loss:0.188128 loss200:0.143772 lr:6.00e-05[train] 1633/33336 1445(s) eta:28053(s) loss:0.188144 loss200:0.143971 lr:6.00e-05[train] 1634/33336 1446(s) eta:28054(s) loss:0.188116 loss200:0.143795 lr:6.00e-05[train] 1635/33336 1447(s) eta:28055(s) loss:0.188174 loss200:0.144825 lr:6.00e-05[train] 1636/33336 1448(s) eta:28057(s) loss:0.188086 loss200:0.143865 lr:6.00e-05[train] 1637/33336 1449(s) eta:28058(s) loss:0.188143 loss200:0.144949 lr:6.00e-05[train] 1638/33336 1449(s) eta:28040(s) loss:0.188104 loss200:0.144829 lr:6.00e-05[train] 1639/33336 1450(s) eta:28041(s) loss:0.188022 loss200:0.144150 lr:6.00e-05[train] 1640/33336 1451(s) eta:28043(s) loss:0.188005 loss200:0.143593 lr:6.00e-05[train] 1641/33336 1452(s) eta:28044(s) loss:0.188056 loss200:0.144647 lr:6.00e-05[train] 1642/33336 1453(s) eta:28045(s) loss:0.188011 loss200:0.144451 lr:6.00e-05[train] 1643/33336 1454(s) eta:28047(s) loss:0.187952 loss200:0.144404 lr:6.00e-05[train] 1644/33336 1455(s) eta:28048(s) loss:0.187957 loss200:0.145087 lr:6.00e-05[train] 1645/33336 1456(s) eta:28049(s) loss:0.187909 loss200:0.145357 lr:6.00e-05[train] 1646/33336 1457(s) eta:28051(s) loss:0.187837 loss200:0.145134 lr:6.00e-05[train] 1647/33336 1458(s) eta:28052(s) loss:0.187910 loss200:0.145768 lr:6.00e-05[train] 1648/33336 1458(s) eta:28034(s) loss:0.187947 loss200:0.146339 lr:6.00e-05[train] 1649/33336 1459(s) eta:28035(s) loss:0.187976 loss200:0.147112 lr:6.00e-05[train] 1650/33336 1460(s) eta:28037(s) loss:0.187897 loss200:0.145629 lr:6.00e-05[train] 1651/33336 1461(s) eta:28038(s) loss:0.187840 loss200:0.143742 lr:6.00e-05[train] 1652/33336 1462(s) eta:28039(s) loss:0.187782 loss200:0.143253 lr:6.00e-05[train] 1653/33336 1463(s) eta:28041(s) loss:0.187725 loss200:0.142880 lr:6.00e-05[train] 1654/33336 1464(s) eta:28042(s) loss:0.187709 loss200:0.143448 lr:6.00e-05[train] 1655/33336 1465(s) eta:28043(s) loss:0.187668 loss200:0.143626 lr:6.00e-05[train] 1656/33336 1465(s) eta:28026(s) loss:0.187663 loss200:0.143273 lr:6.00e-05[train] 1657/33336 1466(s) eta:28027(s) loss:0.187657 loss200:0.143964 lr:6.00e-05[train] 1658/33336 1467(s) eta:28028(s) loss:0.187706 loss200:0.144998 lr:6.00e-05[train] 1659/33336 1468(s) eta:28030(s) loss:0.187634 loss200:0.144713 lr:6.00e-05[train] 1660/33336 1469(s) eta:28031(s) loss:0.187545 loss200:0.143943 lr:6.00e-05[train] 1661/33336 1470(s) eta:28032(s) loss:0.187558 loss200:0.144029 lr:6.00e-05[train] 1662/33336 1471(s) eta:28033(s) loss:0.187508 loss200:0.143809 lr:6.00e-05[train] 1663/33336 1472(s) eta:28035(s) loss:0.187462 loss200:0.143167 lr:6.00e-05[train] 1664/33336 1473(s) eta:28036(s) loss:0.187438 loss200:0.143073 lr:6.00e-05[train] 1665/33336 1473(s) eta:28018(s) loss:0.187370 loss200:0.143218 lr:6.00e-05[train] 1666/33336 1474(s) eta:28020(s) loss:0.187362 loss200:0.143500 lr:6.00e-05[train] 1667/33336 1475(s) eta:28021(s) loss:0.187269 loss200:0.143059 lr:6.00e-05[train] 1668/33336 1476(s) eta:28022(s) loss:0.187315 loss200:0.144023 lr:6.00e-05[train] 1669/33336 1477(s) eta:28024(s) loss:0.187312 loss200:0.144575 lr:6.00e-05[train] 1670/33336 1478(s) eta:28025(s) loss:0.187228 loss200:0.143520 lr:6.00e-05[train] 1671/33336 1479(s) eta:28026(s) loss:0.187176 loss200:0.143556 lr:6.00e-05[train] 1672/33336 1480(s) eta:28027(s) loss:0.187178 loss200:0.144194 lr:6.00e-05[train] 1673/33336 1480(s) eta:28010(s) loss:0.187109 loss200:0.144132 lr:6.00e-05[train] 1674/33336 1481(s) eta:28011(s) loss:0.187064 loss200:0.144209 lr:6.00e-05[train] 1675/33336 1482(s) eta:28012(s) loss:0.186985 loss200:0.144160 lr:6.00e-05[train] 1676/33336 1483(s) eta:28014(s) loss:0.186924 loss200:0.143852 lr:6.00e-05[train] 1677/33336 1484(s) eta:28015(s) loss:0.186928 loss200:0.143874 lr:6.00e-05[train] 1678/33336 1485(s) eta:28016(s) loss:0.186866 loss200:0.143977 lr:6.00e-05[train] 1679/33336 1486(s) eta:28018(s) loss:0.186845 loss200:0.144323 lr:6.00e-05[train] 1680/33336 1486(s) eta:28000(s) loss:0.186796 loss200:0.144005 lr:6.00e-05[train] 1681/33336 1487(s) eta:28001(s) loss:0.186717 loss200:0.142688 lr:6.00e-05[train] 1682/33336 1488(s) eta:28003(s) loss:0.186681 loss200:0.143069 lr:6.00e-05[train] 1683/33336 1489(s) eta:28004(s) loss:0.186590 loss200:0.141818 lr:6.00e-05[train] 1684/33336 1490(s) eta:28005(s) loss:0.186518 loss200:0.141161 lr:6.00e-05[train] 1685/33336 1491(s) eta:28006(s) loss:0.186455 loss200:0.141231 lr:6.00e-05[train] 1686/33336 1492(s) eta:28008(s) loss:0.186395 loss200:0.140835 lr:6.00e-05[train] 1687/33336 1493(s) eta:28009(s) loss:0.186317 loss200:0.140025 lr:6.00e-05[train] 1688/33336 1494(s) eta:28010(s) loss:0.186317 loss200:0.140320 lr:6.00e-05[train] 1689/33336 1494(s) eta:27993(s) loss:0.186463 loss200:0.141469 lr:6.00e-05[train] 1690/33336 1495(s) eta:27994(s) loss:0.186418 loss200:0.141122 lr:6.00e-05[train] 1691/33336 1496(s) eta:27995(s) loss:0.186581 loss200:0.142951 lr:6.00e-05[train] 1692/33336 1497(s) eta:27997(s) loss:0.186510 loss200:0.143000 lr:6.00e-05[train] 1693/33336 1498(s) eta:27998(s) loss:0.186418 loss200:0.142536 lr:6.00e-05[train] 1694/33336 1499(s) eta:27999(s) loss:0.186361 loss200:0.142493 lr:6.00e-05[train] 1695/33336 1500(s) eta:28000(s) loss:0.186331 loss200:0.142623 lr:6.00e-05[train] 1696/33336 1500(s) eta:27983(s) loss:0.186463 loss200:0.143447 lr:6.00e-05[train] 1697/33336 1501(s) eta:27984(s) loss:0.186434 loss200:0.142801 lr:6.00e-05[train] 1698/33336 1502(s) eta:27986(s) loss:0.186403 loss200:0.142250 lr:6.00e-05[train] 1699/33336 1503(s) eta:27987(s) loss:0.186425 loss200:0.143139 lr:6.00e-05[train] 1700/33336 1504(s) eta:27988(s) loss:0.186357 loss200:0.142687 lr:6.00e-05[train] 1701/33336 1505(s) eta:27989(s) loss:0.186384 loss200:0.143453 lr:6.00e-05[train] 1702/33336 1506(s) eta:27991(s) loss:0.186322 loss200:0.142625 lr:6.00e-05[train] 1703/33336 1507(s) eta:27992(s) loss:0.186278 loss200:0.141807 lr:6.00e-05[train] 1704/33336 1508(s) eta:27993(s) loss:0.186227 loss200:0.141940 lr:6.00e-05[train] 1705/33336 1508(s) eta:27976(s) loss:0.186267 loss200:0.142234 lr:6.00e-05[train] 1706/33336 1509(s) eta:27977(s) loss:0.186228 loss200:0.141465 lr:6.00e-05[train] 1707/33336 1510(s) eta:27978(s) loss:0.186202 loss200:0.141920 lr:6.00e-05[train] 1708/33336 1511(s) eta:27980(s) loss:0.186222 loss200:0.142534 lr:6.00e-05[train] 1709/33336 1512(s) eta:27981(s) loss:0.186281 loss200:0.143338 lr:6.00e-05[train] 1710/33336 1513(s) eta:27982(s) loss:0.186307 loss200:0.144143 lr:6.00e-05[train] 1711/33336 1514(s) eta:27983(s) loss:0.186263 loss200:0.144134 lr:6.00e-05[train] 1712/33336 1515(s) eta:27985(s) loss:0.186262 loss200:0.144095 lr:6.00e-05[train] 1713/33336 1515(s) eta:27967(s) loss:0.186220 loss200:0.143928 lr:6.00e-05[train] 1714/33336 1516(s) eta:27969(s) loss:0.186175 loss200:0.144135 lr:6.00e-05[train] 1715/33336 1517(s) eta:27970(s) loss:0.186091 loss200:0.143235 lr:6.00e-05[train] 1716/33336 1518(s) eta:27971(s) loss:0.186028 loss200:0.142701 lr:6.00e-05[train] 1717/33336 1519(s) eta:27972(s) loss:0.185971 loss200:0.142869 lr:6.00e-05[train] 1718/33336 1520(s) eta:27974(s) loss:0.185947 loss200:0.142620 lr:6.00e-05[train] 1719/33336 1521(s) eta:27975(s) loss:0.186041 loss200:0.143484 lr:6.00e-05[train] 1720/33336 1522(s) eta:27976(s) loss:0.185999 loss200:0.143668 lr:6.00e-05[train] 1721/33336 1523(s) eta:27977(s) loss:0.185963 loss200:0.143839 lr:6.00e-05[train] 1722/33336 1523(s) eta:27960(s) loss:0.185881 loss200:0.143517 lr:6.00e-05[train] 1723/33336 1524(s) eta:27961(s) loss:0.185824 loss200:0.143578 lr:6.00e-05[train] 1724/33336 1525(s) eta:27963(s) loss:0.185757 loss200:0.142297 lr:6.00e-05[train] 1725/33336 1526(s) eta:27964(s) loss:0.185852 loss200:0.143032 lr:6.00e-05[train] 1726/33336 1527(s) eta:27965(s) loss:0.185818 loss200:0.142358 lr:6.00e-05[train] 1727/33336 1528(s) eta:27966(s) loss:0.185820 loss200:0.142811 lr:6.00e-05[train] 1728/33336 1529(s) eta:27967(s) loss:0.185789 loss200:0.142486 lr:6.00e-05[train] 1729/33336 1529(s) eta:27950(s) loss:0.185769 loss200:0.142585 lr:6.00e-05[train] 1730/33336 1530(s) eta:27952(s) loss:0.185763 loss200:0.142564 lr:6.00e-05[train] 1731/33336 1531(s) eta:27953(s) loss:0.185787 loss200:0.143218 lr:6.00e-05[train] 1732/33336 1532(s) eta:27954(s) loss:0.185745 loss200:0.143276 lr:6.00e-05[train] 1733/33336 1533(s) eta:27955(s) loss:0.185755 loss200:0.143134 lr:6.00e-05[train] 1734/33336 1534(s) eta:27957(s) loss:0.185701 loss200:0.142815 lr:6.00e-05[train] 1735/33336 1535(s) eta:27958(s) loss:0.185671 loss200:0.143129 lr:6.00e-05[train] 1736/33336 1536(s) eta:27959(s) loss:0.185585 loss200:0.141718 lr:6.00e-05[train] 1737/33336 1536(s) eta:27942(s) loss:0.185528 loss200:0.140866 lr:6.00e-05[train] 1738/33336 1537(s) eta:27943(s) loss:0.185504 loss200:0.141060 lr:6.00e-05[train] 1739/33336 1538(s) eta:27944(s) loss:0.185473 loss200:0.141117 lr:6.00e-05[train] 1740/33336 1539(s) eta:27946(s) loss:0.185406 loss200:0.141071 lr:6.00e-05[train] 1741/33336 1540(s) eta:27947(s) loss:0.185401 loss200:0.141440 lr:6.00e-05[train] 1742/33336 1541(s) eta:27948(s) loss:0.185348 loss200:0.141298 lr:6.00e-05[train] 1743/33336 1542(s) eta:27949(s) loss:0.185376 loss200:0.141805 lr:6.00e-05[train] 1744/33336 1543(s) eta:27950(s) loss:0.185332 loss200:0.140658 lr:6.00e-05[train] 1745/33336 1543(s) eta:27934(s) loss:0.185286 loss200:0.140177 lr:6.00e-05[train] 1746/33336 1544(s) eta:27935(s) loss:0.185251 loss200:0.140490 lr:6.00e-05[train] 1747/33336 1545(s) eta:27936(s) loss:0.185181 loss200:0.140025 lr:6.00e-05[train] 1748/33336 1546(s) eta:27937(s) loss:0.185106 loss200:0.140044 lr:6.00e-05[train] 1749/33336 1547(s) eta:27938(s) loss:0.185040 loss200:0.139644 lr:6.00e-05[train] 1750/33336 1548(s) eta:27940(s) loss:0.185106 loss200:0.140734 lr:6.00e-05[train] 1751/33336 1549(s) eta:27941(s) loss:0.185065 loss200:0.140588 lr:6.00e-05[train] 1752/33336 1549(s) eta:27924(s) loss:0.185129 loss200:0.141517 lr:6.00e-05[train] 1753/33336 1550(s) eta:27925(s) loss:0.185058 loss200:0.140986 lr:6.00e-05[train] 1754/33336 1551(s) eta:27926(s) loss:0.185080 loss200:0.141708 lr:6.00e-05[train] 1755/33336 1552(s) eta:27928(s) loss:0.185034 loss200:0.141847 lr:6.00e-05[train] 1756/33336 1553(s) eta:27929(s) loss:0.185069 loss200:0.142837 lr:6.00e-05[train] 1757/33336 1554(s) eta:27930(s) loss:0.185051 loss200:0.142656 lr:6.00e-05[train] 1758/33336 1555(s) eta:27931(s) loss:0.185057 loss200:0.142488 lr:6.00e-05[train] 1759/33336 1556(s) eta:27932(s) loss:0.185134 loss200:0.143430 lr:6.00e-05[train] 1760/33336 1557(s) eta:27933(s) loss:0.185103 loss200:0.142919 lr:6.00e-05[train] 1761/33336 1557(s) eta:27917(s) loss:0.185062 loss200:0.142585 lr:6.00e-05[train] 1762/33336 1558(s) eta:27918(s) loss:0.185077 loss200:0.142628 lr:6.00e-05[train] 1763/33336 1559(s) eta:27919(s) loss:0.185056 loss200:0.142363 lr:6.00e-05[train] 1764/33336 1560(s) eta:27920(s) loss:0.185016 loss200:0.142164 lr:6.00e-05[train] 1765/33336 1561(s) eta:27922(s) loss:0.184975 loss200:0.142287 lr:6.00e-05[train] 1766/33336 1562(s) eta:27923(s) loss:0.184934 loss200:0.141193 lr:6.00e-05[train] 1767/33336 1563(s) eta:27924(s) loss:0.184892 loss200:0.141344 lr:6.00e-05[train] 1768/33336 1564(s) eta:27925(s) loss:0.184864 loss200:0.141483 lr:6.00e-05[train] 1769/33336 1564(s) eta:27908(s) loss:0.184780 loss200:0.141093 lr:6.00e-05[train] 1770/33336 1565(s) eta:27910(s) loss:0.184740 loss200:0.141111 lr:6.00e-05[train] 1771/33336 1566(s) eta:27911(s) loss:0.184673 loss200:0.140982 lr:6.00e-05[train] 1772/33336 1567(s) eta:27912(s) loss:0.184697 loss200:0.141518 lr:6.00e-05[train] 1773/33336 1568(s) eta:27913(s) loss:0.184625 loss200:0.141471 lr:6.00e-05[train] 1774/33336 1569(s) eta:27914(s) loss:0.184603 loss200:0.141525 lr:6.00e-05[train] 1775/33336 1570(s) eta:27915(s) loss:0.184537 loss200:0.141529 lr:6.00e-05[train] 1776/33336 1571(s) eta:27917(s) loss:0.184495 loss200:0.141579 lr:6.00e-05[train] 1777/33336 1571(s) eta:27900(s) loss:0.184412 loss200:0.141215 lr:6.00e-05[train] 1778/33336 1572(s) eta:27901(s) loss:0.184343 loss200:0.140868 lr:6.00e-05[train] 1779/33336 1573(s) eta:27902(s) loss:0.184265 loss200:0.140651 lr:6.00e-05[train] 1780/33336 1574(s) eta:27904(s) loss:0.184185 loss200:0.139883 lr:6.00e-05[train] 1781/33336 1575(s) eta:27905(s) loss:0.184128 loss200:0.139576 lr:6.00e-05[train] 1782/33336 1576(s) eta:27906(s) loss:0.184128 loss200:0.139811 lr:6.00e-05[train] 1783/33336 1577(s) eta:27907(s) loss:0.184126 loss200:0.139594 lr:6.00e-05[train] 1784/33336 1578(s) eta:27908(s) loss:0.184052 loss200:0.139246 lr:6.00e-05[train] 1785/33336 1579(s) eta:27909(s) loss:0.184073 loss200:0.139700 lr:6.00e-05[train] 1786/33336 1580(s) eta:27910(s) loss:0.184118 loss200:0.139697 lr:6.00e-05[train] 1787/33336 1580(s) eta:27894(s) loss:0.184063 loss200:0.139620 lr:6.00e-05[train] 1788/33336 1581(s) eta:27895(s) loss:0.184016 loss200:0.139727 lr:6.00e-05[train] 1789/33336 1582(s) eta:27896(s) loss:0.184007 loss200:0.140179 lr:6.00e-05[train] 1790/33336 1583(s) eta:27897(s) loss:0.184038 loss200:0.141178 lr:6.00e-05[train] 1791/33336 1584(s) eta:27899(s) loss:0.184018 loss200:0.141590 lr:6.00e-05[train] 1792/33336 1585(s) eta:27900(s) loss:0.183958 loss200:0.141516 lr:6.00e-05[train] 1793/33336 1586(s) eta:27901(s) loss:0.183934 loss200:0.141899 lr:6.00e-05[train] 1794/33336 1587(s) eta:27902(s) loss:0.183905 loss200:0.141326 lr:6.00e-05[train] 1795/33336 1587(s) eta:27886(s) loss:0.183985 loss200:0.142703 lr:6.00e-05[train] 1796/33336 1588(s) eta:27887(s) loss:0.183985 loss200:0.143271 lr:6.00e-05[train] 1797/33336 1589(s) eta:27888(s) loss:0.183919 loss200:0.143397 lr:6.00e-05[train] 1798/33336 1590(s) eta:27889(s) loss:0.183851 loss200:0.143110 lr:6.00e-05[train] 1799/33336 1591(s) eta:27890(s) loss:0.183800 loss200:0.142270 lr:6.00e-05[train] 1800/33336 1592(s) eta:27891(s) loss:0.183769 loss200:0.141297 lr:6.00e-05[train] 1801/33336 1593(s) eta:27892(s) loss:0.183735 loss200:0.141423 lr:6.00e-05[train] 1802/33336 1593(s) eta:27876(s) loss:0.183709 loss200:0.141434 lr:6.00e-05[train] 1803/33336 1594(s) eta:27877(s) loss:0.183643 loss200:0.141122 lr:6.00e-05[train] 1804/33336 1595(s) eta:27878(s) loss:0.183668 loss200:0.140554 lr:6.00e-05[train] 1805/33336 1596(s) eta:27880(s) loss:0.183650 loss200:0.140749 lr:6.00e-05[train] 1806/33336 1597(s) eta:27881(s) loss:0.183599 loss200:0.139597 lr:6.00e-05[train] 1807/33336 1598(s) eta:27882(s) loss:0.183604 loss200:0.139689 lr:6.00e-05[train] 1808/33336 1599(s) eta:27883(s) loss:0.183544 loss200:0.139769 lr:6.00e-05[train] 1809/33336 1600(s) eta:27884(s) loss:0.183472 loss200:0.139072 lr:6.00e-05[train] 1810/33336 1600(s) eta:27868(s) loss:0.183422 loss200:0.138904 lr:6.00e-05[train] 1811/33336 1601(s) eta:27869(s) loss:0.183393 loss200:0.139292 lr:6.00e-05[train] 1812/33336 1602(s) eta:27870(s) loss:0.183323 loss200:0.139271 lr:6.00e-05[train] 1813/33336 1603(s) eta:27871(s) loss:0.183274 loss200:0.138588 lr:6.00e-05[train] 1814/33336 1604(s) eta:27872(s) loss:0.183259 loss200:0.138667 lr:6.00e-05[train] 1815/33336 1605(s) eta:27873(s) loss:0.183216 loss200:0.138761 lr:6.00e-05[train] 1816/33336 1606(s) eta:27875(s) loss:0.183149 loss200:0.138799 lr:6.00e-05[train] 1817/33336 1607(s) eta:27876(s) loss:0.183115 loss200:0.138540 lr:6.00e-05[train] 1818/33336 1608(s) eta:27877(s) loss:0.183065 loss200:0.137854 lr:6.00e-05[train] 1819/33336 1608(s) eta:27861(s) loss:0.183003 loss200:0.137232 lr:6.00e-05[train] 1820/33336 1609(s) eta:27862(s) loss:0.183028 loss200:0.137683 lr:6.00e-05[train] 1821/33336 1610(s) eta:27863(s) loss:0.182955 loss200:0.137517 lr:6.00e-05[train] 1822/33336 1611(s) eta:27864(s) loss:0.182906 loss200:0.137534 lr:6.00e-05[train] 1823/33336 1612(s) eta:27865(s) loss:0.182845 loss200:0.136424 lr:6.00e-05[train] 1824/33336 1613(s) eta:27866(s) loss:0.182859 loss200:0.136919 lr:6.00e-05[train] 1825/33336 1614(s) eta:27867(s) loss:0.182800 loss200:0.136909 lr:6.00e-05[train] 1826/33336 1615(s) eta:27868(s) loss:0.182774 loss200:0.136617 lr:6.00e-05[train] 1827/33336 1616(s) eta:27870(s) loss:0.182730 loss200:0.136777 lr:6.00e-05[train] 1828/33336 1617(s) eta:27871(s) loss:0.182769 loss200:0.137549 lr:6.00e-05[train] 1829/33336 1617(s) eta:27855(s) loss:0.182696 loss200:0.136892 lr:6.00e-05[train] 1830/33336 1618(s) eta:27856(s) loss:0.182670 loss200:0.137092 lr:6.00e-05[train] 1831/33336 1619(s) eta:27857(s) loss:0.182618 loss200:0.137088 lr:6.00e-05[train] 1832/33336 1620(s) eta:27858(s) loss:0.182590 loss200:0.137401 lr:6.00e-05[train] 1833/33336 1621(s) eta:27859(s) loss:0.182526 loss200:0.136658 lr:6.00e-05[train] 1834/33336 1622(s) eta:27860(s) loss:0.182520 loss200:0.136797 lr:6.00e-05[train] 1835/33336 1623(s) eta:27861(s) loss:0.182482 loss200:0.135955 lr:6.00e-05[train] 1836/33336 1624(s) eta:27862(s) loss:0.182418 loss200:0.136052 lr:6.00e-05[train] 1837/33336 1624(s) eta:27846(s) loss:0.182360 loss200:0.135028 lr:6.00e-05[train] 1838/33336 1625(s) eta:27847(s) loss:0.182456 loss200:0.136202 lr:6.00e-05[train] 1839/33336 1626(s) eta:27848(s) loss:0.182468 loss200:0.136960 lr:6.00e-05[train] 1840/33336 1627(s) eta:27849(s) loss:0.182446 loss200:0.136856 lr:6.00e-05[train] 1841/33336 1628(s) eta:27851(s) loss:0.182466 loss200:0.136598 lr:6.00e-05[train] 1842/33336 1629(s) eta:27852(s) loss:0.182405 loss200:0.136372 lr:6.00e-05[train] 1843/33336 1630(s) eta:27853(s) loss:0.182397 loss200:0.136764 lr:6.00e-05[train] 1844/33336 1631(s) eta:27854(s) loss:0.182521 loss200:0.137836 lr:6.00e-05[train] 1845/33336 1632(s) eta:27855(s) loss:0.182464 loss200:0.137680 lr:6.00e-05[train] 1846/33336 1632(s) eta:27839(s) loss:0.182424 loss200:0.137877 lr:6.00e-05[train] 1847/33336 1633(s) eta:27840(s) loss:0.182400 loss200:0.137029 lr:6.00e-05[train] 1848/33336 1634(s) eta:27841(s) loss:0.182387 loss200:0.136566 lr:6.00e-05[train] 1849/33336 1635(s) eta:27842(s) loss:0.182331 loss200:0.135789 lr:6.00e-05[train] 1850/33336 1636(s) eta:27843(s) loss:0.182279 loss200:0.135926 lr:6.00e-05[train] 1851/33336 1637(s) eta:27844(s) loss:0.182298 loss200:0.136551 lr:6.00e-05[train] 1852/33336 1638(s) eta:27846(s) loss:0.182295 loss200:0.136971 lr:6.00e-05[train] 1853/33336 1639(s) eta:27847(s) loss:0.182308 loss200:0.137539 lr:6.00e-05[train] 1854/33336 1640(s) eta:27848(s) loss:0.182243 loss200:0.137033 lr:6.00e-05[train] 1855/33336 1640(s) eta:27832(s) loss:0.182224 loss200:0.137174 lr:6.00e-05[train] 1856/33336 1641(s) eta:27833(s) loss:0.182182 loss200:0.136806 lr:6.00e-05[train] 1857/33336 1642(s) eta:27834(s) loss:0.182169 loss200:0.136704 lr:6.00e-05[train] 1858/33336 1643(s) eta:27835(s) loss:0.182156 loss200:0.136148 lr:6.00e-05[train] 1859/33336 1644(s) eta:27836(s) loss:0.182139 loss200:0.136553 lr:6.00e-05[train] 1860/33336 1645(s) eta:27837(s) loss:0.182129 loss200:0.137168 lr:6.00e-05[train] 1861/33336 1646(s) eta:27838(s) loss:0.182106 loss200:0.136831 lr:6.00e-05[train] 1862/33336 1647(s) eta:27839(s) loss:0.182067 loss200:0.136848 lr:6.00e-05[train] 1863/33336 1648(s) eta:27840(s) loss:0.182045 loss200:0.137004 lr:6.00e-05[train] 1864/33336 1648(s) eta:27825(s) loss:0.182008 loss200:0.136836 lr:6.00e-05[train] 1865/33336 1649(s) eta:27826(s) loss:0.182178 loss200:0.138959 lr:6.00e-05[train] 1866/33336 1650(s) eta:27827(s) loss:0.182330 loss200:0.140410 lr:6.00e-05[train] 1867/33336 1651(s) eta:27828(s) loss:0.182293 loss200:0.140813 lr:6.00e-05[train] 1868/33336 1652(s) eta:27829(s) loss:0.182275 loss200:0.140239 lr:6.00e-05[train] 1869/33336 1653(s) eta:27830(s) loss:0.182251 loss200:0.140020 lr:6.00e-05[train] 1870/33336 1654(s) eta:27831(s) loss:0.182358 loss200:0.141695 lr:6.00e-05[train] 1871/33336 1655(s) eta:27832(s) loss:0.182330 loss200:0.141844 lr:6.00e-05[train] 1872/33336 1655(s) eta:27816(s) loss:0.182340 loss200:0.141900 lr:6.00e-05[train] 1873/33336 1656(s) eta:27817(s) loss:0.182313 loss200:0.142197 lr:6.00e-05[train] 1874/33336 1657(s) eta:27818(s) loss:0.182237 loss200:0.141831 lr:6.00e-05[train] 1875/33336 1658(s) eta:27819(s) loss:0.182230 loss200:0.142407 lr:6.00e-05[train] 1876/33336 1659(s) eta:27820(s) loss:0.182201 loss200:0.142624 lr:6.00e-05[train] 1877/33336 1660(s) eta:27822(s) loss:0.182204 loss200:0.142589 lr:6.00e-05[train] 1878/33336 1661(s) eta:27823(s) loss:0.182181 loss200:0.142874 lr:6.00e-05[train] 1879/33336 1662(s) eta:27824(s) loss:0.182129 loss200:0.142540 lr:6.00e-05[train] 1880/33336 1662(s) eta:27808(s) loss:0.182085 loss200:0.142517 lr:6.00e-05[train] 1881/33336 1663(s) eta:27809(s) loss:0.182014 loss200:0.142486 lr:6.00e-05[train] 1882/33336 1664(s) eta:27810(s) loss:0.181983 loss200:0.142473 lr:6.00e-05[train] 1883/33336 1665(s) eta:27811(s) loss:0.181926 loss200:0.142682 lr:6.00e-05[train] 1884/33336 1666(s) eta:27812(s) loss:0.181882 loss200:0.142846 lr:6.00e-05[train] 1885/33336 1667(s) eta:27813(s) loss:0.181861 loss200:0.143151 lr:6.00e-05[train] 1886/33336 1668(s) eta:27814(s) loss:0.181824 loss200:0.143288 lr:6.00e-05[train] 1887/33336 1669(s) eta:27815(s) loss:0.181772 loss200:0.143429 lr:6.00e-05[train] 1888/33336 1669(s) eta:27800(s) loss:0.181747 loss200:0.143176 lr:6.00e-05[train] 1889/33336 1670(s) eta:27801(s) loss:0.181699 loss200:0.141469 lr:6.00e-05[train] 1890/33336 1671(s) eta:27802(s) loss:0.181654 loss200:0.141398 lr:6.00e-05[train] 1891/33336 1672(s) eta:27803(s) loss:0.181580 loss200:0.139300 lr:6.00e-05[train] 1892/33336 1673(s) eta:27804(s) loss:0.181520 loss200:0.139309 lr:6.00e-05[train] 1893/33336 1674(s) eta:27805(s) loss:0.181538 loss200:0.140229 lr:6.00e-05[train] 1894/33336 1675(s) eta:27806(s) loss:0.181515 loss200:0.140461 lr:6.00e-05[train] 1895/33336 1676(s) eta:27807(s) loss:0.181460 loss200:0.140184 lr:6.00e-05[train] 1896/33336 1676(s) eta:27791(s) loss:0.181446 loss200:0.138896 lr:6.00e-05[train] 1897/33336 1677(s) eta:27792(s) loss:0.181416 loss200:0.138834 lr:6.00e-05[train] 1898/33336 1678(s) eta:27793(s) loss:0.181413 loss200:0.139048 lr:6.00e-05[train] 1899/33336 1679(s) eta:27795(s) loss:0.181355 loss200:0.138290 lr:6.00e-05[train] 1900/33336 1680(s) eta:27796(s) loss:0.181363 loss200:0.138913 lr:6.00e-05[train] 1901/33336 1681(s) eta:27797(s) loss:0.181314 loss200:0.138196 lr:6.00e-05[train] 1902/33336 1682(s) eta:27798(s) loss:0.181249 loss200:0.138076 lr:6.00e-05[train] 1903/33336 1683(s) eta:27799(s) loss:0.181216 loss200:0.138115 lr:6.00e-05[train] 1904/33336 1684(s) eta:27800(s) loss:0.181182 loss200:0.138202 lr:6.00e-05[train] 1905/33336 1684(s) eta:27784(s) loss:0.181217 loss200:0.138162 lr:6.00e-05[train] 1906/33336 1685(s) eta:27785(s) loss:0.181167 loss200:0.138002 lr:6.00e-05[train] 1907/33336 1686(s) eta:27786(s) loss:0.181172 loss200:0.138243 lr:6.00e-05[train] 1908/33336 1687(s) eta:27787(s) loss:0.181112 loss200:0.137474 lr:6.00e-05[train] 1909/33336 1688(s) eta:27788(s) loss:0.181058 loss200:0.136428 lr:6.00e-05[train] 1910/33336 1689(s) eta:27789(s) loss:0.181013 loss200:0.135752 lr:6.00e-05[train] 1911/33336 1690(s) eta:27790(s) loss:0.180952 loss200:0.135517 lr:6.00e-05[train] 1912/33336 1690(s) eta:27775(s) loss:0.180925 loss200:0.135243 lr:6.00e-05[train] 1913/33336 1691(s) eta:27776(s) loss:0.180984 loss200:0.136139 lr:6.00e-05[train] 1914/33336 1692(s) eta:27777(s) loss:0.180959 loss200:0.136260 lr:6.00e-05[train] 1915/33336 1693(s) eta:27778(s) loss:0.180881 loss200:0.136210 lr:6.00e-05[train] 1916/33336 1694(s) eta:27779(s) loss:0.180806 loss200:0.136004 lr:6.00e-05[train] 1917/33336 1695(s) eta:27780(s) loss:0.180728 loss200:0.135716 lr:6.00e-05[train] 1918/33336 1696(s) eta:27781(s) loss:0.180668 loss200:0.135316 lr:6.00e-05[train] 1919/33336 1697(s) eta:27782(s) loss:0.180816 loss200:0.135905 lr:6.00e-05[train] 1920/33336 1697(s) eta:27767(s) loss:0.180819 loss200:0.136272 lr:6.00e-05[train] 1921/33336 1698(s) eta:27768(s) loss:0.180813 loss200:0.136496 lr:6.00e-05[train] 1922/33336 1699(s) eta:27769(s) loss:0.180816 loss200:0.137204 lr:6.00e-05[train] 1923/33336 1700(s) eta:27770(s) loss:0.180820 loss200:0.137706 lr:6.00e-05[train] 1924/33336 1701(s) eta:27771(s) loss:0.180815 loss200:0.138217 lr:6.00e-05[train] 1925/33336 1702(s) eta:27772(s) loss:0.180754 loss200:0.136786 lr:6.00e-05[train] 1926/33336 1703(s) eta:27773(s) loss:0.180752 loss200:0.137032 lr:6.00e-05[train] 1927/33336 1704(s) eta:27774(s) loss:0.180730 loss200:0.136773 lr:6.00e-05[train] 1928/33336 1705(s) eta:27775(s) loss:0.180674 loss200:0.136481 lr:6.00e-05[train] 1929/33336 1705(s) eta:27759(s) loss:0.180654 loss200:0.136436 lr:6.00e-05[train] 1930/33336 1706(s) eta:27760(s) loss:0.180594 loss200:0.135882 lr:6.00e-05[train] 1931/33336 1707(s) eta:27761(s) loss:0.180612 loss200:0.135821 lr:6.00e-05[train] 1932/33336 1708(s) eta:27762(s) loss:0.180547 loss200:0.135534 lr:6.00e-05[train] 1933/33336 1709(s) eta:27763(s) loss:0.180532 loss200:0.135272 lr:6.00e-05[train] 1934/33336 1710(s) eta:27764(s) loss:0.180529 loss200:0.135688 lr:6.00e-05[train] 1935/33336 1711(s) eta:27765(s) loss:0.180477 loss200:0.135424 lr:6.00e-05[train] 1936/33336 1712(s) eta:27766(s) loss:0.180447 loss200:0.135853 lr:6.00e-05[train] 1937/33336 1712(s) eta:27751(s) loss:0.180483 loss200:0.136672 lr:6.00e-05[train] 1938/33336 1713(s) eta:27752(s) loss:0.180453 loss200:0.136555 lr:6.00e-05[train] 1939/33336 1714(s) eta:27753(s) loss:0.180456 loss200:0.136840 lr:6.00e-05[train] 1940/33336 1715(s) eta:27754(s) loss:0.180471 loss200:0.137533 lr:6.00e-05[train] 1941/33336 1716(s) eta:27755(s) loss:0.180450 loss200:0.137348 lr:6.00e-05[train] 1942/33336 1717(s) eta:27756(s) loss:0.180408 loss200:0.137380 lr:6.00e-05[train] 1943/33336 1718(s) eta:27757(s) loss:0.180413 loss200:0.137160 lr:6.00e-05[train] 1944/33336 1719(s) eta:27758(s) loss:0.180421 loss200:0.137594 lr:6.00e-05[train] 1945/33336 1719(s) eta:27743(s) loss:0.180395 loss200:0.137716 lr:6.00e-05[train] 1946/33336 1720(s) eta:27744(s) loss:0.180364 loss200:0.137697 lr:6.00e-05[train] 1947/33336 1721(s) eta:27745(s) loss:0.180322 loss200:0.137881 lr:6.00e-05[train] 1948/33336 1722(s) eta:27746(s) loss:0.180339 loss200:0.138671 lr:6.00e-05[train] 1949/33336 1723(s) eta:27747(s) loss:0.180302 loss200:0.138864 lr:6.00e-05[train] 1950/33336 1724(s) eta:27748(s) loss:0.180277 loss200:0.138029 lr:6.00e-05[train] 1951/33336 1725(s) eta:27749(s) loss:0.180245 loss200:0.138052 lr:6.00e-05[train] 1952/33336 1726(s) eta:27750(s) loss:0.180222 loss200:0.137241 lr:6.00e-05[train] 1953/33336 1726(s) eta:27735(s) loss:0.180169 loss200:0.137317 lr:6.00e-05[train] 1954/33336 1727(s) eta:27736(s) loss:0.180092 loss200:0.136346 lr:6.00e-05[train] 1955/33336 1728(s) eta:27737(s) loss:0.180047 loss200:0.136286 lr:6.00e-05[train] 1956/33336 1729(s) eta:27738(s) loss:0.179986 loss200:0.135352 lr:6.00e-05[train] 1957/33336 1730(s) eta:27739(s) loss:0.180010 loss200:0.135725 lr:6.00e-05[train] 1958/33336 1731(s) eta:27740(s) loss:0.179958 loss200:0.135135 lr:6.00e-05[train] 1959/33336 1732(s) eta:27741(s) loss:0.179953 loss200:0.134393 lr:6.00e-05[train] 1960/33336 1733(s) eta:27742(s) loss:0.179970 loss200:0.134806 lr:6.00e-05[train] 1961/33336 1734(s) eta:27743(s) loss:0.179934 loss200:0.134783 lr:6.00e-05[train] 1962/33336 1734(s) eta:27728(s) loss:0.179875 loss200:0.134046 lr:6.00e-05[train] 1963/33336 1735(s) eta:27729(s) loss:0.179841 loss200:0.133870 lr:6.00e-05[train] 1964/33336 1736(s) eta:27730(s) loss:0.179835 loss200:0.134142 lr:6.00e-05[train] 1965/33336 1737(s) eta:27731(s) loss:0.179837 loss200:0.134488 lr:6.00e-05[train] 1966/33336 1738(s) eta:27731(s) loss:0.179779 loss200:0.134255 lr:6.00e-05[train] 1967/33336 1739(s) eta:27732(s) loss:0.179746 loss200:0.134281 lr:6.00e-05[train] 1968/33336 1740(s) eta:27733(s) loss:0.179743 loss200:0.134473 lr:6.00e-05[train] 1969/33336 1741(s) eta:27734(s) loss:0.179680 loss200:0.134572 lr:6.00e-05[train] 1970/33336 1742(s) eta:27735(s) loss:0.179619 loss200:0.134304 lr:6.00e-05[train] 1971/33336 1742(s) eta:27720(s) loss:0.179621 loss200:0.134882 lr:6.00e-05[train] 1972/33336 1743(s) eta:27721(s) loss:0.179579 loss200:0.134231 lr:6.00e-05[train] 1973/33336 1744(s) eta:27722(s) loss:0.179539 loss200:0.134459 lr:6.00e-05[train] 1974/33336 1745(s) eta:27723(s) loss:0.179519 loss200:0.134422 lr:6.00e-05[train] 1975/33336 1746(s) eta:27724(s) loss:0.179500 loss200:0.134797 lr:6.00e-05[train] 1976/33336 1747(s) eta:27725(s) loss:0.179512 loss200:0.135263 lr:6.00e-05[train] 1977/33336 1748(s) eta:27726(s) loss:0.179481 loss200:0.135671 lr:6.00e-05[train] 1978/33336 1749(s) eta:27727(s) loss:0.179504 loss200:0.136491 lr:6.00e-05[train] 1979/33336 1750(s) eta:27728(s) loss:0.179491 loss200:0.137029 lr:6.00e-05[train] 1980/33336 1750(s) eta:27713(s) loss:0.179463 loss200:0.137436 lr:6.00e-05[train] 1981/33336 1751(s) eta:27714(s) loss:0.179412 loss200:0.137409 lr:6.00e-05[train] 1982/33336 1752(s) eta:27715(s) loss:0.179383 loss200:0.137104 lr:6.00e-05[train] 1983/33336 1753(s) eta:27716(s) loss:0.179404 loss200:0.137304 lr:6.00e-05[train] 1984/33336 1754(s) eta:27717(s) loss:0.179352 loss200:0.137428 lr:6.00e-05[train] 1985/33336 1755(s) eta:27718(s) loss:0.179317 loss200:0.136865 lr:6.00e-05[train] 1986/33336 1756(s) eta:27719(s) loss:0.179384 loss200:0.137117 lr:6.00e-05[train] 1987/33336 1757(s) eta:27720(s) loss:0.179311 loss200:0.136850 lr:6.00e-05[train] 1988/33336 1758(s) eta:27721(s) loss:0.179438 loss200:0.138509 lr:6.00e-05[train] 1989/33336 1759(s) eta:27722(s) loss:0.179435 loss200:0.138541 lr:6.00e-05[train] 1990/33336 1759(s) eta:27707(s) loss:0.179450 loss200:0.138391 lr:6.00e-05[train] 1991/33336 1760(s) eta:27708(s) loss:0.179454 loss200:0.138579 lr:6.00e-05[train] 1992/33336 1761(s) eta:27709(s) loss:0.179436 loss200:0.138919 lr:6.00e-05[train] 1993/33336 1762(s) eta:27710(s) loss:0.179397 loss200:0.138721 lr:6.00e-05[train] 1994/33336 1763(s) eta:27711(s) loss:0.179461 loss200:0.139592 lr:6.00e-05[train] 1995/33336 1764(s) eta:27712(s) loss:0.179472 loss200:0.138972 lr:6.00e-05[train] 1996/33336 1765(s) eta:27712(s) loss:0.179407 loss200:0.138303 lr:6.00e-05[train] 1997/33336 1766(s) eta:27713(s) loss:0.179352 loss200:0.138320 lr:6.00e-05[train] 1998/33336 1766(s) eta:27699(s) loss:0.179320 loss200:0.138583 lr:6.00e-05[train] 1999/33336 1767(s) eta:27700(s) loss:0.179286 loss200:0.138685 lr:6.00e-05[train] 2000/33336 1768(s) eta:27701(s) loss:0.179237 loss200:0.138441 lr:6.00e-05[train] 2001/33336 1769(s) eta:27701(s) loss:0.179189 loss200:0.138249 lr:6.00e-05[train] 2002/33336 1770(s) eta:27702(s) loss:0.179143 loss200:0.138001 lr:6.00e-05[train] 2003/33336 1771(s) eta:27703(s) loss:0.179128 loss200:0.138428 lr:6.00e-05[train] 2004/33336 1772(s) eta:27704(s) loss:0.179114 loss200:0.138033 lr:6.00e-05[train] 2005/33336 1773(s) eta:27705(s) loss:0.179054 loss200:0.137570 lr:6.00e-05[train] 2006/33336 1774(s) eta:27706(s) loss:0.179027 loss200:0.137742 lr:6.00e-05[train] 2007/33336 1774(s) eta:27691(s) loss:0.178985 loss200:0.137256 lr:6.00e-05[train] 2008/33336 1775(s) eta:27692(s) loss:0.178995 loss200:0.137867 lr:6.00e-05[train] 2009/33336 1776(s) eta:27693(s) loss:0.178954 loss200:0.138092 lr:6.00e-05[train] 2010/33336 1777(s) eta:27694(s) loss:0.178967 loss200:0.138645 lr:6.00e-05[train] 2011/33336 1778(s) eta:27695(s) loss:0.178934 loss200:0.138557 lr:6.00e-05[train] 2012/33336 1779(s) eta:27696(s) loss:0.178887 loss200:0.138705 lr:6.00e-05[train] 2013/33336 1780(s) eta:27697(s) loss:0.178866 loss200:0.138902 lr:6.00e-05[train] 2014/33336 1781(s) eta:27698(s) loss:0.178849 loss200:0.138850 lr:6.00e-05[train] 2015/33336 1781(s) eta:27683(s) loss:0.178814 loss200:0.138871 lr:6.00e-05[train] 2016/33336 1782(s) eta:27684(s) loss:0.178830 loss200:0.139609 lr:6.00e-05[train] 2017/33336 1783(s) eta:27685(s) loss:0.178775 loss200:0.139344 lr:6.00e-05[train] 2018/33336 1784(s) eta:27686(s) loss:0.178760 loss200:0.139626 lr:6.00e-05[train] 2019/33336 1785(s) eta:27687(s) loss:0.178760 loss200:0.140169 lr:6.00e-05[train] 2020/33336 1786(s) eta:27688(s) loss:0.178794 loss200:0.140267 lr:6.00e-05[train] 2021/33336 1787(s) eta:27689(s) loss:0.178736 loss200:0.140324 lr:6.00e-05[train] 2022/33336 1788(s) eta:27690(s) loss:0.178676 loss200:0.140136 lr:6.00e-05[train] 2023/33336 1789(s) eta:27691(s) loss:0.178674 loss200:0.140656 lr:6.00e-05[train] 2024/33336 1789(s) eta:27676(s) loss:0.178651 loss200:0.140276 lr:6.00e-05[train] 2025/33336 1790(s) eta:27677(s) loss:0.178634 loss200:0.140620 lr:6.00e-05[train] 2026/33336 1791(s) eta:27678(s) loss:0.178701 loss200:0.141512 lr:6.00e-05[train] 2027/33336 1792(s) eta:27679(s) loss:0.178699 loss200:0.141876 lr:6.00e-05[train] 2028/33336 1793(s) eta:27680(s) loss:0.178644 loss200:0.140945 lr:6.00e-05[train] 2029/33336 1794(s) eta:27681(s) loss:0.178585 loss200:0.140992 lr:6.00e-05[train] 2030/33336 1795(s) eta:27681(s) loss:0.178536 loss200:0.140713 lr:6.00e-05[train] 2031/33336 1796(s) eta:27682(s) loss:0.178532 loss200:0.141130 lr:6.00e-05[train] 2032/33336 1796(s) eta:27668(s) loss:0.178491 loss200:0.140944 lr:6.00e-05[train] 2033/33336 1797(s) eta:27669(s) loss:0.178486 loss200:0.141460 lr:6.00e-05[train] 2034/33336 1798(s) eta:27670(s) loss:0.178454 loss200:0.141175 lr:6.00e-05[train] 2035/33336 1799(s) eta:27671(s) loss:0.178497 loss200:0.141932 lr:6.00e-05[train] 2036/33336 1800(s) eta:27671(s) loss:0.178532 loss200:0.142860 lr:6.00e-05[train] 2037/33336 1801(s) eta:27672(s) loss:0.178502 loss200:0.143062 lr:6.00e-05[train] 2038/33336 1802(s) eta:27673(s) loss:0.178474 loss200:0.141880 lr:6.00e-05[train] 2039/33336 1803(s) eta:27674(s) loss:0.178429 loss200:0.141283 lr:6.00e-05[train] 2040/33336 1803(s) eta:27660(s) loss:0.178425 loss200:0.141439 lr:6.00e-05[train] 2041/33336 1804(s) eta:27661(s) loss:0.178360 loss200:0.140566 lr:6.00e-05[train] 2042/33336 1805(s) eta:27661(s) loss:0.178306 loss200:0.140559 lr:6.00e-05[train] 2043/33336 1806(s) eta:27662(s) loss:0.178351 loss200:0.141067 lr:6.00e-05[train] 2044/33336 1807(s) eta:27663(s) loss:0.178287 loss200:0.139249 lr:6.00e-05[train] 2045/33336 1808(s) eta:27664(s) loss:0.178237 loss200:0.139240 lr:6.00e-05[train] 2046/33336 1809(s) eta:27665(s) loss:0.178189 loss200:0.139099 lr:6.00e-05[train] 2047/33336 1810(s) eta:27666(s) loss:0.178130 loss200:0.138693 lr:6.00e-05[train] 2048/33336 1811(s) eta:27667(s) loss:0.178148 loss200:0.138982 lr:6.00e-05[train] 2049/33336 1812(s) eta:27668(s) loss:0.178116 loss200:0.139149 lr:6.00e-05[train] 2050/33336 1812(s) eta:27653(s) loss:0.178053 loss200:0.138960 lr:6.00e-05[train] 2051/33336 1813(s) eta:27654(s) loss:0.178056 loss200:0.138796 lr:6.00e-05[train] 2052/33336 1814(s) eta:27655(s) loss:0.178087 loss200:0.139125 lr:6.00e-05[train] 2053/33336 1815(s) eta:27656(s) loss:0.178136 loss200:0.139483 lr:6.00e-05[train] 2054/33336 1816(s) eta:27657(s) loss:0.178142 loss200:0.140127 lr:6.00e-05[train] 2055/33336 1817(s) eta:27658(s) loss:0.178100 loss200:0.139845 lr:6.00e-05[train] 2056/33336 1818(s) eta:27659(s) loss:0.178061 loss200:0.139813 lr:6.00e-05[train] 2057/33336 1819(s) eta:27659(s) loss:0.178042 loss200:0.139720 lr:6.00e-05[train] 2058/33336 1819(s) eta:27645(s) loss:0.178054 loss200:0.139945 lr:6.00e-05[train] 2059/33336 1820(s) eta:27646(s) loss:0.178007 loss200:0.139605 lr:6.00e-05[train] 2060/33336 1821(s) eta:27647(s) loss:0.177976 loss200:0.139363 lr:6.00e-05[train] 2061/33336 1822(s) eta:27648(s) loss:0.177942 loss200:0.139194 lr:6.00e-05[train] 2062/33336 1823(s) eta:27649(s) loss:0.177950 loss200:0.139621 lr:6.00e-05[train] 2063/33336 1824(s) eta:27650(s) loss:0.177953 loss200:0.139835 lr:6.00e-05[train] 2064/33336 1825(s) eta:27650(s) loss:0.177934 loss200:0.139961 lr:6.00e-05[train] 2065/33336 1826(s) eta:27651(s) loss:0.177876 loss200:0.137757 lr:6.00e-05[train] 2066/33336 1827(s) eta:27652(s) loss:0.177836 loss200:0.135911 lr:6.00e-05[train] 2067/33336 1827(s) eta:27638(s) loss:0.177784 loss200:0.135690 lr:6.00e-05[train] 2068/33336 1828(s) eta:27639(s) loss:0.177722 loss200:0.135199 lr:6.00e-05[train] 2069/33336 1829(s) eta:27640(s) loss:0.177737 loss200:0.135554 lr:6.00e-05[train] 2070/33336 1830(s) eta:27640(s) loss:0.177724 loss200:0.134398 lr:6.00e-05[train] 2071/33336 1831(s) eta:27641(s) loss:0.177703 loss200:0.134413 lr:6.00e-05[train] 2072/33336 1832(s) eta:27642(s) loss:0.177703 loss200:0.134294 lr:6.00e-05[train] 2073/33336 1833(s) eta:27643(s) loss:0.177706 loss200:0.134557 lr:6.00e-05[train] 2074/33336 1833(s) eta:27629(s) loss:0.177693 loss200:0.135121 lr:6.00e-05[train] 2075/33336 1834(s) eta:27630(s) loss:0.177676 loss200:0.134984 lr:6.00e-05[train] 2076/33336 1835(s) eta:27631(s) loss:0.177613 loss200:0.134580 lr:6.00e-05[train] 2077/33336 1836(s) eta:27631(s) loss:0.177560 loss200:0.133981 lr:6.00e-05[train] 2078/33336 1837(s) eta:27632(s) loss:0.177566 loss200:0.134234 lr:6.00e-05[train] 2079/33336 1838(s) eta:27633(s) loss:0.177550 loss200:0.134529 lr:6.00e-05[train] 2080/33336 1839(s) eta:27634(s) loss:0.177511 loss200:0.134511 lr:6.00e-05[train] 2081/33336 1840(s) eta:27635(s) loss:0.177456 loss200:0.134591 lr:6.00e-05[train] 2082/33336 1840(s) eta:27621(s) loss:0.177406 loss200:0.134337 lr:6.00e-05[train] 2083/33336 1841(s) eta:27622(s) loss:0.177466 loss200:0.135476 lr:6.00e-05[train] 2084/33336 1842(s) eta:27622(s) loss:0.177431 loss200:0.135508 lr:6.00e-05[train] 2085/33336 1843(s) eta:27623(s) loss:0.177369 loss200:0.135041 lr:6.00e-05[train] 2086/33336 1844(s) eta:27624(s) loss:0.177326 loss200:0.134919 lr:6.00e-05[train] 2087/33336 1845(s) eta:27625(s) loss:0.177280 loss200:0.134903 lr:6.00e-05[train] 2088/33336 1846(s) eta:27626(s) loss:0.177217 loss200:0.134456 lr:6.00e-05[train] 2089/33336 1847(s) eta:27627(s) loss:0.177185 loss200:0.134546 lr:6.00e-05[train] 2090/33336 1847(s) eta:27613(s) loss:0.177183 loss200:0.134931 lr:6.00e-05[train] 2091/33336 1848(s) eta:27613(s) loss:0.177131 loss200:0.135057 lr:6.00e-05[train] 2092/33336 1849(s) eta:27614(s) loss:0.177093 loss200:0.135215 lr:6.00e-05[train] 2093/33336 1850(s) eta:27615(s) loss:0.177083 loss200:0.134917 lr:6.00e-05[train] 2094/33336 1851(s) eta:27616(s) loss:0.177029 loss200:0.134547 lr:6.00e-05[train] 2095/33336 1852(s) eta:27617(s) loss:0.176971 loss200:0.134433 lr:6.00e-05[train] 2096/33336 1853(s) eta:27618(s) loss:0.176924 loss200:0.134055 lr:6.00e-05[train] 2097/33336 1854(s) eta:27619(s) loss:0.176913 loss200:0.134202 lr:6.00e-05[train] 2098/33336 1855(s) eta:27619(s) loss:0.176877 loss200:0.133837 lr:6.00e-05[train] 2099/33336 1855(s) eta:27605(s) loss:0.176810 loss200:0.133647 lr:6.00e-05[train] 2100/33336 1856(s) eta:27606(s) loss:0.176763 loss200:0.133070 lr:6.00e-05[train] 2101/33336 1857(s) eta:27607(s) loss:0.176793 loss200:0.133816 lr:6.00e-05[train] 2102/33336 1858(s) eta:27608(s) loss:0.176726 loss200:0.133713 lr:6.00e-05[train] 2103/33336 1859(s) eta:27609(s) loss:0.176763 loss200:0.134388 lr:6.00e-05[train] 2104/33336 1860(s) eta:27610(s) loss:0.176818 loss200:0.135274 lr:6.00e-05[train] 2105/33336 1861(s) eta:27610(s) loss:0.176828 loss200:0.135022 lr:6.00e-05[train] 2106/33336 1862(s) eta:27611(s) loss:0.176789 loss200:0.135066 lr:6.00e-05[train] 2107/33336 1862(s) eta:27597(s) loss:0.176737 loss200:0.134451 lr:6.00e-05[train] 2108/33336 1863(s) eta:27598(s) loss:0.176685 loss200:0.134449 lr:6.00e-05[train] 2109/33336 1864(s) eta:27599(s) loss:0.176630 loss200:0.134364 lr:6.00e-05[train] 2110/33336 1865(s) eta:27600(s) loss:0.176558 loss200:0.134014 lr:6.00e-05[train] 2111/33336 1866(s) eta:27601(s) loss:0.176503 loss200:0.133995 lr:6.00e-05[train] 2112/33336 1867(s) eta:27601(s) loss:0.176459 loss200:0.133759 lr:6.00e-05[train] 2113/33336 1868(s) eta:27602(s) loss:0.176457 loss200:0.133155 lr:6.00e-05[train] 2114/33336 1869(s) eta:27603(s) loss:0.176391 loss200:0.132673 lr:6.00e-05[train] 2115/33336 1869(s) eta:27589(s) loss:0.176353 loss200:0.132991 lr:6.00e-05[train] 2116/33336 1870(s) eta:27590(s) loss:0.176307 loss200:0.133205 lr:6.00e-05[train] 2117/33336 1871(s) eta:27591(s) loss:0.176275 loss200:0.133596 lr:6.00e-05[train] 2118/33336 1872(s) eta:27592(s) loss:0.176231 loss200:0.133684 lr:6.00e-05[train] 2119/33336 1873(s) eta:27592(s) loss:0.176165 loss200:0.131540 lr:6.00e-05[train] 2120/33336 1874(s) eta:27593(s) loss:0.176157 loss200:0.131400 lr:6.00e-05[train] 2121/33336 1875(s) eta:27594(s) loss:0.176098 loss200:0.130814 lr:6.00e-05[train] 2122/33336 1876(s) eta:27595(s) loss:0.176072 loss200:0.130479 lr:6.00e-05[train] 2123/33336 1877(s) eta:27596(s) loss:0.176033 loss200:0.130011 lr:6.00e-05[train] 2124/33336 1877(s) eta:27582(s) loss:0.176167 loss200:0.131446 lr:6.00e-05[train] 2125/33336 1878(s) eta:27583(s) loss:0.176214 loss200:0.132514 lr:6.00e-05[train] 2126/33336 1879(s) eta:27584(s) loss:0.176159 loss200:0.131931 lr:6.00e-05[train] 2127/33336 1880(s) eta:27584(s) loss:0.176153 loss200:0.132056 lr:6.00e-05[train] 2128/33336 1881(s) eta:27585(s) loss:0.176203 loss200:0.133104 lr:6.00e-05[train] 2129/33336 1882(s) eta:27586(s) loss:0.176180 loss200:0.133031 lr:6.00e-05[train] 2130/33336 1883(s) eta:27587(s) loss:0.176157 loss200:0.133338 lr:6.00e-05[train] 2131/33336 1884(s) eta:27588(s) loss:0.176137 loss200:0.132938 lr:6.00e-05[train] 2132/33336 1884(s) eta:27574(s) loss:0.176132 loss200:0.133482 lr:6.00e-05[train] 2133/33336 1885(s) eta:27575(s) loss:0.176130 loss200:0.133585 lr:6.00e-05[train] 2134/33336 1886(s) eta:27575(s) loss:0.176066 loss200:0.132915 lr:6.00e-05[train] 2135/33336 1887(s) eta:27576(s) loss:0.176006 loss200:0.132745 lr:6.00e-05[train] 2136/33336 1888(s) eta:27577(s) loss:0.175935 loss200:0.132259 lr:6.00e-05[train] 2137/33336 1889(s) eta:27578(s) loss:0.175890 loss200:0.131404 lr:6.00e-05[train] 2138/33336 1890(s) eta:27579(s) loss:0.175897 loss200:0.131750 lr:6.00e-05[train] 2139/33336 1891(s) eta:27579(s) loss:0.175957 loss200:0.132334 lr:6.00e-05[train] 2140/33336 1892(s) eta:27580(s) loss:0.175989 loss200:0.132519 lr:6.00e-05[train] 2141/33336 1892(s) eta:27566(s) loss:0.176016 loss200:0.132989 lr:6.00e-05[train] 2142/33336 1893(s) eta:27567(s) loss:0.175998 loss200:0.133175 lr:6.00e-05[train] 2143/33336 1894(s) eta:27568(s) loss:0.176011 loss200:0.133242 lr:6.00e-05[train] 2144/33336 1895(s) eta:27569(s) loss:0.175951 loss200:0.132506 lr:6.00e-05[train] 2145/33336 1896(s) eta:27570(s) loss:0.175900 loss200:0.132187 lr:6.00e-05[train] 2146/33336 1897(s) eta:27571(s) loss:0.175847 loss200:0.131902 lr:6.00e-05[train] 2147/33336 1898(s) eta:27571(s) loss:0.175812 loss200:0.131904 lr:6.00e-05[train] 2148/33336 1899(s) eta:27572(s) loss:0.175823 loss200:0.131839 lr:6.00e-05[train] 2149/33336 1899(s) eta:27558(s) loss:0.175829 loss200:0.132238 lr:6.00e-05[train] 2150/33336 1900(s) eta:27559(s) loss:0.175812 loss200:0.132273 lr:6.00e-05[train] 2151/33336 1901(s) eta:27560(s) loss:0.175799 loss200:0.132422 lr:6.00e-05[train] 2152/33336 1902(s) eta:27561(s) loss:0.175756 loss200:0.132160 lr:6.00e-05[train] 2153/33336 1903(s) eta:27562(s) loss:0.175752 loss200:0.132621 lr:6.00e-05[train] 2154/33336 1904(s) eta:27562(s) loss:0.175898 loss200:0.134917 lr:6.00e-05[train] 2155/33336 1905(s) eta:27563(s) loss:0.175879 loss200:0.135143 lr:6.00e-05[train] 2156/33336 1906(s) eta:27564(s) loss:0.175915 loss200:0.136106 lr:6.00e-05[train] 2157/33336 1907(s) eta:27565(s) loss:0.175880 loss200:0.135472 lr:6.00e-05[train] 2158/33336 1907(s) eta:27551(s) loss:0.175898 loss200:0.136150 lr:6.00e-05[train] 2159/33336 1908(s) eta:27552(s) loss:0.175841 loss200:0.135561 lr:6.00e-05[train] 2160/33336 1909(s) eta:27553(s) loss:0.175795 loss200:0.134876 lr:6.00e-05[train] 2161/33336 1910(s) eta:27554(s) loss:0.175731 loss200:0.134523 lr:6.00e-05[train] 2162/33336 1911(s) eta:27554(s) loss:0.175708 loss200:0.134829 lr:6.00e-05[train] 2163/33336 1912(s) eta:27555(s) loss:0.175653 loss200:0.134550 lr:6.00e-05[train] 2164/33336 1913(s) eta:27556(s) loss:0.175685 loss200:0.134930 lr:6.00e-05[train] 2165/33336 1914(s) eta:27557(s) loss:0.175660 loss200:0.134618 lr:6.00e-05[train] 2166/33336 1914(s) eta:27543(s) loss:0.175617 loss200:0.134712 lr:6.00e-05[train] 2167/33336 1915(s) eta:27544(s) loss:0.175585 loss200:0.134661 lr:6.00e-05[train] 2168/33336 1916(s) eta:27545(s) loss:0.175578 loss200:0.134588 lr:6.00e-05[train] 2169/33336 1917(s) eta:27545(s) loss:0.175579 loss200:0.135208 lr:6.00e-05[train] 2170/33336 1918(s) eta:27546(s) loss:0.175551 loss200:0.135479 lr:6.00e-05[train] 2171/33336 1919(s) eta:27547(s) loss:0.175487 loss200:0.134743 lr:6.00e-05[train] 2172/33336 1920(s) eta:27548(s) loss:0.175457 loss200:0.134819 lr:6.00e-05[train] 2173/33336 1921(s) eta:27549(s) loss:0.175460 loss200:0.135219 lr:6.00e-05[train] 2174/33336 1921(s) eta:27535(s) loss:0.175427 loss200:0.135042 lr:6.00e-05[train] 2175/33336 1922(s) eta:27536(s) loss:0.175369 loss200:0.134581 lr:6.00e-05[train] 2176/33336 1923(s) eta:27537(s) loss:0.175322 loss200:0.133919 lr:6.00e-05[train] 2177/33336 1924(s) eta:27537(s) loss:0.175256 loss200:0.133488 lr:6.00e-05[train] 2178/33336 1925(s) eta:27538(s) loss:0.175193 loss200:0.132555 lr:6.00e-05[train] 2179/33336 1926(s) eta:27539(s) loss:0.175158 loss200:0.132275 lr:6.00e-05[train] 2180/33336 1927(s) eta:27540(s) loss:0.175157 loss200:0.132527 lr:6.00e-05[train] 2181/33336 1928(s) eta:27540(s) loss:0.175248 loss200:0.134012 lr:6.00e-05[train] 2182/33336 1928(s) eta:27527(s) loss:0.175243 loss200:0.134219 lr:6.00e-05[train] 2183/33336 1929(s) eta:27528(s) loss:0.175323 loss200:0.134858 lr:6.00e-05[train] 2184/33336 1930(s) eta:27529(s) loss:0.175281 loss200:0.134897 lr:6.00e-05[train] 2185/33336 1931(s) eta:27529(s) loss:0.175249 loss200:0.134873 lr:6.00e-05[train] 2186/33336 1932(s) eta:27530(s) loss:0.175202 loss200:0.133675 lr:6.00e-05[train] 2187/33336 1933(s) eta:27531(s) loss:0.175224 loss200:0.134617 lr:6.00e-05[train] 2188/33336 1934(s) eta:27532(s) loss:0.175291 loss200:0.134067 lr:6.00e-05[train] 2189/33336 1935(s) eta:27532(s) loss:0.175270 loss200:0.133848 lr:6.00e-05[train] 2190/33336 1936(s) eta:27533(s) loss:0.175252 loss200:0.133475 lr:6.00e-05[train] 2191/33336 1936(s) eta:27520(s) loss:0.175211 loss200:0.132969 lr:6.00e-05[train] 2192/33336 1937(s) eta:27520(s) loss:0.175184 loss200:0.132835 lr:6.00e-05[train] 2193/33336 1938(s) eta:27521(s) loss:0.175147 loss200:0.132794 lr:6.00e-05[train] 2194/33336 1939(s) eta:27522(s) loss:0.175138 loss200:0.132039 lr:6.00e-05[train] 2195/33336 1940(s) eta:27523(s) loss:0.175096 loss200:0.131442 lr:6.00e-05[train] 2196/33336 1941(s) eta:27524(s) loss:0.175044 loss200:0.131503 lr:6.00e-05[train] 2197/33336 1942(s) eta:27524(s) loss:0.175056 loss200:0.132159 lr:6.00e-05[train] 2198/33336 1943(s) eta:27525(s) loss:0.175061 loss200:0.132511 lr:6.00e-05[train] 2199/33336 1944(s) eta:27526(s) loss:0.175011 loss200:0.132281 lr:6.00e-05[train] 2200/33336 1944(s) eta:27512(s) loss:0.174962 loss200:0.132217 lr:6.00e-05[train] 2201/33336 1945(s) eta:27513(s) loss:0.174927 loss200:0.132289 lr:6.00e-05[train] 2202/33336 1946(s) eta:27514(s) loss:0.174916 loss200:0.132608 lr:6.00e-05[train] 2203/33336 1947(s) eta:27515(s) loss:0.174875 loss200:0.132279 lr:6.00e-05[train] 2204/33336 1948(s) eta:27515(s) loss:0.174816 loss200:0.131753 lr:6.00e-05[train] 2205/33336 1949(s) eta:27516(s) loss:0.174758 loss200:0.131692 lr:6.00e-05[train] 2206/33336 1950(s) eta:27517(s) loss:0.174706 loss200:0.131369 lr:6.00e-05[train] 2207/33336 1951(s) eta:27518(s) loss:0.174803 loss200:0.132837 lr:6.00e-05[train] 2208/33336 1951(s) eta:27504(s) loss:0.174762 loss200:0.132262 lr:6.00e-05[train] 2209/33336 1952(s) eta:27505(s) loss:0.174733 loss200:0.132338 lr:6.00e-05[train] 2210/33336 1953(s) eta:27506(s) loss:0.174681 loss200:0.131605 lr:6.00e-05[train] 2211/33336 1954(s) eta:27507(s) loss:0.174732 loss200:0.132476 lr:6.00e-05[train] 2212/33336 1955(s) eta:27507(s) loss:0.174728 loss200:0.132888 lr:6.00e-05[train] 2213/33336 1956(s) eta:27508(s) loss:0.174665 loss200:0.132379 lr:6.00e-05[train] 2214/33336 1957(s) eta:27509(s) loss:0.174600 loss200:0.131811 lr:6.00e-05[train] 2215/33336 1958(s) eta:27510(s) loss:0.174558 loss200:0.131675 lr:6.00e-05[train] 2216/33336 1958(s) eta:27496(s) loss:0.174528 loss200:0.131163 lr:6.00e-05[train] 2217/33336 1959(s) eta:27497(s) loss:0.174490 loss200:0.131275 lr:6.00e-05[train] 2218/33336 1960(s) eta:27498(s) loss:0.174546 loss200:0.132026 lr:6.00e-05[train] 2219/33336 1961(s) eta:27499(s) loss:0.174493 loss200:0.131424 lr:6.00e-05[train] 2220/33336 1962(s) eta:27499(s) loss:0.174502 loss200:0.131148 lr:6.00e-05[train] 2221/33336 1963(s) eta:27500(s) loss:0.174446 loss200:0.131096 lr:6.00e-05[train] 2222/33336 1964(s) eta:27501(s) loss:0.174450 loss200:0.131720 lr:6.00e-05[train] 2223/33336 1965(s) eta:27502(s) loss:0.174449 loss200:0.131720 lr:6.00e-05[train] 2224/33336 1965(s) eta:27488(s) loss:0.174392 loss200:0.131292 lr:6.00e-05[train] 2225/33336 1966(s) eta:27489(s) loss:0.174333 loss200:0.130788 lr:6.00e-05[train] 2226/33336 1967(s) eta:27490(s) loss:0.174274 loss200:0.129430 lr:6.00e-05[train] 2227/33336 1968(s) eta:27491(s) loss:0.174255 loss200:0.129212 lr:6.00e-05[train] 2228/33336 1969(s) eta:27491(s) loss:0.174251 loss200:0.129708 lr:6.00e-05[train] 2229/33336 1970(s) eta:27492(s) loss:0.174188 loss200:0.129579 lr:6.00e-05[train] 2230/33336 1971(s) eta:27493(s) loss:0.174172 loss200:0.129872 lr:6.00e-05[train] 2231/33336 1972(s) eta:27493(s) loss:0.174129 loss200:0.129415 lr:6.00e-05[train] 2232/33336 1972(s) eta:27480(s) loss:0.174090 loss200:0.129372 lr:6.00e-05[train] 2233/33336 1973(s) eta:27481(s) loss:0.174039 loss200:0.128831 lr:6.00e-05[train] 2234/33336 1974(s) eta:27482(s) loss:0.173980 loss200:0.128472 lr:6.00e-05[train] 2235/33336 1975(s) eta:27482(s) loss:0.173944 loss200:0.127619 lr:6.00e-05[train] 2236/33336 1976(s) eta:27483(s) loss:0.173946 loss200:0.127263 lr:6.00e-05[train] 2237/33336 1977(s) eta:27484(s) loss:0.174079 loss200:0.129037 lr:6.00e-05[train] 2238/33336 1978(s) eta:27485(s) loss:0.174042 loss200:0.128871 lr:6.00e-05[train] 2239/33336 1978(s) eta:27472(s) loss:0.174073 loss200:0.129665 lr:6.00e-05[train] 2240/33336 1979(s) eta:27472(s) loss:0.174061 loss200:0.129546 lr:6.00e-05[train] 2241/33336 1980(s) eta:27473(s) loss:0.174020 loss200:0.129727 lr:6.00e-05[train] 2242/33336 1981(s) eta:27474(s) loss:0.173989 loss200:0.129913 lr:6.00e-05[train] 2243/33336 1982(s) eta:27474(s) loss:0.174019 loss200:0.129766 lr:6.00e-05[train] 2244/33336 1983(s) eta:27475(s) loss:0.174031 loss200:0.130536 lr:6.00e-05[train] 2245/33336 1984(s) eta:27476(s) loss:0.173983 loss200:0.130489 lr:6.00e-05[train] 2246/33336 1985(s) eta:27477(s) loss:0.174026 loss200:0.131434 lr:6.00e-05[train] 2247/33336 1985(s) eta:27464(s) loss:0.174009 loss200:0.131829 lr:6.00e-05[train] 2248/33336 1986(s) eta:27464(s) loss:0.173999 loss200:0.131515 lr:6.00e-05[train] 2249/33336 1987(s) eta:27465(s) loss:0.173958 loss200:0.131362 lr:6.00e-05[train] 2250/33336 1988(s) eta:27466(s) loss:0.173894 loss200:0.131265 lr:6.00e-05[train] 2251/33336 1989(s) eta:27466(s) loss:0.173869 loss200:0.130932 lr:6.00e-05[train] 2252/33336 1990(s) eta:27467(s) loss:0.173817 loss200:0.130000 lr:6.00e-05[train] 2253/33336 1991(s) eta:27468(s) loss:0.173811 loss200:0.129409 lr:6.00e-05[train] 2254/33336 1992(s) eta:27469(s) loss:0.173766 loss200:0.128829 lr:6.00e-05[train] 2255/33336 1993(s) eta:27469(s) loss:0.173715 loss200:0.128664 lr:6.00e-05[train] 2256/33336 1994(s) eta:27470(s) loss:0.173665 loss200:0.128477 lr:6.00e-05[train] 2257/33336 1994(s) eta:27457(s) loss:0.173629 loss200:0.128241 lr:6.00e-05[train] 2258/33336 1995(s) eta:27458(s) loss:0.173592 loss200:0.127679 lr:6.00e-05[train] 2259/33336 1996(s) eta:27458(s) loss:0.173568 loss200:0.127862 lr:6.00e-05[train] 2260/33336 1997(s) eta:27459(s) loss:0.173526 loss200:0.127687 lr:6.00e-05[train] 2261/33336 1998(s) eta:27460(s) loss:0.173520 loss200:0.127948 lr:6.00e-05[train] 2262/33336 1999(s) eta:27461(s) loss:0.173471 loss200:0.127291 lr:6.00e-05[train] 2263/33336 2000(s) eta:27461(s) loss:0.173410 loss200:0.126543 lr:6.00e-05[train] 2264/33336 2001(s) eta:27462(s) loss:0.173404 loss200:0.126655 lr:6.00e-05[train] 2265/33336 2001(s) eta:27449(s) loss:0.173432 loss200:0.127549 lr:6.00e-05[train] 2266/33336 2002(s) eta:27450(s) loss:0.173371 loss200:0.127245 lr:6.00e-05[train] 2267/33336 2003(s) eta:27450(s) loss:0.173405 loss200:0.128152 lr:6.00e-05[train] 2268/33336 2004(s) eta:27451(s) loss:0.173352 loss200:0.128162 lr:6.00e-05[train] 2269/33336 2005(s) eta:27452(s) loss:0.173348 loss200:0.127942 lr:6.00e-05[train] 2270/33336 2006(s) eta:27453(s) loss:0.173299 loss200:0.127497 lr:6.00e-05[train] 2271/33336 2007(s) eta:27453(s) loss:0.173260 loss200:0.127252 lr:6.00e-05[train] 2272/33336 2008(s) eta:27454(s) loss:0.173258 loss200:0.127210 lr:6.00e-05[train] 2273/33336 2009(s) eta:27455(s) loss:0.173200 loss200:0.126499 lr:6.00e-05[train] 2274/33336 2009(s) eta:27442(s) loss:0.173164 loss200:0.126200 lr:6.00e-05[train] 2275/33336 2010(s) eta:27442(s) loss:0.173166 loss200:0.126376 lr:6.00e-05[train] 2276/33336 2011(s) eta:27443(s) loss:0.173123 loss200:0.126521 lr:6.00e-05[train] 2277/33336 2012(s) eta:27444(s) loss:0.173101 loss200:0.126791 lr:6.00e-05[train] 2278/33336 2013(s) eta:27445(s) loss:0.173110 loss200:0.126811 lr:6.00e-05[train] 2279/33336 2014(s) eta:27445(s) loss:0.173059 loss200:0.126378 lr:6.00e-05[train] 2280/33336 2015(s) eta:27446(s) loss:0.172998 loss200:0.126060 lr:6.00e-05[train] 2281/33336 2015(s) eta:27433(s) loss:0.172968 loss200:0.126272 lr:6.00e-05[train] 2282/33336 2016(s) eta:27434(s) loss:0.172980 loss200:0.126896 lr:6.00e-05[train] 2283/33336 2017(s) eta:27434(s) loss:0.173015 loss200:0.126651 lr:6.00e-05[train] 2284/33336 2018(s) eta:27435(s) loss:0.172987 loss200:0.126675 lr:6.00e-05[train] 2285/33336 2019(s) eta:27436(s) loss:0.173000 loss200:0.127455 lr:6.00e-05[train] 2286/33336 2020(s) eta:27437(s) loss:0.172996 loss200:0.127831 lr:6.00e-05[train] 2287/33336 2021(s) eta:27437(s) loss:0.173005 loss200:0.128391 lr:6.00e-05[train] 2288/33336 2022(s) eta:27438(s) loss:0.172955 loss200:0.128463 lr:6.00e-05[train] 2289/33336 2023(s) eta:27439(s) loss:0.172923 loss200:0.128412 lr:6.00e-05[train] 2290/33336 2024(s) eta:27439(s) loss:0.172881 loss200:0.127923 lr:6.00e-05[train] 2291/33336 2024(s) eta:27426(s) loss:0.172838 loss200:0.127962 lr:6.00e-05[train] 2292/33336 2025(s) eta:27427(s) loss:0.172794 loss200:0.127820 lr:6.00e-05[train] 2293/33336 2026(s) eta:27428(s) loss:0.172745 loss200:0.127345 lr:6.00e-05[train] 2294/33336 2027(s) eta:27429(s) loss:0.172697 loss200:0.127349 lr:6.00e-05[train] 2295/33336 2028(s) eta:27429(s) loss:0.172668 loss200:0.127598 lr:6.00e-05[train] 2296/33336 2029(s) eta:27430(s) loss:0.172658 loss200:0.127948 lr:6.00e-05Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
[train] 2297/33336 2030(s) eta:27431(s) loss:0.172617 loss200:0.127580 lr:6.00e-05[train] 2298/33336 2030(s) eta:27418(s) loss:0.172637 loss200:0.128155 lr:6.00e-05[train] 2299/33336 2031(s) eta:27418(s) loss:0.172601 loss200:0.128434 lr:6.00e-05[train] 2300/33336 2032(s) eta:27419(s) loss:0.172568 loss200:0.128516 lr:6.00e-05[train] 2301/33336 2033(s) eta:27420(s) loss:0.172547 loss200:0.127940 lr:6.00e-05[train] 2302/33336 2034(s) eta:27421(s) loss:0.172492 loss200:0.127992 lr:6.00e-05[train] 2303/33336 2035(s) eta:27421(s) loss:0.172441 loss200:0.126997 lr:6.00e-05[train] 2304/33336 2036(s) eta:27422(s) loss:0.172433 loss200:0.126296 lr:6.00e-05[train] 2305/33336 2037(s) eta:27423(s) loss:0.172430 loss200:0.126144 lr:6.00e-05[train] 2306/33336 2037(s) eta:27410(s) loss:0.172375 loss200:0.125886 lr:6.00e-05[train] 2307/33336 2038(s) eta:27410(s) loss:0.172333 loss200:0.125935 lr:6.00e-05[train] 2308/33336 2039(s) eta:27411(s) loss:0.172387 loss200:0.127089 lr:6.00e-05[train] 2309/33336 2040(s) eta:27412(s) loss:0.172385 loss200:0.127624 lr:6.00e-05[train] 2310/33336 2041(s) eta:27413(s) loss:0.172351 loss200:0.127963 lr:6.00e-05[train] 2311/33336 2042(s) eta:27413(s) loss:0.172327 loss200:0.128245 lr:6.00e-05[train] 2312/33336 2043(s) eta:27414(s) loss:0.172378 loss200:0.129289 lr:6.00e-05[train] 2313/33336 2044(s) eta:27415(s) loss:0.172326 loss200:0.128689 lr:6.00e-05[train] 2314/33336 2045(s) eta:27415(s) loss:0.172340 loss200:0.129520 lr:6.00e-05[train] 2315/33336 2045(s) eta:27403(s) loss:0.172301 loss200:0.129455 lr:6.00e-05[train] 2316/33336 2046(s) eta:27403(s) loss:0.172236 loss200:0.129162 lr:6.00e-05[train] 2317/33336 2047(s) eta:27404(s) loss:0.172212 loss200:0.129208 lr:6.00e-05[train] 2318/33336 2048(s) eta:27405(s) loss:0.172204 loss200:0.129552 lr:6.00e-05[train] 2319/33336 2049(s) eta:27405(s) loss:0.172178 loss200:0.129937 lr:6.00e-05[train] 2320/33336 2050(s) eta:27406(s) loss:0.172320 loss200:0.131652 lr:6.00e-05[train] 2321/33336 2051(s) eta:27407(s) loss:0.172265 loss200:0.131608 lr:6.00e-05[train] 2322/33336 2051(s) eta:27394(s) loss:0.172346 loss200:0.132815 lr:6.00e-05[train] 2323/33336 2052(s) eta:27395(s) loss:0.172296 loss200:0.132631 lr:6.00e-05[train] 2324/33336 2053(s) eta:27395(s) loss:0.172269 loss200:0.130878 lr:6.00e-05[train] 2325/33336 2054(s) eta:27396(s) loss:0.172315 loss200:0.130885 lr:6.00e-05[train] 2326/33336 2055(s) eta:27397(s) loss:0.172287 loss200:0.131122 lr:6.00e-05[train] 2327/33336 2056(s) eta:27397(s) loss:0.172321 loss200:0.131568 lr:6.00e-05[train] 2328/33336 2057(s) eta:27398(s) loss:0.172274 loss200:0.130465 lr:6.00e-05[train] 2329/33336 2058(s) eta:27399(s) loss:0.172248 loss200:0.130391 lr:6.00e-05[train] 2330/33336 2058(s) eta:27386(s) loss:0.172221 loss200:0.130303 lr:6.00e-05[train] 2331/33336 2059(s) eta:27387(s) loss:0.172252 loss200:0.130854 lr:6.00e-05[train] 2332/33336 2060(s) eta:27387(s) loss:0.172218 loss200:0.130486 lr:6.00e-05[train] 2333/33336 2061(s) eta:27388(s) loss:0.172169 loss200:0.129933 lr:6.00e-05[train] 2334/33336 2062(s) eta:27389(s) loss:0.172124 loss200:0.130063 lr:6.00e-05[train] 2335/33336 2063(s) eta:27389(s) loss:0.172120 loss200:0.130636 lr:6.00e-05[train] 2336/33336 2064(s) eta:27390(s) loss:0.172067 loss200:0.130751 lr:6.00e-05[train] 2337/33336 2065(s) eta:27391(s) loss:0.172115 loss200:0.131781 lr:6.00e-05[train] 2338/33336 2066(s) eta:27391(s) loss:0.172072 loss200:0.131189 lr:6.00e-05[train] 2339/33336 2066(s) eta:27379(s) loss:0.172018 loss200:0.129889 lr:6.00e-05[train] 2340/33336 2067(s) eta:27379(s) loss:0.172035 loss200:0.129719 lr:6.00e-05[train] 2341/33336 2068(s) eta:27380(s) loss:0.172117 loss200:0.130376 lr:6.00e-05[train] 2342/33336 2069(s) eta:27381(s) loss:0.172102 loss200:0.130376 lr:6.00e-05[train] 2343/33336 2070(s) eta:27381(s) loss:0.172057 loss200:0.129686 lr:6.00e-05[train] 2344/33336 2071(s) eta:27382(s) loss:0.172002 loss200:0.129667 lr:6.00e-05[train] 2345/33336 2072(s) eta:27383(s) loss:0.171968 loss200:0.129797 lr:6.00e-05[train] 2346/33336 2072(s) eta:27370(s) loss:0.171951 loss200:0.130150 lr:6.00e-05[train] 2347/33336 2073(s) eta:27371(s) loss:0.172017 loss200:0.131285 lr:6.00e-05[train] 2348/33336 2074(s) eta:27371(s) loss:0.171978 loss200:0.130678 lr:6.00e-05[train] 2349/33336 2075(s) eta:27372(s) loss:0.171926 loss200:0.129989 lr:6.00e-05[train] 2350/33336 2076(s) eta:27373(s) loss:0.171931 loss200:0.130218 lr:6.00e-05[train] 2351/33336 2077(s) eta:27373(s) loss:0.171966 loss200:0.130746 lr:6.00e-05[train] 2352/33336 2078(s) eta:27374(s) loss:0.171916 loss200:0.130603 lr:6.00e-05[train] 2353/33336 2079(s) eta:27375(s) loss:0.171895 loss200:0.130371 lr:6.00e-05[train] 2354/33336 2079(s) eta:27362(s) loss:0.171908 loss200:0.128944 lr:6.00e-05[train] 2355/33336 2080(s) eta:27363(s) loss:0.171868 loss200:0.128644 lr:6.00e-05[train] 2356/33336 2081(s) eta:27363(s) loss:0.171875 loss200:0.128317 lr:6.00e-05[train] 2357/33336 2082(s) eta:27364(s) loss:0.171842 loss200:0.128292 lr:6.00e-05[train] 2358/33336 2083(s) eta:27365(s) loss:0.171826 loss200:0.127896 lr:6.00e-05[train] 2359/33336 2084(s) eta:27365(s) loss:0.171832 loss200:0.128553 lr:6.00e-05[train] 2360/33336 2085(s) eta:27366(s) loss:0.171778 loss200:0.128389 lr:6.00e-05[train] 2361/33336 2085(s) eta:27354(s) loss:0.171734 loss200:0.128540 lr:6.00e-05[train] 2362/33336 2086(s) eta:27354(s) loss:0.171741 loss200:0.128862 lr:6.00e-05[train] 2363/33336 2087(s) eta:27355(s) loss:0.171710 loss200:0.129057 lr:6.00e-05[train] 2364/33336 2088(s) eta:27355(s) loss:0.171665 loss200:0.128167 lr:6.00e-05[train] 2365/33336 2089(s) eta:27356(s) loss:0.171719 loss200:0.129060 lr:6.00e-05[train] 2366/33336 2090(s) eta:27357(s) loss:0.171709 loss200:0.129379 lr:6.00e-05[train] 2367/33336 2091(s) eta:27357(s) loss:0.171737 loss200:0.130046 lr:6.00e-05[train] 2368/33336 2092(s) eta:27358(s) loss:0.171707 loss200:0.129748 lr:6.00e-05[train] 2369/33336 2092(s) eta:27346(s) loss:0.171689 loss200:0.129502 lr:6.00e-05[train] 2370/33336 2093(s) eta:27346(s) loss:0.171711 loss200:0.130040 lr:6.00e-05[train] 2371/33336 2094(s) eta:27347(s) loss:0.171689 loss200:0.130461 lr:6.00e-05[train] 2372/33336 2095(s) eta:27348(s) loss:0.171711 loss200:0.131023 lr:6.00e-05[train] 2373/33336 2096(s) eta:27348(s) loss:0.171719 loss200:0.131071 lr:6.00e-05[train] 2374/33336 2097(s) eta:27349(s) loss:0.171675 loss200:0.130887 lr:6.00e-05[train] 2375/33336 2098(s) eta:27349(s) loss:0.171682 loss200:0.131583 lr:6.00e-05[train] 2376/33336 2099(s) eta:27350(s) loss:0.171673 loss200:0.131974 lr:6.00e-05[train] 2377/33336 2099(s) eta:27338(s) loss:0.171629 loss200:0.132150 lr:6.00e-05[train] 2378/33336 2100(s) eta:27338(s) loss:0.171576 loss200:0.132191 lr:6.00e-05[train] 2379/33336 2101(s) eta:27339(s) loss:0.171576 loss200:0.132558 lr:6.00e-05[train] 2380/33336 2102(s) eta:27340(s) loss:0.171590 loss200:0.132712 lr:6.00e-05[train] 2381/33336 2103(s) eta:27340(s) loss:0.171548 loss200:0.131191 lr:6.00e-05[train] 2382/33336 2104(s) eta:27341(s) loss:0.171566 loss200:0.131450 lr:6.00e-05[train] 2383/33336 2105(s) eta:27342(s) loss:0.171630 loss200:0.131331 lr:6.00e-05[train] 2384/33336 2106(s) eta:27342(s) loss:0.171674 loss200:0.132286 lr:6.00e-05[train] 2385/33336 2106(s) eta:27330(s) loss:0.171686 loss200:0.132759 lr:6.00e-05[train] 2386/33336 2107(s) eta:27330(s) loss:0.171739 loss200:0.133886 lr:6.00e-05[train] 2387/33336 2108(s) eta:27331(s) loss:0.171709 loss200:0.133278 lr:6.00e-05[train] 2388/33336 2109(s) eta:27332(s) loss:0.171676 loss200:0.132134 lr:6.00e-05[train] 2389/33336 2110(s) eta:27332(s) loss:0.171624 loss200:0.131725 lr:6.00e-05[train] 2390/33336 2111(s) eta:27333(s) loss:0.171633 loss200:0.132009 lr:6.00e-05[train] 2391/33336 2112(s) eta:27334(s) loss:0.171583 loss200:0.131847 lr:6.00e-05[train] 2392/33336 2112(s) eta:27321(s) loss:0.171533 loss200:0.131520 lr:6.00e-05[train] 2393/33336 2113(s) eta:27322(s) loss:0.171486 loss200:0.131342 lr:6.00e-05[train] 2394/33336 2114(s) eta:27323(s) loss:0.171429 loss200:0.130744 lr:6.00e-05[train] 2395/33336 2115(s) eta:27323(s) loss:0.171399 loss200:0.130832 lr:6.00e-05[train] 2396/33336 2116(s) eta:27324(s) loss:0.171378 loss200:0.131127 lr:6.00e-05[train] 2397/33336 2117(s) eta:27324(s) loss:0.171329 loss200:0.130390 lr:6.00e-05[train] 2398/33336 2118(s) eta:27325(s) loss:0.171318 loss200:0.130183 lr:6.00e-05[train] 2399/33336 2119(s) eta:27326(s) loss:0.171279 loss200:0.130245 lr:6.00e-05[train] 2400/33336 2120(s) eta:27326(s) loss:0.171222 loss200:0.130080 lr:6.00e-05[train] 2401/33336 2120(s) eta:27314(s) loss:0.171196 loss200:0.130131 lr:6.00e-05[train] 2402/33336 2121(s) eta:27315(s) loss:0.171135 loss200:0.129509 lr:6.00e-05[train] 2403/33336 2122(s) eta:27315(s) loss:0.171125 loss200:0.129816 lr:6.00e-05[train] 2404/33336 2123(s) eta:27316(s) loss:0.171095 loss200:0.130088 lr:6.00e-05[train] 2405/33336 2124(s) eta:27317(s) loss:0.171087 loss200:0.130616 lr:6.00e-05[train] 2406/33336 2125(s) eta:27317(s) loss:0.171048 loss200:0.130703 lr:6.00e-05[train] 2407/33336 2126(s) eta:27318(s) loss:0.171026 loss200:0.129347 lr:6.00e-05[train] 2408/33336 2127(s) eta:27318(s) loss:0.170970 loss200:0.129113 lr:6.00e-05[train] 2409/33336 2127(s) eta:27306(s) loss:0.170920 loss200:0.128802 lr:6.00e-05[train] 2410/33336 2128(s) eta:27307(s) loss:0.170912 loss200:0.129269 lr:6.00e-05[train] 2411/33336 2129(s) eta:27307(s) loss:0.170853 loss200:0.127977 lr:6.00e-05[train] 2412/33336 2130(s) eta:27308(s) loss:0.170807 loss200:0.127433 lr:6.00e-05[train] 2413/33336 2131(s) eta:27309(s) loss:0.170845 loss200:0.128585 lr:6.00e-05[train] 2414/33336 2132(s) eta:27309(s) loss:0.170843 loss200:0.129250 lr:6.00e-05[train] 2415/33336 2133(s) eta:27310(s) loss:0.170899 loss200:0.130375 lr:6.00e-05[train] 2416/33336 2134(s) eta:27310(s) loss:0.170933 loss200:0.131098 lr:6.00e-05[train] 2417/33336 2134(s) eta:27298(s) loss:0.170973 loss200:0.131986 lr:6.00e-05[train] 2418/33336 2135(s) eta:27299(s) loss:0.170973 loss200:0.131349 lr:6.00e-05[train] 2419/33336 2136(s) eta:27300(s) loss:0.170931 loss200:0.131412 lr:6.00e-05[train] 2420/33336 2137(s) eta:27300(s) loss:0.170873 loss200:0.130597 lr:6.00e-05[train] 2421/33336 2138(s) eta:27301(s) loss:0.170884 loss200:0.131326 lr:6.00e-05[train] 2422/33336 2139(s) eta:27301(s) loss:0.170835 loss200:0.130673 lr:6.00e-05[train] 2423/33336 2140(s) eta:27302(s) loss:0.170853 loss200:0.130880 lr:6.00e-05[train] 2424/33336 2140(s) eta:27290(s) loss:0.170801 loss200:0.130870 lr:6.00e-05[train] 2425/33336 2141(s) eta:27290(s) loss:0.170766 loss200:0.131078 lr:6.00e-05[train] 2426/33336 2142(s) eta:27291(s) loss:0.170765 loss200:0.131703 lr:6.00e-05[train] 2427/33336 2143(s) eta:27292(s) loss:0.170796 loss200:0.132279 lr:6.00e-05[train] 2428/33336 2144(s) eta:27292(s) loss:0.170745 loss200:0.131688 lr:6.00e-05[train] 2429/33336 2145(s) eta:27293(s) loss:0.170744 loss200:0.132358 lr:6.00e-05[train] 2430/33336 2146(s) eta:27293(s) loss:0.170728 loss200:0.132328 lr:6.00e-05[train] 2431/33336 2147(s) eta:27294(s) loss:0.170737 loss200:0.132893 lr:6.00e-05[train] 2432/33336 2147(s) eta:27282(s) loss:0.170712 loss200:0.133017 lr:6.00e-05[train] 2433/33336 2148(s) eta:27283(s) loss:0.170666 loss200:0.133009 lr:6.00e-05[train] 2434/33336 2149(s) eta:27283(s) loss:0.170669 loss200:0.133690 lr:6.00e-05[train] 2435/33336 2150(s) eta:27284(s) loss:0.170694 loss200:0.134374 lr:6.00e-05[train] 2436/33336 2151(s) eta:27284(s) loss:0.170650 loss200:0.133799 lr:6.00e-05[train] 2437/33336 2152(s) eta:27285(s) loss:0.170609 loss200:0.131789 lr:6.00e-05[train] 2438/33336 2153(s) eta:27286(s) loss:0.170565 loss200:0.131667 lr:6.00e-05[train] 2439/33336 2154(s) eta:27286(s) loss:0.170519 loss200:0.130737 lr:6.00e-05[train] 2440/33336 2154(s) eta:27274(s) loss:0.170470 loss200:0.130253 lr:6.00e-05[train] 2441/33336 2155(s) eta:27275(s) loss:0.170433 loss200:0.130245 lr:6.00e-05[train] 2442/33336 2156(s) eta:27275(s) loss:0.170555 loss200:0.132056 lr:6.00e-05[train] 2443/33336 2157(s) eta:27276(s) loss:0.170524 loss200:0.131323 lr:6.00e-05[train] 2444/33336 2158(s) eta:27276(s) loss:0.170490 loss200:0.130758 lr:6.00e-05[train] 2445/33336 2159(s) eta:27277(s) loss:0.170544 loss200:0.131937 lr:6.00e-05[train] 2446/33336 2160(s) eta:27278(s) loss:0.170537 loss200:0.131357 lr:6.00e-05[train] 2447/33336 2161(s) eta:27278(s) loss:0.170517 loss200:0.131286 lr:6.00e-05[train] 2448/33336 2161(s) eta:27266(s) loss:0.170467 loss200:0.130763 lr:6.00e-05[train] 2449/33336 2162(s) eta:27267(s) loss:0.170449 loss200:0.130994 lr:6.00e-05[train] 2450/33336 2163(s) eta:27267(s) loss:0.170472 loss200:0.131982 lr:6.00e-05[train] 2451/33336 2164(s) eta:27268(s) loss:0.170497 loss200:0.132548 lr:6.00e-05[train] 2452/33336 2165(s) eta:27269(s) loss:0.170464 loss200:0.132707 lr:6.00e-05[train] 2453/33336 2166(s) eta:27269(s) loss:0.170443 loss200:0.132509 lr:6.00e-05[train] 2454/33336 2167(s) eta:27270(s) loss:0.170468 loss200:0.133290 lr:6.00e-05[train] 2455/33336 2168(s) eta:27270(s) loss:0.170449 loss200:0.133626 lr:6.00e-05[train] 2456/33336 2169(s) eta:27271(s) loss:0.170406 loss200:0.133644 lr:6.00e-05[train] 2457/33336 2169(s) eta:27259(s) loss:0.170379 loss200:0.133712 lr:6.00e-05[train] 2458/33336 2170(s) eta:27260(s) loss:0.170345 loss200:0.133685 lr:6.00e-05[train] 2459/33336 2171(s) eta:27260(s) loss:0.170308 loss200:0.133493 lr:6.00e-05[train] 2460/33336 2172(s) eta:27261(s) loss:0.170272 loss200:0.133495 lr:6.00e-05[train] 2461/33336 2173(s) eta:27261(s) loss:0.170245 loss200:0.133219 lr:6.00e-05[train] 2462/33336 2174(s) eta:27262(s) loss:0.170218 loss200:0.133433 lr:6.00e-05[train] 2463/33336 2175(s) eta:27263(s) loss:0.170195 loss200:0.133818 lr:6.00e-05[train] 2464/33336 2175(s) eta:27251(s) loss:0.170161 loss200:0.133451 lr:6.00e-05[train] 2465/33336 2176(s) eta:27251(s) loss:0.170139 loss200:0.132851 lr:6.00e-05[train] 2466/33336 2177(s) eta:27252(s) loss:0.170095 loss200:0.132982 lr:6.00e-05[train] 2467/33336 2178(s) eta:27252(s) loss:0.170051 loss200:0.132035 lr:6.00e-05[train] 2468/33336 2179(s) eta:27253(s) loss:0.170009 loss200:0.132100 lr:6.00e-05[train] 2469/33336 2180(s) eta:27253(s) loss:0.169995 loss200:0.131953 lr:6.00e-05[train] 2470/33336 2181(s) eta:27254(s) loss:0.170071 loss200:0.133437 lr:6.00e-05[train] 2471/33336 2182(s) eta:27255(s) loss:0.170058 loss200:0.133699 lr:6.00e-05[train] 2472/33336 2182(s) eta:27243(s) loss:0.170034 loss200:0.133407 lr:6.00e-05[train] 2473/33336 2183(s) eta:27243(s) loss:0.170013 loss200:0.133783 lr:6.00e-05[train] 2474/33336 2184(s) eta:27244(s) loss:0.169993 loss200:0.133937 lr:6.00e-05[train] 2475/33336 2185(s) eta:27244(s) loss:0.169943 loss200:0.133272 lr:6.00e-05[train] 2476/33336 2186(s) eta:27245(s) loss:0.169938 loss200:0.133687 lr:6.00e-05[train] 2477/33336 2187(s) eta:27246(s) loss:0.169896 loss200:0.133407 lr:6.00e-05[train] 2478/33336 2188(s) eta:27246(s) loss:0.169853 loss200:0.132759 lr:6.00e-05[train] 2479/33336 2189(s) eta:27247(s) loss:0.169794 loss200:0.132585 lr:6.00e-05[train] 2480/33336 2189(s) eta:27235(s) loss:0.169744 loss200:0.132652 lr:6.00e-05[train] 2481/33336 2190(s) eta:27235(s) loss:0.169704 loss200:0.132481 lr:6.00e-05[train] 2482/33336 2191(s) eta:27236(s) loss:0.169783 loss200:0.133307 lr:6.00e-05[train] 2483/33336 2192(s) eta:27237(s) loss:0.169733 loss200:0.132273 lr:6.00e-05[train] 2484/33336 2193(s) eta:27237(s) loss:0.169689 loss200:0.132025 lr:6.00e-05[train] 2485/33336 2194(s) eta:27238(s) loss:0.169664 loss200:0.131545 lr:6.00e-05[train] 2486/33336 2195(s) eta:27238(s) loss:0.169628 loss200:0.131129 lr:6.00e-05[train] 2487/33336 2196(s) eta:27239(s) loss:0.169612 loss200:0.130817 lr:6.00e-05[train] 2488/33336 2197(s) eta:27239(s) loss:0.169575 loss200:0.130903 lr:6.00e-05[train] 2489/33336 2197(s) eta:27228(s) loss:0.169535 loss200:0.130756 lr:6.00e-05[train] 2490/33336 2198(s) eta:27228(s) loss:0.169547 loss200:0.131381 lr:6.00e-05[train] 2491/33336 2199(s) eta:27229(s) loss:0.169517 loss200:0.131469 lr:6.00e-05[train] 2492/33336 2200(s) eta:27229(s) loss:0.169485 loss200:0.131570 lr:6.00e-05[train] 2493/33336 2201(s) eta:27230(s) loss:0.169444 loss200:0.131608 lr:6.00e-05[train] 2494/33336 2202(s) eta:27230(s) loss:0.169422 loss200:0.131854 lr:6.00e-05[train] 2495/33336 2203(s) eta:27231(s) loss:0.169435 loss200:0.132332 lr:6.00e-05[train] 2496/33336 2204(s) eta:27232(s) loss:0.169396 loss200:0.131952 lr:6.00e-05[train] 2497/33336 2205(s) eta:27232(s) loss:0.169410 loss200:0.132573 lr:6.00e-05[train] 2498/33336 2206(s) eta:27233(s) loss:0.169445 loss200:0.132764 lr:6.00e-05[train] 2499/33336 2206(s) eta:27221(s) loss:0.169389 loss200:0.132468 lr:6.00e-05[train] 2500/33336 2207(s) eta:27222(s) loss:0.169394 loss200:0.132893 lr:6.00e-05[train] 2501/33336 2208(s) eta:27222(s) loss:0.169366 loss200:0.132770 lr:6.00e-05[train] 2502/33336 2209(s) eta:27223(s) loss:0.169329 loss200:0.132931 lr:6.00e-05[train] 2503/33336 2210(s) eta:27223(s) loss:0.169315 loss200:0.133316 lr:6.00e-05[train] 2504/33336 2211(s) eta:27224(s) loss:0.169283 loss200:0.132999 lr:6.00e-05[train] 2505/33336 2212(s) eta:27224(s) loss:0.169266 loss200:0.132806 lr:6.00e-05[train] 2506/33336 2212(s) eta:27213(s) loss:0.169231 loss200:0.132991 lr:6.00e-05[train] 2507/33336 2213(s) eta:27213(s) loss:0.169209 loss200:0.133176 lr:6.00e-05[train] 2508/33336 2214(s) eta:27214(s) loss:0.169172 loss200:0.132070 lr:6.00e-05[train] 2509/33336 2215(s) eta:27214(s) loss:0.169128 loss200:0.131525 lr:6.00e-05[train] 2510/33336 2216(s) eta:27215(s) loss:0.169126 loss200:0.131873 lr:6.00e-05[train] 2511/33336 2217(s) eta:27215(s) loss:0.169105 loss200:0.131871 lr:6.00e-05[train] 2512/33336 2218(s) eta:27216(s) loss:0.169067 loss200:0.130786 lr:6.00e-05[train] 2513/33336 2218(s) eta:27204(s) loss:0.169013 loss200:0.130699 lr:6.00e-05[train] 2514/33336 2219(s) eta:27205(s) loss:0.169018 loss200:0.130586 lr:6.00e-05[train] 2515/33336 2220(s) eta:27205(s) loss:0.168983 loss200:0.130580 lr:6.00e-05[train] 2516/33336 2221(s) eta:27206(s) loss:0.168936 loss200:0.130719 lr:6.00e-05[train] 2517/33336 2222(s) eta:27206(s) loss:0.168896 loss200:0.130481 lr:6.00e-05[train] 2518/33336 2223(s) eta:27207(s) loss:0.168867 loss200:0.130191 lr:6.00e-05[train] 2519/33336 2224(s) eta:27208(s) loss:0.168851 loss200:0.130274 lr:6.00e-05[train] 2520/33336 2225(s) eta:27208(s) loss:0.168830 loss200:0.128348 lr:6.00e-05[train] 2521/33336 2226(s) eta:27209(s) loss:0.168796 loss200:0.128545 lr:6.00e-05[train] 2522/33336 2226(s) eta:27197(s) loss:0.168750 loss200:0.127009 lr:6.00e-05[train] 2523/33336 2227(s) eta:27197(s) loss:0.168733 loss200:0.127337 lr:6.00e-05[train] 2524/33336 2228(s) eta:27198(s) loss:0.168722 loss200:0.127506 lr:6.00e-05[train] 2525/33336 2229(s) eta:27199(s) loss:0.168695 loss200:0.126618 lr:6.00e-05[train] 2526/33336 2230(s) eta:27199(s) loss:0.168669 loss200:0.126588 lr:6.00e-05[train] 2527/33336 2231(s) eta:27200(s) loss:0.168657 loss200:0.126025 lr:6.00e-05[train] 2528/33336 2232(s) eta:27200(s) loss:0.168601 loss200:0.125853 lr:6.00e-05[train] 2529/33336 2233(s) eta:27201(s) loss:0.168581 loss200:0.125875 lr:6.00e-05[train] 2530/33336 2234(s) eta:27201(s) loss:0.168524 loss200:0.125458 lr:6.00e-05[train] 2531/33336 2234(s) eta:27190(s) loss:0.168471 loss200:0.124398 lr:6.00e-05[train] 2532/33336 2235(s) eta:27190(s) loss:0.168421 loss200:0.124147 lr:6.00e-05[train] 2533/33336 2236(s) eta:27191(s) loss:0.168416 loss200:0.124632 lr:6.00e-05[train] 2534/33336 2237(s) eta:27191(s) loss:0.168410 loss200:0.125068 lr:6.00e-05[train] 2535/33336 2238(s) eta:27192(s) loss:0.168425 loss200:0.125282 lr:6.00e-05[train] 2536/33336 2239(s) eta:27192(s) loss:0.168424 loss200:0.125883 lr:6.00e-05[train] 2537/33336 2240(s) eta:27193(s) loss:0.168443 loss200:0.125530 lr:6.00e-05[train] 2538/33336 2241(s) eta:27193(s) loss:0.168434 loss200:0.125906 lr:6.00e-05[train] 2539/33336 2241(s) eta:27182(s) loss:0.168430 loss200:0.126467 lr:6.00e-05[train] 2540/33336 2242(s) eta:27182(s) loss:0.168414 loss200:0.126057 lr:6.00e-05[train] 2541/33336 2243(s) eta:27183(s) loss:0.168407 loss200:0.124977 lr:6.00e-05[train] 2542/33336 2244(s) eta:27184(s) loss:0.168354 loss200:0.124473 lr:6.00e-05[train] 2543/33336 2245(s) eta:27184(s) loss:0.168306 loss200:0.124373 lr:6.00e-05[train] 2544/33336 2246(s) eta:27185(s) loss:0.168286 loss200:0.124733 lr:6.00e-05[train] 2545/33336 2247(s) eta:27185(s) loss:0.168335 loss200:0.125743 lr:6.00e-05[train] 2546/33336 2248(s) eta:27186(s) loss:0.168291 loss200:0.125354 lr:6.00e-05[train] 2547/33336 2249(s) eta:27186(s) loss:0.168261 loss200:0.124173 lr:6.00e-05[train] 2548/33336 2250(s) eta:27187(s) loss:0.168286 loss200:0.124940 lr:6.00e-05[train] 2549/33336 2250(s) eta:27175(s) loss:0.168281 loss200:0.125474 lr:6.00e-05[train] 2550/33336 2251(s) eta:27176(s) loss:0.168436 loss200:0.127367 lr:6.00e-05[train] 2551/33336 2252(s) eta:27176(s) loss:0.168457 loss200:0.127205 lr:6.00e-05[train] 2552/33336 2253(s) eta:27177(s) loss:0.168423 loss200:0.127341 lr:6.00e-05[train] 2553/33336 2254(s) eta:27177(s) loss:0.168397 loss200:0.127241 lr:6.00e-05[train] 2554/33336 2255(s) eta:27178(s) loss:0.168422 loss200:0.127392 lr:6.00e-05[train] 2555/33336 2256(s) eta:27178(s) loss:0.168426 loss200:0.127898 lr:6.00e-05[train] 2556/33336 2256(s) eta:27167(s) loss:0.168391 loss200:0.127356 lr:6.00e-05[train] 2557/33336 2257(s) eta:27167(s) loss:0.168484 loss200:0.128913 lr:6.00e-05[train] 2558/33336 2258(s) eta:27168(s) loss:0.168453 loss200:0.128676 lr:6.00e-05[train] 2559/33336 2259(s) eta:27168(s) loss:0.168406 loss200:0.128000 lr:6.00e-05[train] 2560/33336 2260(s) eta:27169(s) loss:0.168387 loss200:0.128383 lr:6.00e-05[train] 2561/33336 2261(s) eta:27169(s) loss:0.168339 loss200:0.128263 lr:6.00e-05[train] 2562/33336 2262(s) eta:27170(s) loss:0.168298 loss200:0.127637 lr:6.00e-05[train] 2563/33336 2262(s) eta:27159(s) loss:0.168333 loss200:0.128445 lr:6.00e-05[train] 2564/33336 2263(s) eta:27159(s) loss:0.168293 loss200:0.128433 lr:6.00e-05[train] 2565/33336 2264(s) eta:27160(s) loss:0.168268 loss200:0.127465 lr:6.00e-05[train] 2566/33336 2265(s) eta:27160(s) loss:0.168218 loss200:0.126925 lr:6.00e-05[train] 2567/33336 2266(s) eta:27161(s) loss:0.168198 loss200:0.126312 lr:6.00e-05[train] 2568/33336 2267(s) eta:27161(s) loss:0.168185 loss200:0.126481 lr:6.00e-05[train] 2569/33336 2268(s) eta:27162(s) loss:0.168141 loss200:0.126108 lr:6.00e-05[train] 2570/33336 2269(s) eta:27162(s) loss:0.168089 loss200:0.125179 lr:6.00e-05